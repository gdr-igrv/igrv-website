<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Derni√®res nouvelles | GdR IG-RV</title><link>https://gdr-igrv.fr/post/</link><atom:link href="https://gdr-igrv.fr/post/index.xml" rel="self" type="application/rss+xml"/><description>Derni√®res nouvelles</description><generator>Wowchemy (https://wowchemy.com)</generator><language>fr-fr</language><image><url>https://gdr-igrv.fr/media/icon_hu6ab350bd9da14bf3d770a252e9dc8f37_21017_512x512_fill_lanczos_center_3.png</url><title>Derni√®res nouvelles</title><link>https://gdr-igrv.fr/post/</link></image><item><title>Remise du prix de th√®se du GdR et des associations 2025</title><link>https://gdr-igrv.fr/post/25-11-6-remiseprix/</link><pubDate>Thu, 06 Nov 2025 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/25-11-6-remiseprix/</guid><description>&lt;p>√Ä l&amp;rsquo;occasion des &lt;a href="https://project.inria.fr/jfig2022/" target="_blank" rel="noopener">Journ√©es Fran√ßaises de l&amp;rsquo;Informatique Graphique&lt;/a>, le &lt;a href="https://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">prix de th√®se&lt;/a> du GdR a pu √™tre remis √†
&lt;strong>Cyprien Plateau-Holleville&lt;/strong> (XLIM, Universit√© de Limoges) pour sa th√®se intitul√©e ¬´ Construction efficace de g√©om√©trie pour l‚Äôanalyse structurelle de grands syst√®mes mol√©culaires ¬ª.&lt;/p>
&lt;p>Le prix a √©t√© remis par les organisateurs du Prix de th√®se &lt;a href="https://gdr-igrv.fr/author/georges-pierre-bonneau/">Georges-Pierre Bonneau&lt;/a>, ainsi que les pr√©sidents de l&amp;rsquo;AFIG, **
Maxime Maria** et du Chapitre Fran√ßais d&amp;rsquo;Eurographics (EGFR).&lt;/p>
&lt;p>Les remises des prix aux accessits 2025 seront effectu√©s ult√©rieurement.&lt;/p>
&lt;p>&lt;em>(photos Christophe Renaud)&lt;/em>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/25-11-6-remiseprix/20251106_112827_hu271ecc2785cf216df0b594e399362550_2377219_79ace1de1262ccaca50c36919765adc8.webp 400w,
/post/25-11-6-remiseprix/20251106_112827_hu271ecc2785cf216df0b594e399362550_2377219_1d346ef256d8a81ce9ef66f46379cebd.webp 760w,
/post/25-11-6-remiseprix/20251106_112827_hu271ecc2785cf216df0b594e399362550_2377219_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/25-11-6-remiseprix/20251106_112827_hu271ecc2785cf216df0b594e399362550_2377219_79ace1de1262ccaca50c36919765adc8.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/25-11-6-remiseprix/20251106_113102_huf24c077dc91c32158394ad26baf1975d_3006845_da7173efebd640e8e9b9ef3fd4d542cb.webp 400w,
/post/25-11-6-remiseprix/20251106_113102_huf24c077dc91c32158394ad26baf1975d_3006845_8ed9c31f9d638599b6b31d5b9c5a3d20.webp 760w,
/post/25-11-6-remiseprix/20251106_113102_huf24c077dc91c32158394ad26baf1975d_3006845_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/25-11-6-remiseprix/20251106_113102_huf24c077dc91c32158394ad26baf1975d_3006845_da7173efebd640e8e9b9ef3fd4d542cb.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/25-11-6-remiseprix/20251106_113339_hu68ce77d73b5067fc42950121b5a8a6d6_1787352_d4d242bcf557a4829b2e5d6bbae8665c.webp 400w,
/post/25-11-6-remiseprix/20251106_113339_hu68ce77d73b5067fc42950121b5a8a6d6_1787352_9f5a9970e6f3574ed5c2ed5429bb9c50.webp 760w,
/post/25-11-6-remiseprix/20251106_113339_hu68ce77d73b5067fc42950121b5a8a6d6_1787352_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/25-11-6-remiseprix/20251106_113339_hu68ce77d73b5067fc42950121b5a8a6d6_1787352_d4d242bcf557a4829b2e5d6bbae8665c.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>R√©sultats du prix de th√®se du GdR et des associations AFIG et EGFR 2025</title><link>https://gdr-igrv.fr/post/25-07-10-prixthese/</link><pubDate>Sat, 14 Jun 2025 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/25-07-10-prixthese/</guid><description>&lt;p>&lt;strong>R√©sultats du prix de th√®se du GDR IG-RV 2025
en collaboration avec l‚ÄôAssociation Fran√ßaise d‚ÄôInformatique Graphique et le Chapitre Fran√ßais d‚ÄôEurographics.&lt;/strong>&lt;/p>
&lt;p>&lt;a href="http://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">Page des prix de th√®se pour plus de d√©tails sur les laur√©ats&lt;/a>&lt;/p>
&lt;p>Pour cette neuvieme √©dition, la participation au concours √©tait ouverte aux docteurs ayant soutenu leur th√®se entre le 01/01/2024 et le 31/12/2024. Il y a eu 12 soumissions, toutes d‚Äôun excellent niveau scientifique et couvrant largement les th√©matiques du GDR IG-RV. Le jury 2025 a √©t√© anim√© par Georges-Pierre Bonneau et Guillaume Cordonnier. Il √©tait compos√© de Rebecca Fribourg, Fanny Chevalier, Jean-Michel Dischler, Bruno Levy, Damien Rohmer et Eric Galin.
Le prix de th√®se du GDR IG-RV 2024 est d√©cern√© √† :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Cyprien Plateau-Holleville&lt;/strong> (XLIM, Universit√© de Limoges) pour sa th√®se intitul√©e ¬´ &lt;em>Construction efficace de g√©om√©trie pour l&amp;rsquo;analyse structurelle de grands syst√®mes mol√©culaires&lt;/em> ¬ª effectu√©e sous la direction de Maxime Maria et St√©phane M√©rillou&lt;/li>
&lt;/ul>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2025/CPH-prix-these.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://theses.hal.science/tel-04906696v1" target="_blank" rel="noopener">Th√®se&lt;/a>&lt;/p>
&lt;p>Avec deux accessits :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Souhaib Attaiki&lt;/strong> (Ecole Polytechnique) pour sa th√®se intitul√©e ¬´ &lt;em>Robust Deep Learning-based Methods for Non-Rigid Shape Correspondence&lt;/em> ¬ª effectu√©e sous la direction de Maks Ovsjanikov&lt;/li>
&lt;/ul>
&lt;!--
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2024/LoannGio_igrv_jfig_v3.mp4" type="video/mp4">
&lt;/video> -->
&lt;p>&lt;a href="https://theses.hal.science/tel-04956932v1" target="_blank" rel="noopener">Th√®se&lt;/a>&lt;/p>
&lt;p>&lt;strong>Antonin Cheymol&lt;/strong> (INSA Rennes) pour sa th√®se intitul√©e ¬´ &lt;em>Reshaping the virtual body‚Äôs appearance and movements : A contribution to the study of avatar alteration in virtual reality&lt;/em> ¬ª effectu√©e sous la direction de Ferran Argelaguet, Jean-Marie Normand, Anatole Lecuyer et Rebecca Fribourg.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2025/videoAntoninCheymol.mp4" type="video/mp4">
&lt;/video>
&lt;p>Nous tenons √† remercier l‚Äôensemble des candidats pour leur participation,&lt;/p></description></item><item><title>Prix de th√®se Gilles Kahn et prix de th√®se du GdR IG-RV 2024 ‚Äì F√©licitations aux laur√©ats !</title><link>https://gdr-igrv.fr/post/25-02-24-prix-gilles-kahn-news-cnrs/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/25-02-24-prix-gilles-kahn-news-cnrs/</guid><description>&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table des mati√®res&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#√©milie-yu-des-outils-pionniers-pour-la-cr√©ation-3d--prix-de-th√®se-gilles-kahn-2024">√âmilie Yu, des outils pionniers pour la cr√©ation 3D ‚Äì Prix de th√®se Gilles Kahn 2024&lt;/a>&lt;/li>
&lt;li>&lt;a href="#le-prix-de-th√®se-du-gdr-ig-rv-2024-et-la-mise-√†-lhonneur-dans-la-newsletter-cnrs">Le prix de th√®se du GdR IG-RV 2024 et la mise √† l&amp;rsquo;honneur dans la newsletter CNRS&lt;/a>&lt;/li>
&lt;li>&lt;a href="#julie-digne-√†-lhonneur-pour-ses-travaux-en-optimisation">Julie Digne √† l&amp;rsquo;honneur pour ses travaux en optimisation&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;h2 id="√©milie-yu-des-outils-pionniers-pour-la-cr√©ation-3d--prix-de-th√®se-gilles-kahn-2024">√âmilie Yu, des outils pionniers pour la cr√©ation 3D ‚Äì Prix de th√®se Gilles Kahn 2024&lt;/h2>
&lt;p>Le &lt;strong>prix de th√®se Gilles Kahn 2024&lt;/strong>, d√©cern√© par la &lt;strong>Soci√©t√© Informatique de France (SIF)&lt;/strong> et l&amp;rsquo;&lt;strong>Acad√©mie des Sciences&lt;/strong>, a √©t√© attribu√© √† &lt;strong>√âmilie Yu&lt;/strong> pour ses travaux en informatique graphique et en r√©alit√© virtuelle.&lt;/p>
&lt;p>Sa th√®se, intitul√©e &lt;em>Designing Tools for 3D Content Authoring Based on 3D Sketching&lt;/em>, explore la &lt;strong>cr√©ation, l‚Äô√©dition et l‚Äôanimation de formes tridimensionnelles √† partir d‚Äôesquisses&lt;/strong>. Alors que le dessin et les esquisses 2D sont des outils largement r√©pandus dans la cr√©ation graphique et le design industriel, proposer un √©quivalent en &lt;strong>dessin 3D&lt;/strong> accessible et intuitif repr√©sente un d√©fi majeur.&lt;/p>
&lt;p>Les recherches d‚Äô√âmilie Yu se basent sur les concepts de &lt;strong>¬´ coup de crayon 3D ¬ª&lt;/strong>, &lt;strong>¬´ esquisse 3D ¬ª&lt;/strong> et &lt;strong>¬´ couches d‚Äô√©dition 3D ¬ª&lt;/strong>, permettant aux graphistes et designers d‚Äôexprimer leurs id√©es en 3D aussi facilement qu‚Äôen 2D. Sa m√©thodologie, fond√©e sur des entretiens avec des professionnels du domaine, assure une forte &lt;strong>ad√©quation des outils d√©velopp√©s avec les besoins r√©els des cr√©ateurs&lt;/strong>.&lt;/p>
&lt;p>Ces travaux, r√©alis√©s sous la direction d‚Äô&lt;strong>Adrien Bousseau&lt;/strong> au sein de l‚Äô&lt;strong>√©quipe-projet GraphDeco&lt;/strong> du &lt;strong>Centre Inria d‚ÄôUniversit√© C√¥te d‚ÄôAzur&lt;/strong>, ont abouti √† un manuscrit &lt;strong>remarquablement didactique et agr√©able √† lire&lt;/strong>. Aujourd‚Äôhui, √âmilie Yu poursuit ses recherches en tant que &lt;strong>post-doctorante √† l‚ÄôExpressive Computation Lab de l‚ÄôUC Santa Barbara, Californie&lt;/strong>.&lt;/p>
&lt;p>Le jury du prix Gilles Kahn a soulign√© &lt;strong>la qualit√© exceptionnelle des r√©sultats obtenus, publi√©s au meilleur niveau international&lt;/strong>, ainsi que &lt;strong>la rigueur et l&amp;rsquo;approche utilisateur&lt;/strong> qui ont guid√© ses recherches.&lt;/p>
&lt;h2 id="le-prix-de-th√®se-du-gdr-ig-rv-2024-et-la-mise-√†-lhonneur-dans-la-newsletter-cnrs">Le prix de th√®se du GdR IG-RV 2024 et la mise √† l&amp;rsquo;honneur dans la newsletter CNRS&lt;/h2>
&lt;p>Le &lt;strong>GDR IG-RV&lt;/strong> (Informatique G√©om√©trique et Graphique, R√©alit√© Virtuelle et Visualisation) a d√©cern√© son &lt;strong>prix de th√®se 2024&lt;/strong> √† &lt;strong>√âmilie Yu&lt;/strong> pour ses recherches sur la conception d&amp;rsquo;outils de cr√©ation 3D bas√©s sur le dessin 3D. Ses travaux proposent des interactions innovantes pour permettre aux cr√©ateurs d‚Äôexploiter la spontan√©it√© et la pr√©cision du dessin dans des environnements tridimensionnels.&lt;/p>
&lt;p>En plus du prix principal, deux &lt;strong>accessits&lt;/strong> ont √©t√© attribu√©s :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Loann Giovannangeli&lt;/strong>, pour ses travaux sur l‚Äôutilisation de l‚Äôintelligence artificielle pour la g√©n√©ration et l‚Äô√©valuation de visualisations d‚Äôinformation, r√©alis√©s au &lt;strong>LaBRI ‚Äì Universit√© de Bordeaux&lt;/strong>.&lt;/li>
&lt;li>&lt;strong>Axel Paris&lt;/strong>, pour sa th√®se sur la &lt;strong>mod√©lisation et simulation des terrains virtuels&lt;/strong>, men√©e au &lt;strong>LIRIS ‚Äì Universit√© Claude Bernard Lyon 1&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;p>Le prix de th√®se du GdR IG-RV a √©t√© mis en avant dans la derni√®re &lt;strong>newsletter CNRS Sciences Informatiques&lt;/strong>, aux c√¥t√©s d‚Äôautres travaux de pointe en &lt;strong>cr√©ation num√©rique, intelligence artificielle et simulation de terrains&lt;/strong>.&lt;/p>
&lt;p>üîó &lt;a href="https://www.ins2i.cnrs.fr/fr/cnrsinfo/creation-numerique-et-ia-le-gdr-ig-rv-distingue-des-recherches-de-pointe-en-3d-ia-et" target="_blank" rel="noopener">Lire l&amp;rsquo;article sur le prix de th√®se du GdR IG-RV&lt;/a>&lt;br>
üîó &lt;a href="https://gdr-igrv.fr/post/24-06-14-prixthese/" target="_blank" rel="noopener">Annonce du prix de th√®se du GdR IG-RV sur le site du GdR&lt;/a>&lt;/p>
&lt;h2 id="julie-digne-√†-lhonneur-pour-ses-travaux-en-optimisation">Julie Digne √† l&amp;rsquo;honneur pour ses travaux en optimisation&lt;/h2>
&lt;p>La newsletter CNRS met √©galement en avant &lt;strong>Julie Digne&lt;/strong>, directrice de recherche au &lt;strong>LIRIS - CNRS/INSA de Lyon/Universit√© Claude Bernard Lyon 1&lt;/strong>, pour ses recherches en &lt;strong>traitement num√©rique de la g√©om√©trie et optimisation&lt;/strong>.&lt;/p>
&lt;p>L&amp;rsquo;optimisation joue un r√¥le cl√© dans ses travaux, notamment pour le &lt;strong>recalage de mod√®les sur des formes&lt;/strong>, une technique utilis√©e pour estimer la posture d&amp;rsquo;√™tres humains ou d&amp;rsquo;objets scann√©s. Elle d√©veloppe des m√©thodes sp√©cifiques permettant &lt;strong>d&amp;rsquo;effectuer des calculs efficaces sur des donn√©es g√©om√©triques complexes&lt;/strong>.&lt;/p>
&lt;p>Dans ses recherches r√©centes, elle s&amp;rsquo;est int√©ress√©e aux &lt;strong>probl√®mes pos√©s par l‚Äôapprentissage automatique appliqu√© aux donn√©es g√©om√©triques&lt;/strong>, qui n√©cessitent des approches d‚Äôoptimisation adapt√©es du fait de la difficult√© √† repr√©senter des surfaces g√©om√©triques sous forme de grilles.&lt;/p>
&lt;p>√Ä l‚Äôavenir, elle souhaite explorer des &lt;strong>applications low tech&lt;/strong>, notamment le d√©veloppement de &lt;strong>r√©seaux de neurones tr√®s l√©gers&lt;/strong> pouvant √™tre utilis√©s pour des t√¢ches d‚Äôanalyse de formes tout en limitant les ressources de calcul n√©cessaires.&lt;/p>
&lt;p>üîó &lt;a href="https://www.ins2i.cnrs.fr/fr/cnrsinfo/optimisation-conversation-avec-julie-digne" target="_blank" rel="noopener">Lire l&amp;rsquo;article sur Julie Digne dans la newsletter CNRS&lt;/a>&lt;/p>
&lt;p>Ces distinctions t√©moignent de l&amp;rsquo;excellence et de la diversit√© des recherches men√©es en informatique au sein de la communaut√© scientifique.&lt;/p>
&lt;p>F√©licitations √† &lt;strong>√âmilie Yu, Julie Digne, Loann Giovannangeli, Axel Paris et tous les laur√©ats&lt;/strong> pour ces contributions remarquables.&lt;/p></description></item><item><title>Retour mobilit√©s inter-laboratoires 2023</title><link>https://gdr-igrv.fr/post/24-06-24-retours-mobilites/</link><pubDate>Mon, 29 Jul 2024 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/24-06-24-retours-mobilites/</guid><description>&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table des mati√®res&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>
&lt;ul>
&lt;li>&lt;a href="#thierry-bay--ceramaths-hauts-de-france--irit-toulouse-et-xlim-poitiers--2023">Thierry Bay ‚Äì CERAMATHS (Hauts-de-France) / IRIT (Toulouse) et XLIM (Poitiers) ‚Äì 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#deise-santana--cristal-lille--esiee-paris--2023">Deise Santana ‚Äì CRIStAL (Lille) / ESIEE (Paris) ‚Äì 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#marc-hartley--lirmm-montpellier--esiee-paris--2023">Marc Hartley ‚Äì LIRMM (Montpellier) / ESIEE (Paris) ‚Äì 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#romain-pascual--mics-centralesup√©lec--liris-lyon--22-24-mai-2023">Romain Pascual ‚Äì MICS (CentraleSup√©lec) / LIRIS (Lyon) ‚Äì 22-24 mai 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#flavien-l√©cuyer---icube-strasbourg--inria-rennes--2023">Flavien L√©cuyer - ICube (Strasbourg) / Inria (Rennes) ‚Äì 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#cl√©ment-poull---lib-dijon--xlim-poitiers---d√©cembre-2023">Cl√©ment Poull - LIB (Dijon) / XLIM (Poitiers) - D√©cembre 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#julien-mendes-forte---greyc-caen--ligm-champs-sur-marne---20-24-novembre-2023">Julien Mendes Forte - GREYC (Caen) / LIGM (Champs-sur-Marne) - 20-24 novembre 2023&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;p>&lt;em>L&amp;rsquo;action de mobilit√© entre laboratoires fran√ßais via le financement de court s√©jour d&amp;rsquo;un doctorant ou d&amp;rsquo;un enseignant-chercheur/chercheur du GdR a permis la r√©alisation de 7 mobilit√©s en 2023.&lt;/em>&lt;/p>
&lt;h3 id="thierry-bay--ceramaths-hauts-de-france--irit-toulouse-et-xlim-poitiers--2023">Thierry Bay ‚Äì CERAMATHS (Hauts-de-France) / IRIT (Toulouse) et XLIM (Poitiers) ‚Äì 2023&lt;/h3>
&lt;figure id="figure-courbes-alg√©briques-trigonom√©triques-√†-hodographe-pythagorien-atph-surface-trigonom√©trique-√†-partir-de-laquelle-les-donn√©es-ont-√©t√©-√©chantillonn√©es-et-la-courbe-atph-spatiale-reconstruite">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Courbes Alg√©briques Trigonom√©triques √† Hodographe Pythagorien (ATPH): surface trigonom√©trique √† partir de laquelle les donn√©es ont √©t√© √©chantillonn√©es et la courbe ATPH spatiale reconstruite." srcset="
/post/24-06-24-retours-mobilites/thierry1_hu2495901ea778ed007616ceb7e6a997b8_103438_7e15659fdc57dab0c67ae6dae12d08ae.webp 400w,
/post/24-06-24-retours-mobilites/thierry1_hu2495901ea778ed007616ceb7e6a997b8_103438_ac6bf73083a92f0d4651c10dc18f5b88.webp 760w,
/post/24-06-24-retours-mobilites/thierry1_hu2495901ea778ed007616ceb7e6a997b8_103438_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/thierry1_hu2495901ea778ed007616ceb7e6a997b8_103438_7e15659fdc57dab0c67ae6dae12d08ae.webp"
width="620"
height="530"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Courbes Alg√©briques Trigonom√©triques √† Hodographe Pythagorien (ATPH): surface trigonom√©trique √† partir de laquelle les donn√©es ont √©t√© √©chantillonn√©es et la courbe ATPH spatiale reconstruite.
&lt;/figcaption>&lt;/figure>
&lt;p>Thierry Bay, du D√©partement Math√©matiques du CERAMATHS √† Valenciennes, a r√©alis√© une mobilit√© inter-laboratoires pour collaborer avec Laura Saini (CERAMATHS), G√©raldine Morin (IRIT, Toulouse), et Samuel Peltier (XLIM, Poitiers). L&amp;rsquo;objectif √©tait d&amp;rsquo;utiliser les courbes Alg√©briques Trigonom√©triques √† Hodographe Pythagorien (ATPH) pour d√©velopper des mod√®les 3D √† partir de squelettes.&lt;/p>
&lt;p>Les courbes ATPH permettent de mod√©liser pr√©cis√©ment des formes circulaires et leurs offsets, offrant une repr√©sentation param√©trique exacte. Le projet a d√©but√© par la cr√©ation de formes 2D param√©tr√©es par des courbes ATPH, permettant de calculer explicitement la longueur d&amp;rsquo;arc. Ensuite, l&amp;rsquo;√©quipe a √©tendu ces travaux en 3D et aux surfaces, en utilisant des espaces alg√©briques trigonom√©triques.&lt;/p>
&lt;p>La mission a permis de renforcer les collaborations existantes, d&amp;rsquo;explorer de nouvelles m√©thodes de mod√©lisation g√©om√©trique, et de poser les bases pour des g√©n√©ralisations futures des mod√®les splines, polynomiaux et ATPH.&lt;/p>
&lt;h3 id="deise-santana--cristal-lille--esiee-paris--2023">Deise Santana ‚Äì CRIStAL (Lille) / ESIEE (Paris) ‚Äì 2023&lt;/h3>
&lt;figure id="figure-illustration-dun-image-de-son-gradient-et-de-diverses-cartes-de-saillance-et-de-partitions-bas√©es-sur-les-bassins-versants-hi√©rarchiques-et-les-attributs-de-circularit√©">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Illustration d&amp;#39;un image, de son gradient, et de diverses cartes de saillance et de partitions bas√©es sur les bassins versants hi√©rarchiques et les attributs de circularit√©" srcset="
/post/24-06-24-retours-mobilites/deise1_hu78911f42bd5b19a46799146f0717a3ae_963130_9990ce655ca72d61bb29865e275284d3.webp 400w,
/post/24-06-24-retours-mobilites/deise1_hu78911f42bd5b19a46799146f0717a3ae_963130_e71e20de5cbb335dfcf0252a53fdb9f7.webp 760w,
/post/24-06-24-retours-mobilites/deise1_hu78911f42bd5b19a46799146f0717a3ae_963130_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/deise1_hu78911f42bd5b19a46799146f0717a3ae_963130_9990ce655ca72d61bb29865e275284d3.webp"
width="760"
height="521"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Illustration d&amp;rsquo;un image, de son gradient, et de diverses cartes de saillance et de partitions bas√©es sur les bassins versants hi√©rarchiques et les attributs de circularit√©
&lt;/figcaption>&lt;/figure>
&lt;p>Deise Santana, chercheuse en informatique √† l‚Äôuniversit√© de Lille et membre du laboratoire CRIStAL (UMR 9189), a effectu√© une mission de deux semaines √† ESIEE Paris pour collaborer sur un projet de recherche portant sur le calcul des lignes de partage des eaux hi√©rarchiques dans le cadre de graphes pond√©r√©s.&lt;/p>
&lt;h3 id="marc-hartley--lirmm-montpellier--esiee-paris--2023">Marc Hartley ‚Äì LIRMM (Montpellier) / ESIEE (Paris) ‚Äì 2023&lt;/h3>
&lt;figure id="figure-environnement-sous-marins-simul√©s-virtual-worlds-for-testing-robot-navigation-a-study-on-the-difficulty-level-thierry-sotiropoulos-j√©r√©mie-guiochet-f√©lix-ingrand-h√©l√®ne-waeselynck-in-proceedings-of-the-european-dependable-computing-conference-edcc-2016">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Environnement sous-marins simul√©s *Virtual Worlds for Testing Robot Navigation: a Study on the Difficulty Level. Thierry Sotiropoulos, J√©r√©mie Guiochet, F√©lix Ingrand, H√©l√®ne Waeselynck. In Proceedings of the European Dependable Computing Conference (EDCC 2016).*" srcset="
/post/24-06-24-retours-mobilites/marc1_hu81caa448037adfc8e271a9be0543be2e_101753_916adbc22c9b7020d9145c6c78610981.webp 400w,
/post/24-06-24-retours-mobilites/marc1_hu81caa448037adfc8e271a9be0543be2e_101753_07d29c46948e847ffade6b6faaeba789.webp 760w,
/post/24-06-24-retours-mobilites/marc1_hu81caa448037adfc8e271a9be0543be2e_101753_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/marc1_hu81caa448037adfc8e271a9be0543be2e_101753_916adbc22c9b7020d9145c6c78610981.webp"
width="760"
height="262"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Environnement sous-marins simul√©s &lt;br>&lt;em>Virtual Worlds for Testing Robot Navigation: a Study on the Difficulty Level. Thierry Sotiropoulos, J√©r√©mie Guiochet, F√©lix Ingrand, H√©l√®ne Waeselynck. In Proceedings of the European Dependable Computing Conference (EDCC 2016).&lt;/em>
&lt;/figcaption>&lt;/figure>
&lt;p>Marc Hartley, doctorant au LIRMM √† Montpellier, a r√©alis√© une mission de recherche √† ESIEE Paris, portant sur le d√©veloppement d&amp;rsquo;un simulateur d&amp;rsquo;environnements sous-marins. Ce projet international et interdisciplinaire vise √† √©valuer et am√©liorer les protocoles d&amp;rsquo;observation de la biodiversit√© et √† valider des syst√®mes robotiques sous-marins.&lt;/p>
&lt;p>Durant son s√©jour, Marc Hartley a collabor√© avec les chercheurs d&amp;rsquo;ESIEE Paris pour avancer sur la g√©n√©ration proc√©durale d&amp;rsquo;environnements sous-marins. Son travail a port√© sur la cr√©ation de fonds marins, adapt√©s aux sc√©narios de validation des missions robotiques. Il a particuli√®rement explor√© la mod√©lisation des bordures d&amp;rsquo;√Æles coralliennes et des r√©seaux karstiques.&lt;/p>
&lt;p>La mission a permis de d√©velopper des m√©thodes proc√©durales contr√¥lables pour g√©n√©rer des environnements r√©alistes, int√©grant des obstacles et des caract√©ristiques topologiques sp√©cifiques.&lt;/p>
&lt;h3 id="romain-pascual--mics-centralesup√©lec--liris-lyon--22-24-mai-2023">Romain Pascual ‚Äì MICS (CentraleSup√©lec) / LIRIS (Lyon) ‚Äì 22-24 mai 2023&lt;/h3>
&lt;figure id="figure-g-carte-associ√©e-√†-un-objet-g√©om√©trique-romain-pascual-pascale-le-gall-hakim-belhaouari-agn√®s-arnould-une-approche-pour-inf√©rer-les-expressions-de-calcul-g√©om√©trique-en-mod√©lisation-√†-base-topologique-22√®me-journ√©es-des-approches-formelles-dans-lassistance-au-d√©veloppement-de-logiciels-afadl23-jun-2023-rennes-france">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="G-carte associ√©e √† un objet g√©om√©trique *Romain Pascual, Pascale Le Gall, Hakim Belhaouari, Agn√®s Arnould. Une approche pour inf√©rer les expressions de calcul g√©om√©trique en mod√©lisation √† base topologique. 22√®me Journ√©es des Approches Formelles dans l‚ÄôAssistance au D√©veloppement de Logiciels, AFADL‚Äô23., Jun 2023, Rennes, France.*" srcset="
/post/24-06-24-retours-mobilites/romain1_hudec8a329174fc37849e265970269706a_52664_94624722607d55fd92a89dc65a4344d3.webp 400w,
/post/24-06-24-retours-mobilites/romain1_hudec8a329174fc37849e265970269706a_52664_986e88e6ab2851638931e8d3f2020bd0.webp 760w,
/post/24-06-24-retours-mobilites/romain1_hudec8a329174fc37849e265970269706a_52664_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/romain1_hudec8a329174fc37849e265970269706a_52664_94624722607d55fd92a89dc65a4344d3.webp"
width="760"
height="159"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
G-carte associ√©e √† un objet g√©om√©trique &lt;br>&lt;em>Romain Pascual, Pascale Le Gall, Hakim Belhaouari, Agn√®s Arnould. Une approche pour inf√©rer les expressions de calcul g√©om√©trique en mod√©lisation √† base topologique. 22√®me Journ√©es des Approches Formelles dans l‚ÄôAssistance au D√©veloppement de Logiciels, AFADL‚Äô23., Jun 2023, Rennes, France.&lt;/em>
&lt;/figcaption>&lt;/figure>
&lt;p>Romain Pascual, ATER au laboratoire MICS de CentraleSup√©lec, a effectu√© une mission de trois jours au LIRIS de Lyon afin d&amp;rsquo;initier une collaboration autour de l&amp;rsquo;utilisation de signatures topologiques pour des op√©rations d&amp;rsquo;√©dition de maillages volumiques.&lt;/p>
&lt;p>Durant son s√©jour, Romain Pascual a travaill√© √©troitement avec Guillaume Damiand et Vincent Nivoliers du LIRIS. Leur objectif commun √©tait d&amp;rsquo;explorer l&amp;rsquo;application des techniques de r√©√©criture de graphes pour la mod√©lisation g√©om√©trique, en s&amp;rsquo;inspirant des m√©thodes de cherche-remplace sur les cartes combinatoires d√©velopp√©es par leurs homologues lyonnais.&lt;/p>
&lt;p>Cette collaboration a permis de poser les bases d&amp;rsquo;un projet visant √† √©tendre la repr√©sentation des signatures de la m√©thode cherche-remplace en int√©grant des id√©es issues des techniques de r√©√©criture. L&amp;rsquo;approche propos√©e cherche √† appliquer cette m√©thode √† plusieurs cellules topologiques, ouvrant ainsi de nouvelles perspectives pour la mod√©lisation g√©om√©trique bas√©e sur des graphes.&lt;/p>
&lt;h3 id="flavien-l√©cuyer---icube-strasbourg--inria-rennes--2023">Flavien L√©cuyer - ICube (Strasbourg) / Inria (Rennes) ‚Äì 2023&lt;/h3>
&lt;figure id="figure-environnement-virtuel-pour-une-th√©rapie-en-r√©alit√©-virtuelle-thomas-lehoux-christelle-nithart-porche-antonio-capobianco-miguel-gervilla-flavien-lecuyer-et-al-towards-virtual-reality-exposure-therapy-for-cocaine-use-disorder-a-feasibility-study-of-inducing-cocaine-craving-through-virtual-reality-addictive-behaviors-reports-2024-19-pp100549">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Environnement virtuel pour une th√©rapie en R√©alit√© Virtuelle *Thomas Lehoux, Christelle Nithart Porche, Antonio Capobianco, Miguel Gervilla, Flavien Lecuyer, et al.. Towards virtual reality exposure therapy for cocaine use disorder: A feasibility study of inducing cocaine craving through virtual reality. Addictive Behaviors Reports, 2024, 19, pp.100549.*" srcset="
/post/24-06-24-retours-mobilites/flavien1_hu6a0621bc777fb7a9da9ff6d21ac20822_66069_a45d3433a171ede714a77230e2f0d486.webp 400w,
/post/24-06-24-retours-mobilites/flavien1_hu6a0621bc777fb7a9da9ff6d21ac20822_66069_6659d451b3092652cb9e7d0b65791aef.webp 760w,
/post/24-06-24-retours-mobilites/flavien1_hu6a0621bc777fb7a9da9ff6d21ac20822_66069_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/flavien1_hu6a0621bc777fb7a9da9ff6d21ac20822_66069_a45d3433a171ede714a77230e2f0d486.webp"
width="760"
height="323"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Environnement virtuel pour une th√©rapie en R√©alit√© Virtuelle &lt;br>&lt;em>Thomas Lehoux, Christelle Nithart Porche, Antonio Capobianco, Miguel Gervilla, Flavien Lecuyer, et al.. Towards virtual reality exposure therapy for cocaine use disorder: A feasibility study of inducing cocaine craving through virtual reality. Addictive Behaviors Reports, 2024, 19, pp.100549.&lt;/em>
&lt;/figcaption>&lt;/figure>
&lt;p>Dans le cadre de leurs travaux sur l&amp;rsquo;influence des √©motions sur le sentiment d&amp;rsquo;incarnation en r√©alit√© virtuelle, les chercheurs de Strasbourg ont initi√© une collaboration avec l&amp;rsquo;√©quipe Hybrid de l&amp;rsquo;INRIA Rennes. Cette mission a impliqu√© Flavien L√©cuyer, jeune ma√Ætre de conf√©rences, et Benjamin Freeling, doctorant, dans le but de d√©finir les contours d&amp;rsquo;une √©tude conjointe.&lt;/p>
&lt;p>Pendant leur visite √† Rennes, les chercheurs ont rencontr√© Ferran Argelaguet et discut√© des recherches compl√©mentaires men√©es au laboratoire IRISA/Inria Rennes. Ensemble, ils ont explor√© les facteurs permettant l&amp;rsquo;incarnation des avatars virtuels et ont envisag√© des solutions innovantes pour am√©liorer les simulations de r√©alit√© virtuelle. Cette collaboration vise √† comparer le sentiment d&amp;rsquo;incarnation dans des contextes applicatifs similaires, en utilisant des casques de r√©alit√© virtuelle standard et un environnement de type CAVE, tel que celui de la plateforme Immersia.&lt;/p>
&lt;p>Les discussions ont mis en lumi√®re le potentiel de l&amp;rsquo;analyse en temps r√©el de l&amp;rsquo;implication √©motionnelle des utilisateurs, offrant ainsi de nouvelles perspectives pour √©valuer l&amp;rsquo;incarnation virtuelle. Cette approche pourrait surmonter les limites des questionnaires post-exp√©rience actuellement utilis√©s pour mesurer l&amp;rsquo;incarnation virtuelle.&lt;/p>
&lt;h3 id="cl√©ment-poull---lib-dijon--xlim-poitiers---d√©cembre-2023">Cl√©ment Poull - LIB (Dijon) / XLIM (Poitiers) - D√©cembre 2023&lt;/h3>
&lt;figure id="figure-rendu-de-sph√®res-en-verre-grav√©-globe-en-m√©tal-milieu-et-en-verre-droite-scintillants-walter-b-marschner-sr-li-h-torrance-ke-microfacet-models-for-refraction-through-rough-surfaces-egsr-2007-pp-195206-and-chermain-x-sauvage-b-dischler-j-m-dachsbacher-c-importance-sampling-of-glittering-bsdfs-based-on-finite-mixture-distributions-egsr-2021">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Rendu de sph√®res en verre grav√© (globe), en m√©tal (milieu) et en verre (droite) scintillants. *Walter B., Marschner S.R., Li H., Torrance K.E.: Microfacet models for refraction through rough surfaces (EGSR 2007, pp. 195‚Äì206)* and *Chermain X., Sauvage B., Dischler J.-M., Dachsbacher C.: Importance sampling of glittering BSDFs based on finite mixture distributions. (EGSR 2021)*" srcset="
/post/24-06-24-retours-mobilites/clement1_huf9a5e1308a8a8fed9144796e965c919d_558143_ecb363e3142dccb22a28a87b11a7e340.webp 400w,
/post/24-06-24-retours-mobilites/clement1_huf9a5e1308a8a8fed9144796e965c919d_558143_b11df375001e27658177c2bc6fa599ed.webp 760w,
/post/24-06-24-retours-mobilites/clement1_huf9a5e1308a8a8fed9144796e965c919d_558143_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/clement1_huf9a5e1308a8a8fed9144796e965c919d_558143_ecb363e3142dccb22a28a87b11a7e340.webp"
width="760"
height="259"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Rendu de sph√®res en verre grav√© (globe), en m√©tal (milieu) et en verre (droite) scintillants. &lt;br>&lt;em>Walter B., Marschner S.R., Li H., Torrance K.E.: Microfacet models for refraction through rough surfaces (EGSR 2007, pp. 195‚Äì206)&lt;/em> and &lt;em>Chermain X., Sauvage B., Dischler J.-M., Dachsbacher C.: Importance sampling of glittering BSDFs based on finite mixture distributions. (EGSR 2021)&lt;/em>
&lt;/figcaption>&lt;/figure>
&lt;p>Cl√©ment Poull, doctorant au sein de l&amp;rsquo;√©quipe Mod√©lisation G√©om√©trique (MG) du Laboratoire d&amp;rsquo;Informatique de Bourgogne (LIB), a effectu√© une mobilit√© d&amp;rsquo;une semaine en d√©cembre 2023 √† l&amp;rsquo;√©quipe Informatique Graphique (IG) du laboratoire XLIM √† Poitiers. Cette mobilit√© s&amp;rsquo;inscrit dans le cadre du projet ANR JCJC FRACLETTES, dont l&amp;rsquo;objectif est la repr√©sentation, l&amp;rsquo;analyse et la caract√©risation de surfaces rugueuses pour la simulation num√©rique.&lt;/p>
&lt;p>Les objectifs de cette mobilit√© √©taient de formaliser les discussions entre les √©quipes MG et IG sur l&amp;rsquo;utilisation de mod√®les fractals pour la simulation d&amp;rsquo;√©clairage et de pr√©parer un travail de fond sur le contr√¥le de la distribution des normales aux microfacettes pour la plausibilit√© physique des calculs de simulation d‚Äô√©clairage.&lt;/p>
&lt;p>Cl√©ment Poull travaille sur la d√©finition d&amp;rsquo;un mod√®le math√©matique fractal d√©terministe pour le contr√¥le g√©om√©trique de la rugosit√©. L&amp;rsquo;√©quipe IG du XLIM s&amp;rsquo;int√©resse √† la repr√©sentation, la synth√®se et l&amp;rsquo;animation de structures g√©om√©triques complexes, ainsi qu&amp;rsquo;√† la gestion de leur apparence en simulation d‚Äô√©clairage. Les mod√®les fractals d√©velopp√©s par Cl√©ment Poull pourraient √™tre utilis√©s pour contr√¥ler la distribution des normales aux microfacettes, am√©liorant ainsi le r√©alisme des simulations d&amp;rsquo;√©clairage.&lt;/p>
&lt;h3 id="julien-mendes-forte---greyc-caen--ligm-champs-sur-marne---20-24-novembre-2023">Julien Mendes Forte - GREYC (Caen) / LIGM (Champs-sur-Marne) - 20-24 novembre 2023&lt;/h3>
&lt;figure id="figure-analyse-topologique-dune-image-f-et-ses-ensembles-de-seuils-o√π-les-arbres-des-formes-et-les-arbres-topologiques-des-formes-repr√©sentent-les-relations-dinclusion-et-dimbrication-des-composantes-connexes-des-seuils-de-f">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Analyse topologique d&amp;#39;une image F et ses ensembles de seuils, o√π les arbres des formes et les arbres topologiques des formes repr√©sentent les relations d&amp;#39;inclusion et d&amp;#39;imbrication des composantes connexes des seuils de F" srcset="
/post/24-06-24-retours-mobilites/julien1_hua2bb820b2a25709951d08af30cb1c715_61928_209c210ea143c9c671a354abf859b106.webp 400w,
/post/24-06-24-retours-mobilites/julien1_hua2bb820b2a25709951d08af30cb1c715_61928_e2bf4ab7e5d0b11b90410022b20d33e3.webp 760w,
/post/24-06-24-retours-mobilites/julien1_hua2bb820b2a25709951d08af30cb1c715_61928_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/julien1_hua2bb820b2a25709951d08af30cb1c715_61928_209c210ea143c9c671a354abf859b106.webp"
width="760"
height="393"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Analyse topologique d&amp;rsquo;une image F et ses ensembles de seuils, o√π les arbres des formes et les arbres topologiques des formes repr√©sentent les relations d&amp;rsquo;inclusion et d&amp;rsquo;imbrication des composantes connexes des seuils de F
&lt;/figcaption>&lt;/figure>
&lt;p>Julien Mendes Forte, doctorant au sein de l&amp;rsquo;√©quipe Image du laboratoire GREYC √† Caen, a effectu√© une mobilit√© au Laboratoire d‚ÄôInformatique Gaspard Monge (LIGM) √† Champs-sur-Marne du 20 au 24 novembre 2023. Il a √©t√© accueilli par l&amp;rsquo;√©quipe A3SI pour travailler sur le sujet de l&amp;rsquo;Arbre Topologique des Formes (ATdF).&lt;/p>
&lt;p>Les objectifs de cette mobilit√© √©taient de discuter avec Benjamin Perret, d√©veloppeur de la biblioth√®que Higra, de l&amp;rsquo;int√©gration de l&amp;rsquo;ATdF dans la biblioth√®que et d&amp;rsquo;explorer l&amp;rsquo;utilisation de l&amp;rsquo;ATdF comme moyen de guider l&amp;rsquo;apprentissage des r√©seaux de neurones gr√¢ce √† la d√©finition d‚Äôune fonction de perte bas√©e sur la structure.&lt;/p>
&lt;p>Julien Mendes Forte travaille sur l&amp;rsquo;analyse structurelle d&amp;rsquo;images pour l&amp;rsquo;extraction et la mesure de l&amp;rsquo;information topologique. Il a notamment d√©velopp√© un nouveau descripteur topologique d&amp;rsquo;images bas√© sur l&amp;rsquo;ATdF. L&amp;rsquo;int√©gration de l&amp;rsquo;ATdF dans la biblioth√®que Higra permettrait de diffuser cet outil et de faciliter son utilisation. L&amp;rsquo;utilisation de l&amp;rsquo;ATdF pour guider l&amp;rsquo;apprentissage des r√©seaux de neurones est une piste prometteuse pour am√©liorer la pr√©cision des segmentations d&amp;rsquo;images.&lt;/p></description></item><item><title>R√©sultats du prix de th√®se du GdR et des associations AFIG et EGFR 2024</title><link>https://gdr-igrv.fr/post/24-06-14-prixthese/</link><pubDate>Fri, 14 Jun 2024 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/24-06-14-prixthese/</guid><description>&lt;p>&lt;strong>R√©sultats du prix de th√®se du GDR IG-RV 2024
en collaboration avec l‚ÄôAssociation Fran√ßaise d‚ÄôInformatique Graphique et le Chapitre Fran√ßais d‚ÄôEurographics.&lt;/strong>&lt;/p>
&lt;p>&lt;a href="http://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">Page des prix de th√®se pour plus de d√©tails sur les laur√©ats&lt;/a>&lt;/p>
&lt;p>Pour cette huiti√®me √©dition, la participation au concours √©tait ouverte aux docteurs ayant soutenu leur th√®se entre le 01/01/2023 et le 31/12/2023. Il y a eu 12 soumissions, toutes d‚Äôun excellent niveau scientifique et couvrant largement les th√©matiques du GDR IG-RV. Cette ann√©e, le jury 2024 a √©t√© anim√© par Georges-Pierre Bonneau et Guillaume Cordonnier. Il √©tait compos√© de Yvonne Jansen, Jean-Michel Dischler, Bruno Levy, Damien Rohmer, Eric Gali et Daniel Mestre.&lt;/p>
&lt;p>Le prix de th√®se du GDR IG-RV 2024 est d√©cern√© √† :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Emilie Yu&lt;/strong> (Inria, Universit√© C√¥te d‚ÄôAzur) pour sa th√®se intitul√©e ¬´ Conception d‚Äôoutils de creÃÅation de contenu 3D baseÃÅs sur le dessin 3D ¬ª effectu√©e sous la direction de Adrien Bousseau.&lt;/li>
&lt;/ul>
&lt;p>Avec deux accessits :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Loann Giovannangeli&lt;/strong> (Universit√© de Bordeaux) pour sa th√®se intitul√©e ¬´ G√©n√©ration et √âvaluation de Visualisations avec des techniques d‚ÄôApprentissage Automatique ¬ª effectu√©e sous la direction de Romain Bourqui.&lt;/li>
&lt;li>&lt;strong>Axel Paris&lt;/strong> (Universit√© de Lyon) pour sa th√®se intitul√©e ¬´ Modeling and simulating virtual terrains ¬ª effectu√©e sous la direction de Eric Galin et Eric Gu√©rin.&lt;/li>
&lt;/ul>
&lt;p>Nous tenons √† remercier l‚Äôensemble des candidats pour leur participation,&lt;/p>
&lt;p>Bien cordialement&lt;/p>
&lt;p>Les animateurs du prix de th√®se 2024,
Guillaume Cordonnier et Georges-Pierre Bonneau&lt;/p></description></item><item><title>R√©sultats du prix de th√®se du GdR et des associations AFIG et EGFR 2023</title><link>https://gdr-igrv.fr/post/08-11-2023-prixthese/</link><pubDate>Tue, 07 Nov 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/08-11-2023-prixthese/</guid><description>&lt;p>&lt;strong>R√©sultats du prix de th√®se du GDR IG-RV 2023
en collaboration avec l‚ÄôAssociation Fran√ßaise d‚ÄôInformatique Graphique et le Chapitre Fran√ßais d‚ÄôEurographics.&lt;/strong>&lt;/p>
&lt;p>&lt;a href="http://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">Page des prix de th√®se pour plus de d√©tails sur les laur√©ats&lt;/a>&lt;/p>
&lt;p>Pour cette septi√®me √©dition, la participation au concours √©tait ouverte aux docteurs ayant soutenu leur th√®se entre le 01/01/2022 et le 31/12/2022. Il y a eu 13 soumissions, toutes d‚Äôun excellent niveau scientifique et couvrant largement les th√©matiques du GDR IG-RV. Cette ann√©e, le jury de s√©lection a √©t√© anim√© par Guillaume Cordonnier et Lo√Øc Barthe et il √©tait compos√© de Florence Bertails-Descoubes, Bruno Levy, Tamy Boubekeur, Eric Galin, Yvonne Jansen et Daniel Mestre.&lt;/p>
&lt;p>Le prix de th√®se du GDR IG-RV 2023 est d√©cern√© √† :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Thibault Tricard&lt;/strong> (Inria, Universit√© de Lorraine) pour sa th√®se intitul√©e ¬´ Procedural noises for the design of small-scale structures in Additive Manufacturing ¬ª effectu√©e sous la direction de Sylvain Lefebvre et Didier Rouxel.&lt;/li>
&lt;/ul>
&lt;p>Deux accessit ont aussi √©t√© d√©cern√©s √† :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Anne-Laure Guinet&lt;/strong> (Universit√© Evry-Paris-Saclay) pour sa th√®se intitul√©e ¬´ Retours sensoriels multimodaux en r√©alit√© augment√©e pour la r√©√©ducation de la marche des enfants atteints de paralysie c√©r√©brale ¬ª effectu√©e sous la direction de Samir Otmane, Guillaume Bouyer et de Eric Desailly.&lt;/li>
&lt;li>&lt;strong>Fran√ßois Protais&lt;/strong> (Inria, Universit√© de Lorraine) pour sa th√®se intitul√©e ¬´ Maillage √† dominante Polycube ¬ª effectu√©e sous la direction de Dmitry Sokolov et Franck Ledoux.&lt;/li>
&lt;/ul>
&lt;p>Le prix de th√®se sera remis √† l&amp;rsquo;occasion des Journ√©es Fran√ßaises de l&amp;rsquo;Informatique Graphique, les 8-10 novembre √† Montpellier.&lt;/p>
&lt;p>Nous tenons √† remercier l‚Äôensemble des candidats pour leur participation,&lt;/p>
&lt;p>Bien cordialement&lt;/p>
&lt;p>Les animateurs du prix de th√®se 2023,
Guillaume Cordonnier et Lo√Øc Barthe&lt;/p></description></item><item><title>Des contributions fran√ßaises √† SIGGRAPH 2023</title><link>https://gdr-igrv.fr/post/23-07-31-siggraph2023/</link><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/23-07-31-siggraph2023/</guid><description>&lt;p>N&amp;rsquo;h√©sitez pas √† nous signaler tout oubli.&lt;/p>
&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table des mati√®res&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#building-a-virtual-weakly-compressible-wind-tunnel-testing-facility">Building a Virtual Weakly-compressible Wind Tunnel Testing Facility&lt;/a>&lt;/li>
&lt;li>&lt;a href="#patternshop-editing-point-patterns-by-image-manipulation">Patternshop: Editing Point Patterns by Image Manipulation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#a-sparse-non-parametric-brdf-model">A Sparse Non-parametric BRDF Model&lt;/a>&lt;/li>
&lt;li>&lt;a href="#videodoodles-hand-drawn-animations-on-videos-with-scene-aware-canvases">VideoDoodles: Hand-drawn Animations on Videos With Scene-aware Canvases&lt;/a>&lt;/li>
&lt;li>&lt;a href="#large-scale-terrain-authoring-through-interactive-erosion-simulation">Large-scale Terrain Authoring Through Interactive Erosion Simulation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#forming-terrains-by-glacial-erosion">Forming Terrains by Glacial Erosion&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contesse-accurate-occluding-contours-for-subdivision-surfaces">ConTesse: Accurate Occluding Contours for Subdivision Surfaces&lt;/a>&lt;/li>
&lt;li>&lt;a href="#polynomial-2d-green-coordinates-for-polygonal-cages">Polynomial 2D Green Coordinates for Polygonal Cages&lt;/a>&lt;/li>
&lt;li>&lt;a href="#orientable-dense-cyclic-infill-for-anisotropic-appearance-fabrication">Orientable Dense Cyclic Infill for Anisotropic Appearance Fabrication&lt;/a>&lt;/li>
&lt;li>&lt;a href="#complex-wrinkle-field-evolution">Complex Wrinkle Field Evolution&lt;/a>&lt;/li>
&lt;li>&lt;a href="#coupling-conduction-convection-and-radiative-transfer-in-a-single-path-space-application-to-infrared-rendering">Coupling Conduction, Convection and Radiative Transfer in a Single Path-Space: Application to Infrared Rendering&lt;/a>&lt;/li>
&lt;li>&lt;a href="#textured-mesh-quality-assessment-large-scale-dataset-and-deep-learning-based-quality-metric">Textured Mesh Quality Assessment: Large-scale Dataset and Deep Learning-based Quality Metric&lt;/a>&lt;/li>
&lt;li>&lt;a href="#variational-shape-reconstruction-via-quadric-error-metrics">Variational Shape Reconstruction via Quadric Error Metrics&lt;/a>&lt;/li>
&lt;li>&lt;a href="#somigliana-coordinates-an-elasticity-derived-approach-for-cage-deformation">Somigliana Coordinates: An Elasticity-derived Approach for Cage Deformation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#constraint-based-simulation-of-passive-suction-cups">Constraint-based Simulation of Passive Suction Cups&lt;/a>&lt;/li>
&lt;li>&lt;a href="#mesogen-designing-procedural-on-surface-stranded-mesostructures">MesoGen: Designing Procedural On-surface Stranded Mesostructures&lt;/a>&lt;/li>
&lt;li>&lt;a href="#fluid-solid-coupling-in-kinetic-two-phase-flow-simulation">Fluid-solid Coupling in Kinetic Two-phase Flow Simulation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#greil-crowds-crowd-simulation-with-deep-reinforcement-learning-and-examples">GREIL-Crowds: Crowd Simulation With Deep Reinforcement Learning and Examples&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3d-gaussian-splatting-for-real-time-radiance-field-rendering">3D Gaussian Splatting for Real-Time Radiance Field Rendering&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pcbend-light-up-your-3d-shapes-with-foldable-circuit-boards">PCBend: Light Up Your 3D Shapes With Foldable Circuit Boards&lt;/a>&lt;/li>
&lt;li>&lt;a href="#fast-gpu-based-two-way-continuous-collision-handling">Fast GPU-based Two-way Continuous Collision Handling&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;h2 id="building-a-virtual-weakly-compressible-wind-tunnel-testing-facility">Building a Virtual Weakly-compressible Wind Tunnel Testing Facility&lt;/h2>
&lt;p>&lt;em>Chaoyang Lyu (ShanghaiTech University / SIMIT / UCAS), Kai Bai (ShanghaiTech University / AEROCAE Digital Ltd.), Yiheng Wu (ShanghaiTech University), Mathieu Desbrun (Inria and Ecole Polytechnique), Changxi Zheng (Tencent Pixel Lab and Columbia University), Xiaopei Liu (ShanghaiTech University)&lt;/em>&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-07-31-siggraph2023/windTunnel2023_hu2d9686d9240c9a987dd2062745f588e6_62179_8fff236cd3acb2de842d10cbcb75af86.webp 400w,
/post/23-07-31-siggraph2023/windTunnel2023_hu2d9686d9240c9a987dd2062745f588e6_62179_65ae865b18131d2f96d1cd959b0983d4.webp 760w,
/post/23-07-31-siggraph2023/windTunnel2023_hu2d9686d9240c9a987dd2062745f588e6_62179_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/windTunnel2023_hu2d9686d9240c9a987dd2062745f588e6_62179_8fff236cd3acb2de842d10cbcb75af86.webp"
width="313"
height="195"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Virtual wind tunnel testing is a key ingredient in the engineering design process for the automotive and aeronautical industries as well as for urban planning: through visualization and analysis of the simulation data, it helps optimize lift and drag coefficients, increase peak speed, detect high pressure zones, and reduce wind noise at low cost prior to manufacturing. In this paper, we develop an efficient and accurate virtual wind tunnel system based on recent contributions from both computer graphics and computational fluid dynamics in high-performance kinetic solvers. Running on one or multiple GPUs, our massively-parallel lattice Boltzmann model meets industry standards for accuracy and consistency while exceeding current mainstream industrial solutions in terms of efficiency √ê especially for unsteady turbulent flow simulation at very high Reynolds number (on the order of 10^7) &amp;ndash; due to key contributions in improved collision modeling and boundary treatment, automatic construction of multiresolution grids for complex models, as well as performance optimization. We demonstrate the efficacy and reliability of our virtual wind tunnel testing facility through comparisons of our results to multiple benchmark tests, showing an increase in both accuracy and efficiency compared to state-of-the-art industrial solutions. We also illustrate the fine turbulence structures that our system can capture, indicating the relevance of our solver for both VFX and industrial product design.&lt;/p>
&lt;video controls >
&lt;source src="http://www.geometry.caltech.edu/Movies/LBWD&amp;#43;23.mp4" type="video/mp4">
&lt;/video>
&lt;h2 id="patternshop-editing-point-patterns-by-image-manipulation">Patternshop: Editing Point Patterns by Image Manipulation&lt;/h2>
&lt;p>&lt;em>Xingchang Huang (Max Planck Institute for Informatics), Tobias Ritschel (University College London), Hans-Peter Seidel (Max Planck Institute for Informatics), Pooran Memari (LIX-Inria), Gurprit Singh (Max Planck Institute for Informatics)&lt;/em>&lt;/p>
&lt;figure id="figure-our-framework-facilitate-point-pattern-design-by-representing-both-density-and-correlation-as-a-three-channel-raster-image-a-these-images-can-be-edited-c-in-terms-of-their-density-or-correlation-using-off-the-shelf-image-manipulation-software-the-resulting-point-patterns-are-shown-before-b-and-after-the-edits-d-please-see-the-accompanied-supplemental-material-for-vector-graphic-images">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Our framework facilitate point pattern design by representing both density and correlation as a three-channel raster image (a). These images can be edited (c) in terms of their density or correlation using off-the-shelf image manipulation software. The resulting point patterns are shown before (b) and after the edits (d). Please see the accompanied supplemental material for vector graphic images." srcset="
/post/23-07-31-siggraph2023/Huang2023_hub913d5f797897cd9e2b8611f3f4630bc_441127_e6f2b232f3683b0f9b166032b45a887b.webp 400w,
/post/23-07-31-siggraph2023/Huang2023_hub913d5f797897cd9e2b8611f3f4630bc_441127_19bb6c8269387816e94a57c4a55291f0.webp 760w,
/post/23-07-31-siggraph2023/Huang2023_hub913d5f797897cd9e2b8611f3f4630bc_441127_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Huang2023_hub913d5f797897cd9e2b8611f3f4630bc_441127_e6f2b232f3683b0f9b166032b45a887b.webp"
width="760"
height="207"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Our framework facilitate point pattern design by representing both density and correlation as a three-channel raster image (a). These images can be edited (c) in terms of their density or correlation using off-the-shelf image manipulation software. The resulting point patterns are shown before (b) and after the edits (d). Please see the accompanied supplemental material for vector graphic images.
&lt;/figcaption>&lt;/figure>
&lt;p>Point patterns are characterized by their density and correlation. While spatial variation of density is well-understood, analysis and synthesis of spatially-varying correlation is an open challenge. No tools are available to intuitively edit such point patterns, primarily due to the lack of a compact representation for spatially varying correlation. We propose a low-dimensional perceptual embedding for point correlations. This embedding can map point patterns to common three-channel raster images, enabling manipulation with off-the-shelf image editing software. To synthesize back point patterns, we propose a novel edge-aware objective that carefully handles sharp variations in density and correlation. The resulting framework allows intuitive and backward-compatible manipulation of point patterns, such as recoloring, relighting to even texture synthesis that have not been available to 2D point pattern design before. Effectiveness of our approach is tested in several user experiments. Code is available at &lt;a href="https://github.com/xchhuang/patternshop" target="_blank" rel="noopener">https://github.com/xchhuang/patternshop&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://xchhuang.github.io/patternshop/" target="_blank" rel="noopener">&lt;em>Page projet&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="a-sparse-non-parametric-brdf-model">A Sparse Non-parametric BRDF Model&lt;/h2>
&lt;p>&lt;em>Tanaboon Tongbuasirilai, Jonas Unger (Linkoping University), Christine Guillemot (INRIA), Ehsan Miandji (Linkoping University)&lt;/em>&lt;/p>
&lt;figure id="figure-an-overview-of-the-proposed-framework-for-learning-accurate-representations-and-sparse-data-driven-brdf-models-through-analysis-of-the-space-of-brdfs-the-brdf-dictionary-ensemble-is-trained-once-and-can-accurately-represent-a-wide-range-of-previously-unseen-materials">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="An overview of the proposed framework for learning accurate representations and sparse data-driven BRDF models through analysis of the space of BRDFs. The BRDF dictionary ensemble is trained once and can accurately represent a wide range of previously unseen materials." srcset="
/post/23-07-31-siggraph2023/Tongbuasirilai2023_hua36147e27d19343525cc8ffe3f476577_106446_dcd635af33beb48d29efc6cca2115be8.webp 400w,
/post/23-07-31-siggraph2023/Tongbuasirilai2023_hua36147e27d19343525cc8ffe3f476577_106446_a7a2990d988acf85350ef90e89ad92f3.webp 760w,
/post/23-07-31-siggraph2023/Tongbuasirilai2023_hua36147e27d19343525cc8ffe3f476577_106446_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Tongbuasirilai2023_hua36147e27d19343525cc8ffe3f476577_106446_dcd635af33beb48d29efc6cca2115be8.webp"
width="760"
height="200"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
An overview of the proposed framework for learning accurate representations and sparse data-driven BRDF models through analysis of the space of BRDFs. The BRDF dictionary ensemble is trained once and can accurately represent a wide range of previously unseen materials.
&lt;/figcaption>&lt;/figure>
&lt;p>This paper presents a novel sparse non-parametric BRDF model derived using a machine learning approach to represent the space of possible BRDFs using a set of multidimensional sub-spaces, or dictionaries. By training the dictionaries under a sparsity constraint, the model guarantees high quality representations with minimal storage requirements and an inherent clustering of the BDRF-space. The model can be trained once and then reused to represent a wide variety of measured BRDFs. Moreover, the proposed method is flexible to incorporate new unobserved data sets, parameterizations, and transformations. In addition, we show that any two, or more, BRDFs can be smoothly interpolated in the coefficient space of the model rather than the significantly higher-dimensional BRDF space. The proposed sparse BRDF model is evaluated using the MERL, DTU and RGL-EPFL BRDF databases. Experimental results show that the proposed approach results in about 9.75dB higher SNR on average for rendered images as compared to current state-of-the-art models.&lt;/p>
&lt;p>&lt;a href="https://hal.science/hal-03654734/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="videodoodles-hand-drawn-animations-on-videos-with-scene-aware-canvases">VideoDoodles: Hand-drawn Animations on Videos With Scene-aware Canvases&lt;/h2>
&lt;p>&lt;em>Emilie Yu (Centre Inria d&amp;rsquo;Universite Cote d&amp;rsquo;Azur), Kevin Matzen, Cuong Nguyen, Oliver Wang, Rubaiat Habib Kazi (Adobe), Adrien Bousseau (Centre Inria d&amp;rsquo;Universite Cote d&amp;rsquo;Azur and TU Delft)&lt;/em>&lt;/p>
&lt;figure id="figure-video-doodles-combine-hand-drawn-animations-with-video-footage-our-interactive-system-eases-the-creation-of-this-mixed-media-art-by-letting-users-place-planar-canvases-in-the-scene-which-are-then-tracked-in-3d-in-this-example-the-inserted-rainbow-bridge-exhibits-correct-perspective-and-occlusions-and-the-characters-face-and-arms-follow-the-tram-as-it-runs-towards-the-camera">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Video doodles combine hand-drawn animations with video footage. Our interactive system eases the creation of this mixed media art by letting users place planar canvases in the scene which are then tracked in 3D. In this example, the inserted rainbow bridge exhibits correct perspective and occlusions, and the character‚Äôs face and arms follow the tram as it runs towards the camera." srcset="
/post/23-07-31-siggraph2023/Yu2023_hue8dae0495c45bedbccd3c7a8dc80448c_1188849_505a82327c9e5f44bedcd333f1ca82b4.webp 400w,
/post/23-07-31-siggraph2023/Yu2023_hue8dae0495c45bedbccd3c7a8dc80448c_1188849_28cbdf70130e3e95c8f68f7c7da0a145.webp 760w,
/post/23-07-31-siggraph2023/Yu2023_hue8dae0495c45bedbccd3c7a8dc80448c_1188849_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Yu2023_hue8dae0495c45bedbccd3c7a8dc80448c_1188849_505a82327c9e5f44bedcd333f1ca82b4.webp"
width="760"
height="141"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Video doodles combine hand-drawn animations with video footage. Our interactive system eases the creation of this mixed media art by letting users place planar canvases in the scene which are then tracked in 3D. In this example, the inserted rainbow bridge exhibits correct perspective and occlusions, and the character‚Äôs face and arms follow the tram as it runs towards the camera.
&lt;/figcaption>&lt;/figure>
&lt;p>We present an interactive system to ease the creation of so-called video doodles ‚Äì videos on which artists insert hand-drawn animations for entertainment or educational purposes. Video doodles are challenging to create because to be convincing, the inserted drawings must appear as if they were part of the captured scene. In particular, the drawings should undergo tracking, perspective deformations and occlusions as they move with respect to the camera and to other objects in the scene ‚Äì visual effects that are difficult to reproduce with existing 2D video editing software. Our system supports these effects by relying on planar canvases that users position in a 3D scene reconstructed from the video. Furthermore, we present a custom tracking algorithm that allows users to anchor canvases to static or dynamic objects in the scene, such that the canvases move and rotate to follow the position and direction of these objects. When testing our system, novices could create a variety of short animated clips in a dozen of minutes, while professionals praised its speed and ease of use compared to existing tools.&lt;/p>
&lt;video controls >
&lt;source src="https://em-yu.github.io/media/figures/VideoDoodles/RESULTS_ours.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://em-yu.github.io/research/videodoodles/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="large-scale-terrain-authoring-through-interactive-erosion-simulation">Large-scale Terrain Authoring Through Interactive Erosion Simulation&lt;/h2>
&lt;p>&lt;em>Hugo Schott, Axel Paris, Lucie Fournier, Eric Guerin, Eric Galin (Univ Lyon / INSA Lyon / CNRS / UCBL / LIRIS / UMR5205)&lt;/em>&lt;/p>
&lt;figure id="figure-given-an-input-uplift-field-we-automatically-generate-the-large-scale-terrain-elevation-by-simulating-stream-power-erosion-using-a-parallel-drainage-area-algorithm-inlined-in-the-simulation-the-user-may-define-the-uplift-field-providing-ridge-and-river-networks-or-using-inverse-procedural-modeling-by-computing-the-uplift-from-an-input-digital-elevation-model">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Given an input uplift field, we automatically generate the large-scale terrain elevation by simulating stream power erosion using a parallel drainage area algorithm inlined in the simulation. The user may define the uplift field, providing ridge and river networks, or using inverse procedural modeling by computing the uplift from an input digital elevation model." srcset="
/post/23-07-31-siggraph2023/Schott2023_hu42c68a5fabc66b4348f4f85244181c2e_387504_b89d7b0a5cd66d972f088d7668fbf4b6.webp 400w,
/post/23-07-31-siggraph2023/Schott2023_hu42c68a5fabc66b4348f4f85244181c2e_387504_adee5beb6d3ae8da36b781d57687d5c6.webp 760w,
/post/23-07-31-siggraph2023/Schott2023_hu42c68a5fabc66b4348f4f85244181c2e_387504_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Schott2023_hu42c68a5fabc66b4348f4f85244181c2e_387504_b89d7b0a5cd66d972f088d7668fbf4b6.webp"
width="760"
height="151"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Given an input uplift field, we automatically generate the large-scale terrain elevation by simulating stream power erosion using a parallel drainage area algorithm inlined in the simulation. The user may define the uplift field, providing ridge and river networks, or using inverse procedural modeling by computing the uplift from an input digital elevation model.
&lt;/figcaption>&lt;/figure>
&lt;p>Large-scale terrains are essential in the definition of virtual worlds. Given the diversity of landforms and the geomorphological complexity, there is a need for authoring techniques offering hydrological consistency without sacrificing user control. In this paper, we bridge the gap between large-scale erosion simulation and authoring into an efficient framework. We set aside modeling in the elevation domain in favour of the uplift domain, and compute emerging reliefs by simulating the stream power erosion. Our simulation relies on a fast yet accurate approximation of drainage area and flow routing to compute the erosion interactively, which allows for incremental authoring. Our model provides landscape artists with tools for shaping mountain ranges and valleys, such as copy-and-paste operations; warping for imitating folds and faults; point and curve elevation constraints to precisely sculpt ridges or carve river networks. It also lends itself to inverse procedural modeling by reconstructing the uplift from an input digital elevation model and allows hydrologically consistent blending between terrain patches.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/gCP7jzcPLyQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://hal.archives-ouvertes.fr/hal-04049125/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="forming-terrains-by-glacial-erosion">Forming Terrains by Glacial Erosion&lt;/h2>
&lt;p>&lt;em>Guillaume Cordonnier (Inria and Universite Cote d&amp;rsquo;Azur), Guillaume Jouvet (University of Lausanne), Adrien Peytavie (Univ Lyon / INSA Lyon / CNRS / UCBL / LIRIS / UMR5205), Jean Braun (Helmholtz Centre Potsdam and University of Potsdam), Marie-Paule Cani (Ecole Polytechnique), Bedrich Benes (Purdue University), Eric Galin, Eric Guerin (Univ Lyon / INSA Lyon / CNRS / UCBL / LIRIS / UMR5205), James Gain (University of Cape Town)&lt;/em>&lt;/p>
&lt;figure id="figure-a-landscape-carved-by-our-simulated-glacier-specific-landforms-are-1-u-shaped-valleys-2-hanging-valleys-3-a-glacial-cirque-overhung-by-ar√™tes-and-horns-4-a-pass-and-5-highaltitude-lakes">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="A landscape carved by our simulated glacier. Specific landforms are (1) U-shaped valleys, (2) hanging valleys, (3) a glacial cirque overhung by ar√™tes and horns, (4) a pass, and (5) high‚Äìaltitude lakes." srcset="
/post/23-07-31-siggraph2023/Cordonnier2023_hu0e9c5b3ce4c6577c3de3b8d979210db0_152763_1780becfd13c6b355004cd47d9e08edb.webp 400w,
/post/23-07-31-siggraph2023/Cordonnier2023_hu0e9c5b3ce4c6577c3de3b8d979210db0_152763_0dffbd41210d5e45a516ebc6706fb8c8.webp 760w,
/post/23-07-31-siggraph2023/Cordonnier2023_hu0e9c5b3ce4c6577c3de3b8d979210db0_152763_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Cordonnier2023_hu0e9c5b3ce4c6577c3de3b8d979210db0_152763_1780becfd13c6b355004cd47d9e08edb.webp"
width="412"
height="314"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
A landscape carved by our simulated glacier. Specific landforms are (1) U-shaped valleys, (2) hanging valleys, (3) a glacial cirque overhung by ar√™tes and horns, (4) a pass, and (5) high‚Äìaltitude lakes.
&lt;/figcaption>&lt;/figure>
&lt;p>We introduce the first solution for simulating the formation and evolution of glaciers, together with their attendant erosive effects, for periods covering the combination of glacial and inter-glacial cycles. Our efficient solution includes both a fast yet accurate deep learning-based estimation of high-order ice flows and a new, multi-scale advection scheme enabling us to account for the distinct time scales at which glaciers reach equilibrium compared to eroding the terrain. We combine the resulting glacial erosion model with finer-scale erosive phenomena to account for the transport of debris flowing from cliffs. This enables us to model the formation of terrain shapes not previously adequately modeled in Computer Graphics, ranging from U-shaped and hanging valleys to fjords and glacial lakes.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/xfk_J4VhdWA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://hal.archives-ouvertes.fr/hal-04090644/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="contesse-accurate-occluding-contours-for-subdivision-surfaces">ConTesse: Accurate Occluding Contours for Subdivision Surfaces&lt;/h2>
&lt;p>&lt;em>Chenxi Liu (University of British Columbia), Pierre Benard (University of Bordeaux / CNRS / Bordeaux INP / INRIA / LaBRI), Aaron Hertzmann (Adobe Research), Shayan Hoshyari (Adobe)&lt;/em>&lt;/p>
&lt;figure id="figure-given-a-a-smooth-3d-surface-and-a-camera-viewpoint-our-method-produces-b-a-triangle-mesh-where-the-occluding-contour-of-the-mesh-accurately-approximates-the-occluding-contour-of-the-smooth-surface-standard-algorithms-may-then-be-used-to-extract-c-the-view-map-of-occluding-contours-and-to-d-stylize-them-fertility-courtesy-uu-from-aimshape-visionair-shape-repository">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Given (a) a smooth 3D surface and a camera viewpoint, our method produces (b) a triangle mesh where the occluding contour of the mesh accurately approximates the occluding contour of the smooth surface. Standard algorithms may then be used to extract (c) the view map of occluding contours, and to (d) stylize them. (Fertility courtesy UU from AIM@SHAPE-VISIONAIR Shape Repository). " srcset="
/post/23-07-31-siggraph2023/Liu2023_hu8cd5e87749f2520bba733f76166d2fcb_237901_ff05ff1039096b189a946f19311ebc07.webp 400w,
/post/23-07-31-siggraph2023/Liu2023_hu8cd5e87749f2520bba733f76166d2fcb_237901_8765f93cb0a8c9ca08cf8757545148fd.webp 760w,
/post/23-07-31-siggraph2023/Liu2023_hu8cd5e87749f2520bba733f76166d2fcb_237901_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Liu2023_hu8cd5e87749f2520bba733f76166d2fcb_237901_ff05ff1039096b189a946f19311ebc07.webp"
width="760"
height="183"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Given (a) a smooth 3D surface and a camera viewpoint, our method produces (b) a triangle mesh where the occluding contour of the mesh accurately approximates the occluding contour of the smooth surface. Standard algorithms may then be used to extract (c) the view map of occluding contours, and to (d) stylize them. (Fertility courtesy UU from AIM@SHAPE-VISIONAIR Shape Repository).
&lt;/figcaption>&lt;/figure>
&lt;p>This paper proposes a method for computing the visible occluding contours of subdivision surfaces. The paper first introduces new theory for contour visibility of smooth surfaces. Necessary and sufficient conditions are introduced for when a sampled occluding contour is valid, that is, when it may be assigned consistent visibility. Previous methods do not guarantee these conditions, which helps explain why smooth contour visibility has been such a challenging problem in the past. The paper then proposes an algorithm that, given a subdivision surface, finds sampled contours satisfying these conditions, and then generates a new triangle mesh matching the given occluding contours. The contours of the output triangle mesh may then be rendered with standard non-photorealistic rendering algorithms, using the mesh for visibility computation. The method can be applied to any triangle mesh, by treating it as the base mesh of a subdivision surface.&lt;/p>
&lt;p>&lt;a href="https://dgp.toronto.edu/~hertzman/contesse/contesse_arxiv.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="polynomial-2d-green-coordinates-for-polygonal-cages">Polynomial 2D Green Coordinates for Polygonal Cages&lt;/h2>
&lt;p>&lt;em>Elie Michel, Jean-Marc Thiery (Adobe Research)&lt;/em>&lt;/p>
&lt;figure id="figure-top-row-a-input-image-and-an-embedding-polygonal-cage-b-d-deformations-obtained-using-mean-value-coordinates-cubic-mean-value-coordinates-and-green-coordinates-e-our-conformal-deformations-obtained-with-cubic-curves-bottom-row-more-resuls-of-our-approach-using-polynomial-curves-of-various-orders-from-1-to-7">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Top row: (a) input image and an embedding polygonal cage; (b-d) deformations obtained using Mean-Value coordinates, Cubic Mean-Value coordinates, and Green coordinates; (e) our conformal deformations obtained with cubic curves. Bottom row: more resuls of our approach, using polynomial curves of various orders (from 1 to 7)." srcset="
/post/23-07-31-siggraph2023/Michel2023_huc959bab4be803eed9e21ba0ee506a8ec_189161_ef86e0c3f951e6738d9ef7afb90eea9d.webp 400w,
/post/23-07-31-siggraph2023/Michel2023_huc959bab4be803eed9e21ba0ee506a8ec_189161_4919a178f9e4a2d872e6b45012955a26.webp 760w,
/post/23-07-31-siggraph2023/Michel2023_huc959bab4be803eed9e21ba0ee506a8ec_189161_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Michel2023_huc959bab4be803eed9e21ba0ee506a8ec_189161_ef86e0c3f951e6738d9ef7afb90eea9d.webp"
width="760"
height="288"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Top row: (a) input image and an embedding polygonal cage; (b-d) deformations obtained using Mean-Value coordinates, Cubic Mean-Value coordinates, and Green coordinates; (e) our conformal deformations obtained with cubic curves. Bottom row: more resuls of our approach, using polynomial curves of various orders (from 1 to 7).
&lt;/figcaption>&lt;/figure>
&lt;p>Cage coordinates are a powerful means to define 2D deformation fields from sparse control points. We introduce Conformal polynomial Coordinates for closed polyhedral cages, enabling segments to be transformed into polynomial curves of any order. Extending classical 2D Green coordinates, our coordinates result in conformal harmonic deformations that are cage-aware. We demonstrate the usefulness of our technique on a variety of 2D deformation scenarios where curves allow artists to perform intuitive deformations with few input parameters. Our method combines the texture preservation property of conformal deformations together with the expressiveness offered by Bezier controls.&lt;/p>
&lt;p>&lt;a href="https://portfolio.exppad.com/documents/2023__Michel__PolynomialGreenCoords.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="orientable-dense-cyclic-infill-for-anisotropic-appearance-fabrication">Orientable Dense Cyclic Infill for Anisotropic Appearance Fabrication&lt;/h2>
&lt;p>&lt;em>Xavier Chermain, Cedric Zanni, Jonas Mart√É¬≠nez, Pierre-Alexandre Hugron, Sylvain Lefebvre (Universite de Lorraine / CNRS / Inria)&lt;/em>&lt;/p>
&lt;figure id="figure-we-develop-an-efficient-algorithm-that-produces-an-orientable-dense-cyclic-infill-by-aligning-a-field-of-periodic-functions-contouring-it-to-obtain-cycles-and-connecting-all-cycles-into-one-we-leverage-this-algorithm-to-print-anisotropic-appearances-using-fused-filament-fabrication-left-the-shape-with-purple-boundaries-is-infilled-with-a-cycle-the-cycles-directions-have-four-modes-parallel-to-the-boundary-red-area-orthogonal-to-the-boundary-blue-area-smoothest-lines-yellow-area-and-constrained-lines-color-gradient-area-our-algorithm-is-very-flexible-allowing-directions-to-be-constrained-everywhere-areas-with-a-color-gradient-in-the-logo-or-only-within-the-vicinity-of-the-boundary-blue-red-and-yellow-areas-alignment-with-boundaries-can-also-be-constrained-as-in-this-example-the-grey-cycle-is-the-output-of-our-algorithm-curve-interspace-objective-25-mm-right-printed-cycle-with-interspace-set-to-04-mm-the-trajectorys-directions-determine-the-appearance-as-extruded-filaments-exhibit-anisotropic-roughness">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="We develop an efficient algorithm that produces an orientable dense cyclic infill by aligning a field of periodic functions, contouring it to obtain cycles, and connecting all cycles into one. We leverage this algorithm to print anisotropic appearances using fused filament fabrication. Left: the shape with purple boundaries is infilled with a cycle. The cycle‚Äôs directions have four modes: parallel to the boundary (red area), orthogonal to the boundary (blue area), smoothest lines (yellow area), and constrained lines (color gradient area). Our algorithm is very flexible, allowing directions to be constrained everywhere (areas with a color gradient in the logo) or only within the vicinity of the boundary (blue, red, and yellow areas). Alignment with boundaries can also be constrained, as in this example. The grey cycle is the output of our algorithm (curve interspace objective: 2.5 mm). Right: Printed cycle with interspace set to 0.4 mm. The trajectory‚Äôs directions determine the appearance, as extruded filaments exhibit anisotropic roughness." srcset="
/post/23-07-31-siggraph2023/Chermain2023_hue373d50df52cd9152bf212acc56125b2_855072_4c0a4b50beb7eee86837a2bbf5954390.webp 400w,
/post/23-07-31-siggraph2023/Chermain2023_hue373d50df52cd9152bf212acc56125b2_855072_8169254fd2858771158ad0bc89a78528.webp 760w,
/post/23-07-31-siggraph2023/Chermain2023_hue373d50df52cd9152bf212acc56125b2_855072_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Chermain2023_hue373d50df52cd9152bf212acc56125b2_855072_4c0a4b50beb7eee86837a2bbf5954390.webp"
width="760"
height="208"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
We develop an efficient algorithm that produces an orientable dense cyclic infill by aligning a field of periodic functions, contouring it to obtain cycles, and connecting all cycles into one. We leverage this algorithm to print anisotropic appearances using fused filament fabrication. Left: the shape with purple boundaries is infilled with a cycle. The cycle‚Äôs directions have four modes: parallel to the boundary (red area), orthogonal to the boundary (blue area), smoothest lines (yellow area), and constrained lines (color gradient area). Our algorithm is very flexible, allowing directions to be constrained everywhere (areas with a color gradient in the logo) or only within the vicinity of the boundary (blue, red, and yellow areas). Alignment with boundaries can also be constrained, as in this example. The grey cycle is the output of our algorithm (curve interspace objective: 2.5 mm). Right: Printed cycle with interspace set to 0.4 mm. The trajectory‚Äôs directions determine the appearance, as extruded filaments exhibit anisotropic roughness.
&lt;/figcaption>&lt;/figure>
&lt;p>We present a method to 3D print surfaces exhibiting a prescribed varying field of anisotropic appearance using only standard fused filament fabrication printers. This enables the fabrication of patterns triggering reflections similar to that of brushed metal with direct control over the directionality of the reflections. Our key insight, on which we ground the method, is that the direction of the deposition paths leads to a certain degree of surface roughness, which yields a visual anisotropic appearance. Therefore, generating dense cyclic infills aligned with a line field allows us to grade the anisotropic appearance of the printed surface. To achieve this, we introduce a highly parallelizable algorithm for optimizing oriented, cyclic paths. Our algorithm outperforms existing approaches regarding efficiency, robustness, and result quality. We demonstrate the effectiveness of our technique in conveying an anisotropic appearance on several challenging test cases, ranging from patterns to photographs reinterpreted as anisotropic appearances.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/aUDzZrlRnNU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://xavierchermain.github.io/data/pdf/Chermain2023Orientable.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="complex-wrinkle-field-evolution">Complex Wrinkle Field Evolution&lt;/h2>
&lt;p>&lt;em>Zhen Chen (The University of Texas at Austin), Danny Kaufman (Adobe Research), Melina Skouras (Univ. Grenoble Alpes / Inria / CNRS), Etienne Vouga (The University of Texas at Austin)&lt;/em>&lt;/p>
&lt;figure id="figure-we-propose-complex-wrinkle-fields-cwf-s-a-new-discrete-wrinkle-model-that-enables-the-resolution-of-highly-detailed-wrinkle-patterns-on-coarse-base-mesh-geometry-the-cwf-representation-consists-of-a-positive-number-a-per-vertex-encoding-the-wrinkle-amplitude-a-one-form-œâ-per-edge-to-model-wrinkle-frequency-and-a-complex-number-z-per-vertex-to-represent-wrinkle-phase-coupled-via-a-weak-variational-consistency-condition-ensuring-that-z-can-capture-singularities-while-also-being-as-compatible-with-œâ-as-possible--31-we-equip-the-cwf-representation-with-a-novel-temporal-interpolation-algorithm--4-and-a-spatial-upsampling-method--5-that-together-allow-for-smooth-interpolation-between-wrinkle-patterns-represented-on-surfaces-by-cwf-s-leftmost-and-rightmost-column-and-base-mesh-independent-rendering-of-arbitrarily-high-resolution-wrinkle-patterns-together-these-contributions-make-it-possible-to-smoothly-evolve-wrinkle-patterns-between-two-prescribed-keyframes-middle-columns-with-automatic-merging-splitting-and-reconnection-of-wrinkles-as-necessary-via-smooth-sliding-of-singularities-across-the-surface-zoomed-in-figures-in-middle-columns">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="We propose Complex Wrinkle Fields (CWF s), a new discrete wrinkle model that enables the resolution of highly detailed wrinkle patterns on coarse base-mesh geometry. The CWF representation consists of a positive number a per vertex encoding the wrinkle amplitude, a one-form œâ per edge to model wrinkle frequency, and a complex number Àúz per vertex to represent wrinkle phase, coupled via a weak variational consistency condition ensuring that Àúz can capture singularities while also being as compatible with œâ as possible (¬ß 3.1). We equip the CWF representation with a novel temporal interpolation algorithm (¬ß 4) and a spatial upsampling method (¬ß 5) that together allow for smooth interpolation between wrinkle patterns represented on surfaces by CWF s (leftmost and rightmost column), and base-mesh-independent rendering of arbitrarily high-resolution wrinkle patterns. Together these contributions make it possible to smoothly evolve wrinkle patterns between two prescribed keyframes (middle columns) with automatic merging, splitting, and reconnection of wrinkles as necessary via smooth sliding of singularities across the surface (zoomed-in figures in middle columns). " srcset="
/post/23-07-31-siggraph2023/Chen2023_hu99dd2c25e008671c2d5a5f4a3f46a512_30874_8976b6c9414acc86a60084e3c1fd782c.webp 400w,
/post/23-07-31-siggraph2023/Chen2023_hu99dd2c25e008671c2d5a5f4a3f46a512_30874_23dacdd406eebdb9fc5e9d5216779463.webp 760w,
/post/23-07-31-siggraph2023/Chen2023_hu99dd2c25e008671c2d5a5f4a3f46a512_30874_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Chen2023_hu99dd2c25e008671c2d5a5f4a3f46a512_30874_8976b6c9414acc86a60084e3c1fd782c.webp"
width="720"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
We propose Complex Wrinkle Fields (CWF s), a new discrete wrinkle model that enables the resolution of highly detailed wrinkle patterns on coarse base-mesh geometry. The CWF representation consists of a positive number a per vertex encoding the wrinkle amplitude, a one-form œâ per edge to model wrinkle frequency, and a complex number Àúz per vertex to represent wrinkle phase, coupled via a weak variational consistency condition ensuring that Àúz can capture singularities while also being as compatible with œâ as possible (¬ß 3.1). We equip the CWF representation with a novel temporal interpolation algorithm (¬ß 4) and a spatial upsampling method (¬ß 5) that together allow for smooth interpolation between wrinkle patterns represented on surfaces by CWF s (leftmost and rightmost column), and base-mesh-independent rendering of arbitrarily high-resolution wrinkle patterns. Together these contributions make it possible to smoothly evolve wrinkle patterns between two prescribed keyframes (middle columns) with automatic merging, splitting, and reconnection of wrinkles as necessary via smooth sliding of singularities across the surface (zoomed-in figures in middle columns).
&lt;/figcaption>&lt;/figure>
&lt;p>We propose a new approach for representing wrinkles, designed to capture complex and detailed wrinkle behavior on coarse triangle meshes, called Complex Wrinkle Fields. Complex Wrinkle Fields consist of an almost-everywhere-unit complex-valued phase function over the surface; a frequency one-form; and an amplitude scalar, with a soft compatibility condition coupling the frequency and phase. We develop algorithms for interpolating between two such wrinkle fields, for visualizing them as displacements of a Loop-subdivided refinement of the base mesh, and for making smooth local edits to the wrinkle amplitude, frequency, and/or orientation. These algorithms make it possible, for the first time, to create and edit animations of wrinkles on triangle meshes that are smooth in space, evolve smoothly through time, include singularities along with their complex interactions, and that represent frequencies far finer than the surface resolution.&lt;/p>
&lt;p>&lt;a href="https://zhenchen-jay.github.io/uploads/CWF.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="coupling-conduction-convection-and-radiative-transfer-in-a-single-path-space-application-to-infrared-rendering">Coupling Conduction, Convection and Radiative Transfer in a Single Path-Space: Application to Infrared Rendering&lt;/h2>
&lt;p>&lt;em>Megane Bati, Stephane Blanco (Univ. Toulouse), Christophe Coustet, Vincent Eymet, Vincent Forest (Meso-Star), Richard Fournier (Univ. Toulouse), Jacques Gautrais (Univ. Toulouse and CNRS), Nicolas Mellado, Mathias Paulin (Univ. Toulouse), Benjamin Piaud (Meso-Star)&lt;/em>&lt;/p>
&lt;figure id="figure-we-propose-a-monte-carlo-approach-to-tackle-multiple-physics-with-a-single-algorithm-translating-their-coupling-into-a-single-path-space-composed-of-randomly-chained-sub-paths-for-each-physics-application-is-exemplified-with-heat-transfer-a-an-infrared-image-of-a-steady-state-thermal-exchanger-with-temperature-imposed-on-the-left-and-right-walls-b-monte-carlo-paths-alternate-between-heat-transfer-modes-here-conduction-and-radiation-c-a-huge-benefit-is-the-fast-production-of-transient-simulations-at-any-time-using-the-information-gathered-in-a-ie-from-only-one-monte-carlo-run-at-steady-state">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="We propose a Monte Carlo approach to tackle multiple physics with a single algorithm, translating their coupling into a single path-space composed of randomly chained sub-paths for each physics. Application is exemplified with heat transfer. (a) An infrared image of a steady state thermal exchanger, with temperature imposed on the left and right walls. (b) Monte Carlo paths alternate between heat-transfer modes (here conduction and radiation). (c) A huge benefit is the fast production of transient simulations, at any time, using the information gathered in (a), i.e. from only one Monte Carlo run at steady state. " srcset="
/post/23-07-31-siggraph2023/Bati2023_hu84965310d0506e2d17a54baf42b38b68_243366_e08d4c4b6c16bacfcae2a09910b4af2e.webp 400w,
/post/23-07-31-siggraph2023/Bati2023_hu84965310d0506e2d17a54baf42b38b68_243366_be96c724bf2390c9521759a5b504ac12.webp 760w,
/post/23-07-31-siggraph2023/Bati2023_hu84965310d0506e2d17a54baf42b38b68_243366_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Bati2023_hu84965310d0506e2d17a54baf42b38b68_243366_e08d4c4b6c16bacfcae2a09910b4af2e.webp"
width="760"
height="211"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
We propose a Monte Carlo approach to tackle multiple physics with a single algorithm, translating their coupling into a single path-space composed of randomly chained sub-paths for each physics. Application is exemplified with heat transfer. (a) An infrared image of a steady state thermal exchanger, with temperature imposed on the left and right walls. (b) Monte Carlo paths alternate between heat-transfer modes (here conduction and radiation). (c) A huge benefit is the fast production of transient simulations, at any time, using the information gathered in (a), i.e. from only one Monte Carlo run at steady state.
&lt;/figcaption>&lt;/figure>
&lt;p>In the past decades, Monte Carlo methods have shown their ability to solve PDEs, independently of the dimensionality of the integration domain and for different use-cases (e.g. light transport, geometry processing, physics simulation). Specifically, the path-space formulation of transport equations is a key ingredient to define tractable and scalable solvers, and we observe nowadays a strong interest in the definition of simulation systems based on Monte Carlo algorithms. We also observe that, when simulating combined physics (e.g. thermal rendering from a heat transfer simulation), there is a lack of coupled Monte Carlo algorithms allowing to solve all the physics at once, in the same path space, rather than combining several independent MC estimators, a combination that would make the global solver critically sensitive to the complexity of each simulation space. This brings to our proposal: a coupled, single path-space, Monte Carlo algorithm for efficient multi-physics problems solving. In this work, we combine our understanding and knowledge of Physics and Computer Graphics to demonstrate how to formulate and arrange different simulation spaces into a single path space. We define a tractable formalism for coupled heat transfer simulation using Monte Carlo, and we leverage the path-space construction to interactively compute multiple simulations with different conditions in the same scene, in terms of boundary conditions and observation time. We validate our proposal in the context of infrared rendering with different thermal simulation scenarios: e.g., room temperature simulation, visualization of heat paths within materials (detection of thermal bridges), heat diffusion capacity of thermal exchanger. We expect that our theoretical framework will foster collaboration and multidisciplinary studies. The perspectives this framework opens are detailed and we suggest a research agenda towards the resolution of coupled PDEs at the interface of Physics and Computer Graphics.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/UIjgiNymjyw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://hal.science/hal-04090428" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="textured-mesh-quality-assessment-large-scale-dataset-and-deep-learning-based-quality-metric">Textured Mesh Quality Assessment: Large-scale Dataset and Deep Learning-based Quality Metric&lt;/h2>
&lt;p>&lt;em>Yana Nehme, Johanna Delanoy, Florent Dupont, Jean-Philippe Farrugia (Univ Lyon, UCBL, CNRS, INSA Lyon, LIRIS, UMR5205), Patrick Le Callet (Nantes Universite, Ecole Centrale Nantes, CNRS, LS2N, UMR 6004), Guillaume Lavoue (Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE)&lt;/em>&lt;/p>
&lt;figure id="figure-a-geometry-and-color-spatial-information-and-b-visual-attention-complexity-for-the-selected-source-models">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="(a) Geometry and color spatial information and (b) visual attention complexity for the selected source models. " srcset="
/post/23-07-31-siggraph2023/Nehme2023_hub855d19a346a83ffc1b6f6e9abe80016_324891_7bc39a1ff4f61a485311b010e1c8ee12.webp 400w,
/post/23-07-31-siggraph2023/Nehme2023_hub855d19a346a83ffc1b6f6e9abe80016_324891_4f9ef59a8df25bf3dddd11c0d5c08b9e.webp 760w,
/post/23-07-31-siggraph2023/Nehme2023_hub855d19a346a83ffc1b6f6e9abe80016_324891_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Nehme2023_hub855d19a346a83ffc1b6f6e9abe80016_324891_7bc39a1ff4f61a485311b010e1c8ee12.webp"
width="760"
height="357"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
(a) Geometry and color spatial information and (b) visual attention complexity for the selected source models.
&lt;/figcaption>&lt;/figure>
&lt;p>Over the past decade, 3D graphics have become highly detailed to mimic the real world, exploding their size and complexity. Certain applications and device constraints necessitate their simplification and/or lossy compression, which can degrade their visual quality. Thus, to ensure the best Quality of Experience (QoE), it is important to evaluate the visual quality to accurately drive the compression and find the right compromise between visual quality and data size. In this work, we focus on subjective and objective quality assessment of textured 3D meshes. We first establish a large-scale dataset, which includes 55 source models quantitatively characterized in terms of geometric, color, and semantic complexity, and corrupted by combinations of 5 types of compression-based distortions applied on the geometry, texture mapping and texture image of the meshes. This dataset contains over 343k distorted stimuli. We propose an approach to select a challenging subset of 3000 stimuli for which we collected 148929 quality judgments from over 4500 participants in a large-scale crowdsourced subjective experiment. Leveraging our subject-rated dataset, a learning-based quality metric for 3D graphics was proposed. Our metric demonstrates state-of-the-art results on our dataset of textured meshes and on a dataset of distorted meshes with vertex colors. Finally, we present an application of our metric and dataset to explore the influence of distortion interactions and content characteristics on the perceived quality of compressed textured meshes.&lt;/p>
&lt;p>&lt;a href="https://arxiv.org/abs/2202.02397" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="variational-shape-reconstruction-via-quadric-error-metrics">Variational Shape Reconstruction via Quadric Error Metrics&lt;/h2>
&lt;p>&lt;em>Tong Zhao (Inria Sophia-Antipolis / Universite Cote d&amp;rsquo;Azur / LTCI, Telecom Paris), Laurent Buse, David Cohen-Steiner (Inria Sophia-Antipolis and Universite Cote d&amp;rsquo;Azur), Tamy Boubekeur, Jean-Marc Thiery (Adobe Research), Pierre Alliez (Inria Sophia-Antipolis and Universite Cote d&amp;rsquo;Azur)&lt;/em>&lt;/p>
&lt;figure id="figure-variational-shape-reconstruction-the-clustering-of-the-points-is-randomly-initialized-then-alternates-partitioning-and-generator-updating-some-generators-relocate-to-sharp-features-after-one-iteration-new-generators-are-then-added-the-clustering-converges-after-five-iterations-a-set-of-candidate-edges-is-derived-from-the-adjacency-between-clusters-and-candidate-facets-red-are-generated-the-output-mesh-is-reconstructed-via-a-constrained-binary-solver-that-selects-a-subset-of-the-red-facets">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Variational shape reconstruction. The clustering of the points is randomly initialized, then alternates partitioning and generator updating. Some generators relocate to sharp features after one iteration. New generators are then added. The clustering converges after five iterations. A set of candidate edges is derived from the adjacency between clusters, and candidate facets (red) are generated. The output mesh is reconstructed via a constrained binary solver that selects a subset of the red facets." srcset="
/post/23-07-31-siggraph2023/Zhao2023_hu42af5ecf5f79dbe7dfdad4aa9dd341cb_168617_e4a9ba29ac1bf8ebc6e22e86840c41b5.webp 400w,
/post/23-07-31-siggraph2023/Zhao2023_hu42af5ecf5f79dbe7dfdad4aa9dd341cb_168617_c15cb938484df3342f21a08cd5673d28.webp 760w,
/post/23-07-31-siggraph2023/Zhao2023_hu42af5ecf5f79dbe7dfdad4aa9dd341cb_168617_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Zhao2023_hu42af5ecf5f79dbe7dfdad4aa9dd341cb_168617_e4a9ba29ac1bf8ebc6e22e86840c41b5.webp"
width="530"
height="442"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Variational shape reconstruction. The clustering of the points is randomly initialized, then alternates partitioning and generator updating. Some generators relocate to sharp features after one iteration. New generators are then added. The clustering converges after five iterations. A set of candidate edges is derived from the adjacency between clusters, and candidate facets (red) are generated. The output mesh is reconstructed via a constrained binary solver that selects a subset of the red facets.
&lt;/figcaption>&lt;/figure>
&lt;p>Inspired by the strengths of quadric error metrics initially designed for mesh decimation, we propose a concise mesh reconstruction approach for 3D point clouds. Our approach proceeds by clustering the input points enriched with quadric error metrics, where the generator of each cluster is the optimal 3D point for the sum of its quadric error metrics. This approach favors the placement of generators on sharp features, and tends to equidistribute the error among clusters. We reconstruct the output surface mesh from the adjacency between clusters and a constrained binary solver. We combine our clustering process with an adaptive refinement driven by the error. Compared to prior art, our method avoids dense reconstruction prior to simplification and produces immediately an optimized mesh.&lt;/p>
&lt;p>&lt;a href="https://hal.science/3IA-COTEDAZUR/hal-04131765v1" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="somigliana-coordinates-an-elasticity-derived-approach-for-cage-deformation">Somigliana Coordinates: An Elasticity-derived Approach for Cage Deformation&lt;/h2>
&lt;p>&lt;em>Jiong Chen (Ecole Polytechnique), Fernando de Goes (Pixar Animation Studios), Mathieu Desbrun (Inria and Ecole Polytechnique)&lt;/em>&lt;/p>
&lt;figure id="figure-somigliana-coordinates-given-an-initial-cage-top-inset-and-its-deformed-pose-our-novel-cage-deformer-promotes-a-more-elastic-behavior-of-the-cage-deformation-than-previous-works-by-leveraging-an-elasticity-derived-matrix-weighted-combination-of-both-vertex-positions-and-face-normals-of-the-cage-a-poisson-ratio-ùúà-and-bulging-scale-ùõæ-can-be-adjusted-to-offer-control-over-local-and-global-volume-change">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Somigliana coordinates. Given an initial cage (top inset) and its deformed pose, our novel cage deformer promotes a more elastic behavior of the cage deformation than previous works by leveraging an elasticity-derived matrix-weighted combination of both vertex positions and face normals of the cage. A Poisson ratio ùúà and bulging scale ùõæ can be adjusted to offer control over local and global volume change." srcset="
/post/23-07-31-siggraph2023/Chen2023_hu0adf2dcb2860ad037672cb1a8b05efab_195171_23a0a4e89e3c5b74157bd83b6823ae2b.webp 400w,
/post/23-07-31-siggraph2023/Chen2023_hu0adf2dcb2860ad037672cb1a8b05efab_195171_5d59cb19498097398a7b0c91193e1311.webp 760w,
/post/23-07-31-siggraph2023/Chen2023_hu0adf2dcb2860ad037672cb1a8b05efab_195171_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Chen2023_hu0adf2dcb2860ad037672cb1a8b05efab_195171_23a0a4e89e3c5b74157bd83b6823ae2b.webp"
width="520"
height="537"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Somigliana coordinates. Given an initial cage (top inset) and its deformed pose, our novel cage deformer promotes a more elastic behavior of the cage deformation than previous works by leveraging an elasticity-derived matrix-weighted combination of both vertex positions and face normals of the cage. A Poisson ratio ùúà and bulging scale ùõæ can be adjusted to offer control over local and global volume change.
&lt;/figcaption>&lt;/figure>
&lt;p>In this paper, we present a novel cage deformer based on elasticity-derived matrix-valued coordinates. In order to bypass the typical shearing artifacts and lack of volume control of existing cage deformers, we promote a more elastic behavior of the cage deformation by deriving our coordinates from the Somigliana identity, a boundary integral formulation based on the fundamental solution of linear elasticity. Given an initial cage and its deformed pose, the deformation of the cage interior is deduced from these Somigliana coordinates via a corotational scheme, resulting in a matrix-weighted combination of both vertex positions and face normals of the cage. Our deformer thus generalizes Green coordinates, while producing physically-plausible spatial deformations that are invariant under similarity transformations and with interactive bulging control. We demonstrate the efficiency and versatility of our method through a series of examples in 2D and 3D.&lt;/p>
&lt;video controls >
&lt;source src="https://jiongchen.github.io/files/somi-video.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://jiongchen.github.io/files/somi-paper.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="constraint-based-simulation-of-passive-suction-cups">Constraint-based Simulation of Passive Suction Cups&lt;/h2>
&lt;p>&lt;em>Antonin Bernardin, Univ. Rennes / INSA / IRISA / Inria), Paul Kry (McGill University), Sheldon Andrews (Ecole de technologie superieure), Christian Duriez (Inria / Univ. Lille / CNRS), Maud Marchal (Univ. Rennes / INSA / IRISA / Inria)&lt;/em>&lt;/p>
&lt;figure id="figure-the-monster-pop-up-toy-sticks-to-its-base-until-the-spring-forces-release-it-due-to-air-leakage-making-the-whole-structure-to-jump">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="The Monster pop-up toy sticks to its base until the spring forces release it due to air leakage, making the whole structure to jump." srcset="
/post/23-07-31-siggraph2023/Bernardin2023_hu1ef156b0be57381ad4a03fb9d01dabfd_172949_6848ed7477bd4084947563a4ba38779b.webp 400w,
/post/23-07-31-siggraph2023/Bernardin2023_hu1ef156b0be57381ad4a03fb9d01dabfd_172949_65e9441b98ce3af2f21d81153548e4ae.webp 760w,
/post/23-07-31-siggraph2023/Bernardin2023_hu1ef156b0be57381ad4a03fb9d01dabfd_172949_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Bernardin2023_hu1ef156b0be57381ad4a03fb9d01dabfd_172949_6848ed7477bd4084947563a4ba38779b.webp"
width="760"
height="244"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
The Monster pop-up toy sticks to its base until the spring forces release it due to air leakage, making the whole structure to jump.
&lt;/figcaption>&lt;/figure>
&lt;p>In this paper, we propose a physics-based model of suction phenomenon to achieve simulation of deformable objects like suction cups. Our model uses a constraint-based formulation to simulate the variations of pressure inside suction cups. The respective internal pressures are represented as pressure constraints which are coupled with anti-interpenetration and friction constraints. Furthermore, our method is able to detect multiple air cavities using information from collision detection. We solve the pressure constraints based on the ideal gas law while considering several cavity states. We test our model with a number of scenarios reflecting a variety of uses, for instance, a spring loaded jumping toy, a manipulator performing a pick and place task, and an octopus tentacle grasping a soda can. We also evaluate the ability of our model to reproduce the physics of suction cups of varying shapes, lifting objects of different masses, and sliding on a slippery surface. The results show promise for various applications such as the simulation in soft robotics and computer animation.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/PSKXglvD77I" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://inria.hal.science/hal-03869711/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="mesogen-designing-procedural-on-surface-stranded-mesostructures">MesoGen: Designing Procedural On-surface Stranded Mesostructures&lt;/h2>
&lt;p>&lt;em>Elie Michel, Tamy Boubekeur (Adobe Research)&lt;/em>&lt;/p>
&lt;figure id="figure-we-propose-a-workflow-for-designing-rich-mesostructures-with-self-similarity-but-no-repetition-artifacts-our-method-is-based-on-wang-tiling-to-enable-fast-authoring-and-efficient-real-time-rendering">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="We propose a workflow for designing rich mesostructures, with self-similarity but no repetition artifacts. Our method is based on Wang tiling to enable fast authoring and efficient real-time rendering." srcset="
/post/23-07-31-siggraph2023/Michel2023_hu234445fd5bf9117d38de5295c8b1e7af_184189_2ada78d3e31abf0ce485db0b2562436e.webp 400w,
/post/23-07-31-siggraph2023/Michel2023_hu234445fd5bf9117d38de5295c8b1e7af_184189_b3d5cb25393d734eb4a2b16ebd2a8b09.webp 760w,
/post/23-07-31-siggraph2023/Michel2023_hu234445fd5bf9117d38de5295c8b1e7af_184189_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Michel2023_hu234445fd5bf9117d38de5295c8b1e7af_184189_2ada78d3e31abf0ce485db0b2562436e.webp"
width="760"
height="191"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
We propose a workflow for designing rich mesostructures, with self-similarity but no repetition artifacts. Our method is based on Wang tiling to enable fast authoring and efficient real-time rendering.
&lt;/figcaption>&lt;/figure>
&lt;p>Three-dimensional mesostructures enrich coarse macrosurfaces with complex features, which are 3D geometry with arbitrary topology in essence, but are expected to be self-similar with no tiling artifacts, just like texture-based material models. This is a challenging task, as no existing modeling tool provides the right constraints in the design phase to ensure such properties while maintaining real-time editing capabilities. In this paper, we propose MesoGen, a novel tile-centric authoring approach for the design of procedural mesostructures featuring non-periodic self-similarity while being represented as a compact and GPU-friendly model. We ensure by construction the continuity of the mesostructure: the user designs a set of atomic tiles by drawing 2D cross-sections on the interfaces between tiles, and selecting pairs of cross-sections to be connected as strands, i.e., 3D sweep surfaces. In parallel, a tiling engine continuously fills the shell space of the macrosurface with the so-defined tile set while ensuring that only matching interfaces are in contact. Moreover, the engine suggests to the user the addition of new tiles whenever the problem happens to be over-constrained. As a result, our method allows for the rapid creation of complex, seamless procedural mesostructure and is particularly adapted for wicker-like ones, often impossible to achieve with scattering-based mesostructure synthesis methods.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/AXDTo-JkECc" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://eliemichel.github.io/MesoGen/documents/michel23mesogen.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="fluid-solid-coupling-in-kinetic-two-phase-flow-simulation">Fluid-solid Coupling in Kinetic Two-phase Flow Simulation&lt;/h2>
&lt;p>&lt;em>Wei Li (Inria and Tencent Lightspeed Studios), Mathieu Desbrun (Inria and Ecole Polytechnique)&lt;/em>&lt;/p>
&lt;figure id="figure-key-drop-in-this-paper-we-propose-a-stable-and-efficient-kinetic-two-phase-flow-simulator-which-can-handle-complex-fluid-solid-coupling-like-a-skeleton-key-being-dropped-in-water-the-dynamics-of-the-bubbles-entrapped-by-the-fall-is-well-captured-as-the-insets-of-a-real-experiment-demonstrate">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Key Drop. In this paper, we propose a stable and efficient kinetic two-phase flow simulator which can handle complex fluid-solid coupling, like a skeleton key being dropped in water. The dynamics of the bubbles entrapped by the fall is well captured as the insets of a real experiment demonstrate." srcset="
/post/23-07-31-siggraph2023/Li2023_hu884feca0fdeb785fdf0a7749cd3e433f_151433_8d3af0a36c1f61c865dab29e1467dc82.webp 400w,
/post/23-07-31-siggraph2023/Li2023_hu884feca0fdeb785fdf0a7749cd3e433f_151433_51446ddf5702eb2350a7b169c4ddf10e.webp 760w,
/post/23-07-31-siggraph2023/Li2023_hu884feca0fdeb785fdf0a7749cd3e433f_151433_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Li2023_hu884feca0fdeb785fdf0a7749cd3e433f_151433_8d3af0a36c1f61c865dab29e1467dc82.webp"
width="760"
height="145"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Key Drop. In this paper, we propose a stable and efficient kinetic two-phase flow simulator which can handle complex fluid-solid coupling, like a skeleton key being dropped in water. The dynamics of the bubbles entrapped by the fall is well captured as the insets of a real experiment demonstrate.
&lt;/figcaption>&lt;/figure>
&lt;p>Real-life flows exhibit complex and visually appealing behaviors such as bubbling, splashing, glugging and wetting that simulation techniques in graphics have attempted to capture for years. While early approaches were not capable of reproducing multiphase flow phenomena due to their excessive numerical viscosity and low accuracy, kinetic solvers based on the lattice Boltzmann method have recently demonstrated the ability to simulate water-air interaction at high Reynolds numbers in a massively-parallel fashion. However, robust and accurate handling of fluid-solid coupling has remained elusive: be it for CG or CFD solvers, as soon as the motion of immersed objects is too fast or too sudden, pressures near boundaries and interfacial forces exhibit spurious oscillations leading to blowups. Built upon a phase-field and velocity-distribution based lattice-Boltzmann solver for multiphase flows, this paper spells out a series of numerical improvements in momentum exchange, interfacial forces, and two-way coupling to drastically reduce these typical artifacts, thus significantly expanding the types of fluid-solid coupling that we can efficiently simulate. We highlight the numerical benefits of our solver through various challenging simulation results, including comparisons to previous work and real footage.&lt;/p>
&lt;video controls >
&lt;source src="https://pages.saclay.inria.fr/mathieu.desbrun/Movies/LD23.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://pages.saclay.inria.fr/mathieu.desbrun/pubs/LD23.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="greil-crowds-crowd-simulation-with-deep-reinforcement-learning-and-examples">GREIL-Crowds: Crowd Simulation With Deep Reinforcement Learning and Examples&lt;/h2>
&lt;p>&lt;em>Panayiotis Charalambous (CYENS - Centre of Excellence), Julien Pettre (Univ Rennes, Inria, CNRS, IRISA), Vassilis Vassiliades (University of Cyprus), Yiorgos Chrysanthou (CYENS - Centre of Excellence and University of Cyprus), Nuria Pelechano (Universitat Politecnica de Catalunya)&lt;/em>&lt;/p>
&lt;figure id="figure-results-from-the-same-simulation---all-agents-use-the-pedestrian-controller-the-policy-is-able-to-capture-and-simulate-simultaneously-a-d-social-groups-flocks-individuals-mixed-behaviours-e-f-and-various-behaviors-such-as-agents-suddenly-standing-still-joiningleaving-groups-etc">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Results from the same simulation - all agents use the pedestrian controller. The policy is able to capture and simulate simultaneously (a-d) social groups, flocks, individuals, mixed behaviours; (e-f) and various behaviors such as agents suddenly standing still, joining/leaving groups, etc. " srcset="
/post/23-07-31-siggraph2023/Charalambous2023_hu79748757eaefa5accd1610b59ba6b2df_3266474_2ceab80dd7366ef663b8e2151a161813.webp 400w,
/post/23-07-31-siggraph2023/Charalambous2023_hu79748757eaefa5accd1610b59ba6b2df_3266474_564c60c79c2a7a2b6d633a14241d80e1.webp 760w,
/post/23-07-31-siggraph2023/Charalambous2023_hu79748757eaefa5accd1610b59ba6b2df_3266474_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Charalambous2023_hu79748757eaefa5accd1610b59ba6b2df_3266474_2ceab80dd7366ef663b8e2151a161813.webp"
width="760"
height="470"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Results from the same simulation - all agents use the pedestrian controller. The policy is able to capture and simulate simultaneously (a-d) social groups, flocks, individuals, mixed behaviours; (e-f) and various behaviors such as agents suddenly standing still, joining/leaving groups, etc.
&lt;/figcaption>&lt;/figure>
&lt;p>Simulating crowds with realistic behaviors is a difficult but very important task for a variety of applications. Quantifying how a person balances between different conflicting criteria such as goal seeking,collision avoidance and moving within a group is not intuitive, especially if we consider that behaviors differ largely between people. Inspired by recent advances in Deep Reinforcement Learning, we propose Guided REinforcement Learning (GREIL) Crowds, a method that learns a model for pedestrian behaviors which is guided by reference crowd data. The model successfully captures behaviors such as goal seeking, being part of consistent groups without the need to define explicit relationships and wandering around seemingly without a specific purpose. Two fundamental concepts are important in achieving these results: (a) the per agent state representation and (b) the reward function. The agent state is a temporal representation of the situation around each agent. The reward function is based on the idea that people try to move in situations/states in which they feel comfortable in. Therefore, in order for agents to stay in a comfortable state space, we first obtain a distribution of states extracted from real crowd data; then we evaluate states based on how much of an outlier they are compared to such a distribution. We demonstrate that our system can capture and simulate many complex and subtle crowd interactions in varied scenarios. Additionally, the proposed method generalizes to unseen situations, generates consistent behaviors and does not suffer from the limitations of other data-driven and reinforcement learning approaches.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/VNPUJJW4crM" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://veupnea.github.io/publication_pages/siggraph23-greil.html" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="3d-gaussian-splatting-for-real-time-radiance-field-rendering">3D Gaussian Splatting for Real-Time Radiance Field Rendering&lt;/h2>
&lt;p>&lt;em>Bernhard Kerbl, Georgios Kopanas (Inria and Universite Cote d&amp;rsquo;Azur), Thomas Leimkuhler (MPI Informatik), George Drettakis (Inria and Universite Cote d&amp;rsquo;Azur)&lt;/em>&lt;/p>
&lt;figure id="figure-our-method-achieves-real-time-rendering-of-radiance-fields-with-quality-that-equals-the-previous-method-with-the-best-quality-barron-et-al--2022-while-only-requiring-optimization-times-competitive-with-the-fastest-previous-methods-fridovich-keil-and-yu-et-al--2022-m√ºller-et-al-2022-key-to-this-performance-is-a-novel-3d-gaussian-scene-representation-coupled-with-a-real-time-differentiable-renderer-which-offers-significant-speedup-to-both-scene-optimization-and-novel-view-synthesis-note-that-for-comparable-training-times-to-instantngp-m√ºller-et-al-2022-we-achieve-similar-quality-to-theirs-while-this-is-the-maximum-quality-they-reach-by-training-for-51min-we-achieve-state-of-the-art-quality-even-slightly-better-than-mip-nerf360-barron-et-al--2022">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Our method achieves real-time rendering of radiance fields with quality that equals the previous method with the best quality [Barron et al . 2022], while only requiring optimization times competitive with the fastest previous methods [Fridovich-Keil and Yu et al . 2022; M√ºller et al. 2022]. Key to this performance is a novel 3D Gaussian scene representation coupled with a real-time differentiable renderer, which offers significant speedup to both scene optimization and novel view synthesis. Note that for comparable training times to InstantNGP [M√ºller et al. 2022], we achieve similar quality to theirs; while this is the maximum quality they reach, by training for 51min we achieve state-of-the-art quality, even slightly better than Mip-NeRF360 [Barron et al . 2022]." srcset="
/post/23-07-31-siggraph2023/Kerbl2023_huc22b53f1cf87cbeb04c2739cff4b3c3d_504750_c4fbd3e130d994b2dec9cae0b4a54099.webp 400w,
/post/23-07-31-siggraph2023/Kerbl2023_huc22b53f1cf87cbeb04c2739cff4b3c3d_504750_dda269068874c0caf8f27acec50b580a.webp 760w,
/post/23-07-31-siggraph2023/Kerbl2023_huc22b53f1cf87cbeb04c2739cff4b3c3d_504750_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Kerbl2023_huc22b53f1cf87cbeb04c2739cff4b3c3d_504750_c4fbd3e130d994b2dec9cae0b4a54099.webp"
width="760"
height="179"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Our method achieves real-time rendering of radiance fields with quality that equals the previous method with the best quality [Barron et al . 2022], while only requiring optimization times competitive with the fastest previous methods [Fridovich-Keil and Yu et al . 2022; M√ºller et al. 2022]. Key to this performance is a novel 3D Gaussian scene representation coupled with a real-time differentiable renderer, which offers significant speedup to both scene optimization and novel view synthesis. Note that for comparable training times to InstantNGP [M√ºller et al. 2022], we achieve similar quality to theirs; while this is the maximum quality they reach, by training for 51min we achieve state-of-the-art quality, even slightly better than Mip-NeRF360 [Barron et al . 2022].
&lt;/figcaption>&lt;/figure>
&lt;p>Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates.&lt;/p>
&lt;p>We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (‚â• 100 fps) novel-view synthesis at 1080p resolution.&lt;/p>
&lt;p>First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/T_kXY43VZnk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/3d_gaussian_splatting_high.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank" rel="noopener">&lt;em>Project page&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="pcbend-light-up-your-3d-shapes-with-foldable-circuit-boards">PCBend: Light Up Your 3D Shapes With Foldable Circuit Boards&lt;/h2>
&lt;p>&lt;em>Marco Freire* (Universite de Lorraine / CNRS / Inria), Manas Bhargava* (ISTA), Camille Schreck, Pierre-Alexandre Hugron (Universite de Lorraine / CNRS / Inria), Bernd Bickel (ISTA), Sylvain Lefebvre (Universite de Lorraine / CNRS / Inria) (* Joint first authors)&lt;/em>&lt;/p>
&lt;figure id="figure-starting-from-a-3d-mesh-our-method-automatically-generates-design-files-to-produce-an-on-surface-display-composed-of-individually-addressable-rgb-leds-the-circuit-board-is-manufactured-through-standard-pcb-production-services-including-component-soldering-the-user-then-folds-the-fabricated-board-back-onto-a-3d-printed-support-the-final-model-becomes-a-curved-display-onto-which-intricate-light-patterns-can-be-programmed-in-a-shader-like-manner">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Starting from a 3D mesh our method automatically generates design files to produce an on-surface display composed of individually addressable RGB LEDs. The circuit board is manufactured through standard PCB production services, including component soldering. The user then folds the fabricated board back onto a 3D printed support. The final model becomes a curved display, onto which intricate light patterns can be programmed in a shader-like manner." srcset="
/post/23-07-31-siggraph2023/Freire2023_hu607ffb6b7b8d3832e4c4abdd43f7c096_1579071_72bd301b3ef90bf013071be9ddf286c2.webp 400w,
/post/23-07-31-siggraph2023/Freire2023_hu607ffb6b7b8d3832e4c4abdd43f7c096_1579071_0841e7f95ef699e33f22341f85bd8147.webp 760w,
/post/23-07-31-siggraph2023/Freire2023_hu607ffb6b7b8d3832e4c4abdd43f7c096_1579071_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Freire2023_hu607ffb6b7b8d3832e4c4abdd43f7c096_1579071_72bd301b3ef90bf013071be9ddf286c2.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Starting from a 3D mesh our method automatically generates design files to produce an on-surface display composed of individually addressable RGB LEDs. The circuit board is manufactured through standard PCB production services, including component soldering. The user then folds the fabricated board back onto a 3D printed support. The final model becomes a curved display, onto which intricate light patterns can be programmed in a shader-like manner.
&lt;/figcaption>&lt;/figure>
&lt;p>We propose a computational design approach for covering a surface with individually addressable RGB LEDs, effectively forming a low-resolution surface screen. To achieve a low-cost and scalable approach, we propose creating designs from flat PCB panels bent in-place along the surface of a 3D printed core. Working with standard rigid PCBs enables the use of established PCB manufacturing services, allowing the fabrication of designs with several hundred LEDs. Our approach optimizes the PCB geometry for folding, and then jointly optimizes the LED packing, circuit and routing, solving a challenging layout problem under strict manufacturing requirements. Unlike paper, PCBs cannot bend beyond a certain point without breaking. Therefore, we introduce parametric cut patterns acting as hinges, designed to allow bending while remaining compact. To tackle the joint optimization of placement, circuit and routing, we propose a specialized algorithm that splits the global problem into one sub-problem per triangle, which is then individually solved. Our technique generates PCB blueprints in a completely automated way. After being fabricated by a PCB manufacturing service, the boards are bent and glued by the user onto the 3D printed support. We demonstrate our technique on a range of physical models and virtual examples, creating intricate surface light patterns from hundreds of LEDs.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/nJspqdpyWq4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://manas-avi.github.io/publications/2023/PCBend/FoldableElectronics-2023-camera-ready.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://visualcomputing.ist.ac.at/publications/2023/PLUY3SWFCB/" target="_blank" rel="noopener">&lt;em>Project page&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="fast-gpu-based-two-way-continuous-collision-handling">Fast GPU-based Two-way Continuous Collision Handling&lt;/h2>
&lt;p>&lt;em>Tianyu Wang (FaceUnity), Jiong Chen (Ecole Polytechnique), Dongping Li, Xiaowei Liu (FaceUnity), Huamin Wang (Style3D), Kun Zhou (Zhejiang University)&lt;/em>&lt;/p>
&lt;figure id="figure-knotting-the-bow-knot-example-on-the-top-with-142k-triangles-and-the-reef-knot-example-on-the-bottom-with-71k-triangles-are-presented-in-this-work-we-develop-a-two-way-method-for-safe-and-fast-collision-handling-in-deformable-body-simulation-thanks-to-this-method-our-simulator-can-robustly-handle-complex-collision-contacts-in-these-two-examples-at-4-to-17-fps-and-10-to-21-fps-respectively">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Knotting. The bow knot example (on the top, with 142K triangles) and the reef knot example (on the bottom, with 71K triangles) are presented. In this work, we develop a two-way method for safe and fast collision handling in deformable body simulation. Thanks to this method, our simulator can robustly handle complex collision contacts in these two examples at 4 to 17 FPS and 10 to 21 FPS respectively." srcset="
/post/23-07-31-siggraph2023/Wang2023_hu69823277c1dcb031b5bd621e1a13ecc8_528044_f396f3e5b544b8db768c92875f90fca7.webp 400w,
/post/23-07-31-siggraph2023/Wang2023_hu69823277c1dcb031b5bd621e1a13ecc8_528044_6e919c3166ff63a6527f0b1c9454a3e8.webp 760w,
/post/23-07-31-siggraph2023/Wang2023_hu69823277c1dcb031b5bd621e1a13ecc8_528044_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Wang2023_hu69823277c1dcb031b5bd621e1a13ecc8_528044_f396f3e5b544b8db768c92875f90fca7.webp"
width="760"
height="354"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Knotting. The bow knot example (on the top, with 142K triangles) and the reef knot example (on the bottom, with 71K triangles) are presented. In this work, we develop a two-way method for safe and fast collision handling in deformable body simulation. Thanks to this method, our simulator can robustly handle complex collision contacts in these two examples at 4 to 17 FPS and 10 to 21 FPS respectively.
&lt;/figcaption>&lt;/figure>
&lt;p>Step-and-project is a popular method to simulate non-penetrating deformable bodies in physically-based animation. The strategy is to first integrate the system in time without considering contacts and then resolve potential intersections, striking a good balance between plausibility and efficiency. However, existing methods can be defective and unsafe when using large time steps, taking risks of failure or demanding repetitive collision testing and resolving that severely degrade performance. In this paper, we propose a novel two-way method for fast and reliable continuous collision handling. Our method launches an optimization from both ends of the intermediate time-integrated state and the previous intersection-free state. It progressively generates a piecewise linear path and eventually obtains a feasible solution for the next time step. The algorithm efficiently alternates between a forward step and a backward step until the result is conditionally converged. Thanks to a set of unified volume-based contact constraints, our method offers flexible and reliable handling of various codimensional deformable bodies, including volumetric bodies, cloth, hair and sand. Experimental results demonstrate the safety, robustness, physical fidelity and numerical efficiency of our method, making it particularly suitable for scenarios involving large deformations or large time steps.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/6T52DU2iFu0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://wanghmin.github.io/Wang-2023-FGB/Wang-2023-FGB.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p></description></item><item><title>Hommage √† Jean-Marc Chassery</title><link>https://gdr-igrv.fr/post/23-06-17-hommage-jm-chassery/</link><pubDate>Sat, 17 Jun 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/23-06-17-hommage-jm-chassery/</guid><description>&lt;p>C‚Äôest avec une immense tristesse que nous avons appris le d√©c√®s soudain de Jean-Marc Chassery le 17 juin 2023.&lt;/p>
&lt;p>Jean-Marc a √©t√© non seulement un des pionniers de la g√©om√©trie discr√®te dans les ann√©es 90, et un des ma√Ætres d‚Äôoeuvre de la cr√©ation du groupe de travail GDMM via le rapprochement entre les communaut√©s de g√©om√©trie discr√®te et morphologie math√©matique.&lt;/p>
&lt;p>Tr√®s impliqu√© dans l&amp;rsquo;animation et la structuration de la recherche, il a assur√© de nombreuses responsabilit√©s tout au long de sa carri√®re : fondateur et premier directeur du GIPSA-Lab, directeur du GdR ISIS de 1992 √† 2001 apr√®s avoir eu des responsabilit√©s dans le GdR TDSI ; membre du Comit√© National du CNRS (CoNRS) en section 07 en 2001 ; Directeur-Adjoint Scientifique (DAS) √† la cr√©ation de l‚ÄôINSIS de 2009 √† 2012 ; d√©l√©gu√© scientifique √† l‚ÄôHCERES de 2012 √† 2017.&lt;/p>
&lt;p>M√™me √† la retraite depuis plusieurs ann√©es, Jean-Marc restait tr√®s proche de ses anciens coll√®gues pour qui sa disparition est une tr√®s grande perte.&lt;/p>
&lt;p>&lt;a href="https://www.gdr-isis.fr/index.php/hommage-a-jean-marc-chassery/" target="_blank" rel="noopener">Hommage √† Jean-Marc Chassery sur le site du GdR ISIS&lt;/a>&lt;/p></description></item><item><title>Retour sur les pleini√®res 2023</title><link>https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/</guid><description>&lt;h1 id="lancement">Lancement&lt;/h1>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/pl%c3%a9ni%c3%a8res2023_lancement.pdf"> Acc√©der √† la pr√©sentation &lt;/a>&lt;/p>
&lt;h1 id="session-ia-et-animation">Session &amp;ldquo;IA et Animation&amp;rdquo;&lt;/h1>
&lt;h2 id="alexandre-meyer---ia-et-animation">Alexandre Meyer - IA et Animation&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_IA_hu9c8879c4c5db3e353099dc518ed8460d_132337_1c8d139b532166c6aad267c88e4667c1.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_IA_hu9c8879c4c5db3e353099dc518ed8460d_132337_0047e2b8bf705773fc13470a534e92a4.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_IA_hu9c8879c4c5db3e353099dc518ed8460d_132337_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_IA_hu9c8879c4c5db3e353099dc518ed8460d_132337_1c8d139b532166c6aad267c88e4667c1.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Alexandre Meyer est Ma√Ætre de conf√©rences (HDR) au d√©partement d&amp;rsquo;informatique de l&amp;rsquo;Universit√© Lyon 1 depuis 2004. Il m√®ne ses recherches dans le groupe SAARA du laboratoire LIRIS.
Ses travaux de recherche se situent √† l&amp;rsquo;interface entre l&amp;rsquo;infographie et la vision par ordinateur. Dans le domaine de la vision par ordinateur, ses travaux se concentrent sur la reconnaissance des expressions des visages et des mouvements du corps, en √©tablissant souvent un lien avec l&amp;rsquo;animation ou la perception. Du c√¥t√© de l&amp;rsquo;infographie, ses travaux vont de l&amp;rsquo;animation proc√©durale (z√©ro donn√©es) √† l&amp;rsquo;animation bas√©e sur l&amp;rsquo;apprentissage, avec un int√©r√™t particulier pour l&amp;rsquo;√©dition ou la cr√©ation de style dans les animations.&lt;/p>
&lt;p>Il a donn√© une pr√©sentation sur l&amp;rsquo;utilisation de l&amp;rsquo;intelligence artificielle (IA) dans l&amp;rsquo;animation. Sa pr√©sentation a discut√© des progr√®s r√©alis√©s gr√¢ce √† l&amp;rsquo;apprentissage profond et a explor√© diff√©rentes m√©thodes utilis√©es dans ce domaine. Diff√©rents types de r√©seaux de neurones ont √©t√© abord√©s, tels que les r√©seaux de convolution et les autoencodeurs. Des techniques d&amp;rsquo;am√©lioration de la qualit√© des animations ont √©t√© discut√©es, ainsi que l&amp;rsquo;utilisation des espaces latents pour la repr√©sentation des poses. Des exemples d&amp;rsquo;applications de l&amp;rsquo;IA dans l&amp;rsquo;animation ont √©t√© donn√©s, comme la g√©n√©ration d&amp;rsquo;avatars 3D √† partir de textes. Enfin, la pr√©sentation a soulign√© les avanc√©es r√©alis√©es et les d√©fis √† relever dans ce domaine.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/2023_GDR_AMeyer.pdf"> Acc√©der √† la pr√©sentation &lt;/a>&lt;/p>
&lt;figure id="figure-alexandre-meyer-universit√©-lyon1-liris---httpspersoliriscnrsframeyerpublic_htmlwww">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Alexandre Meyer (Universit√© Lyon1, LIRIS) : https://perso.liris.cnrs.fr/ameyer/public_html/www/" srcset="
/post/23-06-06-retour-pleinieres-2023/alexM_hua93c34035ab6236b9d4769d2cad09f7e_26557_b00db74b34e210594f2eac9c3173bb2e.webp 400w,
/post/23-06-06-retour-pleinieres-2023/alexM_hua93c34035ab6236b9d4769d2cad09f7e_26557_2958251a62cc56b99a62120650218d32.webp 760w,
/post/23-06-06-retour-pleinieres-2023/alexM_hua93c34035ab6236b9d4769d2cad09f7e_26557_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/alexM_hua93c34035ab6236b9d4769d2cad09f7e_26557_b00db74b34e210594f2eac9c3173bb2e.webp"
width="118"
height="119"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Alexandre Meyer (Universit√© Lyon1, LIRIS) : &lt;a href="https://perso.liris.cnrs.fr/ameyer/public_html/www/" target="_blank" rel="noopener">https://perso.liris.cnrs.fr/ameyer/public_html/www/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h1 id="session-impact-environnemental--on-en-est-o√π">Session &amp;ldquo;Impact environnemental : on en est o√π&amp;rdquo;&lt;/h1>
&lt;h2 id="peter-sturm">Peter Sturm&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_peter_hu9c8879c4c5db3e353099dc518ed8460d_130370_d43289433e96465a1ee6d1c90da1352e.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_peter_hu9c8879c4c5db3e353099dc518ed8460d_130370_7baf54c6edffaf28acc3d112b073ec04.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_peter_hu9c8879c4c5db3e353099dc518ed8460d_130370_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_peter_hu9c8879c4c5db3e353099dc518ed8460d_130370_d43289433e96465a1ee6d1c90da1352e.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Peter Sturm est adjoint au directeur scientifique, en charge du domaine &amp;ldquo;Perception, cognition, interaction&amp;rdquo; √† Inria depuis le 9 avril 2015. Il m√®ne ses recherches dans l&amp;rsquo;√©quipe STEEP √† Inria Grenoble Rh√¥ne-Alpes.
Ses sujets de recherche, centr√©s sur la vision par ordinateur, concernent surtout le calibrage de cam√©ras, la reconstruction 3D et l‚Äôestimation de mouvement, que ce soit pour des cam√©ras perspectives ou omnidirectionnelles. Depuis 2011, Peter contribue aux travaux de l&amp;rsquo;institut sur le d√©veloppement durable et, plus particuli√®rement, sur des mod√®les int√©gr√©s d‚Äôusage des sols et de transport.&lt;/p>
&lt;p>Il a donn√© une pr√©sentation abordant les th√®mes des effets rebond, de l&amp;rsquo;efficience, de la sobri√©t√© et de la r√©silience. Au dela de la d√©finition des ces notions, Peter a aussi sensibilis√© l&amp;rsquo;audience √† l&amp;rsquo;importance de se poser les bonnes questions (autour des impacts environnementaux mais pas seulement), de bien nommer les choses et d&amp;rsquo;avoir conscience des possibles impacts des technologies developp√©es dans les laboratoires.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/2023_05_30_GdR_IG_RV_Peter_Sturm.pdf"> Acc√©der √† la pr√©sentation &lt;/a>&lt;/p>
&lt;figure id="figure-peter-sturm-inria-grenoble-ljk--httpssteepinriafrmembres-de-lequipepeter-sturm">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Peter Sturm (INRIA Grenoble, LJK) : https://steep.inria.fr/membres-de-lequipe/peter-sturm/" srcset="
/post/23-06-06-retour-pleinieres-2023/peterS_hudbec3e859f1c8a7103c10d23fa8ef1d6_69529_aad061517f32190af7b33bafdef3d111.webp 400w,
/post/23-06-06-retour-pleinieres-2023/peterS_hudbec3e859f1c8a7103c10d23fa8ef1d6_69529_a80a7e0004cc92dd366970a130259e55.webp 760w,
/post/23-06-06-retour-pleinieres-2023/peterS_hudbec3e859f1c8a7103c10d23fa8ef1d6_69529_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/peterS_hudbec3e859f1c8a7103c10d23fa8ef1d6_69529_aad061517f32190af7b33bafdef3d111.webp"
width="265"
height="195"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Peter Sturm (INRIA Grenoble, LJK) : &lt;a href="https://steep.inria.fr/membres-de-lequipe/peter-sturm/" target="_blank" rel="noopener">https://steep.inria.fr/membres-de-lequipe/peter-sturm/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="laurent-lefevre">Laurent Lefevre&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_laurent_hu9c8879c4c5db3e353099dc518ed8460d_124772_1ca442ff78a80f2ada1c4653908c7690.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_laurent_hu9c8879c4c5db3e353099dc518ed8460d_124772_74a19166b28154bacbbd73a1e39cdf94.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_laurent_hu9c8879c4c5db3e353099dc518ed8460d_124772_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_laurent_hu9c8879c4c5db3e353099dc518ed8460d_124772_1ca442ff78a80f2ada1c4653908c7690.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Laurent Lef√®vre est un chercheur permanent en informatique √† Inria. Il travaille au sein de l&amp;rsquo;√©quipe AVALON (Algorithmes et Architectures Logicielles pour les Plates-formes Orient√©es Service) d&amp;rsquo;Inria et du Laboratoire LIP √† l&amp;rsquo;√âcole Normale Sup√©rieure de Lyon.
Ses domaines de recherche comprennent l&amp;rsquo;informatique distribu√©e et les r√©seaux, l&amp;rsquo;informatique et les r√©seaux √©co√©nerg√©tiques, le Green IT, la durabilit√© en informatique, les r√©seaux d√©finis par logiciel, les r√©seaux autonomes, les protocoles et services de r√©seaux √† haute performance, les r√©seaux actifs et programmables, les r√©seaux tol√©rants aux perturbations, le calcul en grappes, les syst√®mes de m√©moire partag√©e distribu√©e et la coh√©rence des donn√©es, ainsi que la tol√©rance aux pannes.&lt;/p>
&lt;p>Il a pr√©sent√© l&amp;rsquo;impact du num√©rique, √† la fois de son usage (consommation d&amp;rsquo;√©nergie) mais aussi de son cycle de vie (extraction des ressources et recyclage), sur l&amp;rsquo;environnement, dans un monde o√π les usages du num√©riques sont de plus en plus nombreux.
Il a ensuite pr√©sent√© quelques pistes pour prendre en compte ces enjeux.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/GDR-IG-RV_2023_Laurent_Lefevre_diffuse.pdf"> Acc√©der √† la pr√©sentation &lt;/a>&lt;/p>
&lt;figure id="figure-laurent-lefevre-inria-lip--httpspersoens-lyonfrlaurentlefevre">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Laurent Lefevre (INRIA, LIP) : https://perso.ens-lyon.fr/laurent.lefevre/" srcset="
/post/23-06-06-retour-pleinieres-2023/laurentL_huf81403ad945414b1df24ec670126f56e_20248_0adc25409d2129bd67674b33f826a080.webp 400w,
/post/23-06-06-retour-pleinieres-2023/laurentL_huf81403ad945414b1df24ec670126f56e_20248_a1c8aad6b11c2337c207786b562e8e1b.webp 760w,
/post/23-06-06-retour-pleinieres-2023/laurentL_huf81403ad945414b1df24ec670126f56e_20248_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/laurentL_huf81403ad945414b1df24ec670126f56e_20248_0adc25409d2129bd67674b33f826a080.webp"
width="320"
height="240"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Laurent Lefevre (INRIA, LIP) : &lt;a href="https://perso.ens-lyon.fr/laurent.lefevre/" target="_blank" rel="noopener">https://perso.ens-lyon.fr/laurent.lefevre/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h1 id="session-ig-rv-et-jo-2024">Session &amp;ldquo;IG-RV et JO 2024&amp;rdquo;&lt;/h1>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_JO_hu9c8879c4c5db3e353099dc518ed8460d_125334_f743bb1567cfcfb9f4decc50c0561225.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_JO_hu9c8879c4c5db3e353099dc518ed8460d_125334_bb2b6d949688661643884d2e7772c01c.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_JO_hu9c8879c4c5db3e353099dc518ed8460d_125334_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_JO_hu9c8879c4c5db3e353099dc518ed8460d_125334_f743bb1567cfcfb9f4decc50c0561225.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h2 id="lije-yao">Lije Yao&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_lijie_hu7fef5788bd28ca160c0fe5ce76757543_128964_cfc4f4d5497828abaed767f20bf576bc.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_lijie_hu7fef5788bd28ca160c0fe5ce76757543_128964_004bdbcd6e6acf97cf222bd90e491a12.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_lijie_hu7fef5788bd28ca160c0fe5ce76757543_128964_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_lijie_hu7fef5788bd28ca160c0fe5ce76757543_128964_cfc4f4d5497828abaed767f20bf576bc.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Lije Yao pr√©pare actuellement un doctorat √† Inria dans l&amp;rsquo;√©quipe Aviz (Analyse et visualisation) et l&amp;rsquo;Universit√© Paris-Saclay. Ses principaux sujets de recherche comprennent la visualisation de l&amp;rsquo;information et l&amp;rsquo;analyse visuelle, avec un accent sur la visualisation en mouvement.&lt;/p>
&lt;p>Elle a pr√©sent√© ses recherches sur la visualisation situ√©e et en temps r√©el des informations li√©es aux comp√©titions de natations.&lt;/p>
&lt;figure id="figure-lije-yao-inria-saclay">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Lije Yao (INRIA Saclay)" srcset="
/post/23-06-06-retour-pleinieres-2023/LijieYao_huf9d1f7593529e1e0866263f2b932ecbb_38534_3142174961f8f80cd2c848390dfaa53a.webp 400w,
/post/23-06-06-retour-pleinieres-2023/LijieYao_huf9d1f7593529e1e0866263f2b932ecbb_38534_05d1f13daf041649d06456f7c385015a.webp 760w,
/post/23-06-06-retour-pleinieres-2023/LijieYao_huf9d1f7593529e1e0866263f2b932ecbb_38534_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/LijieYao_huf9d1f7593529e1e0866263f2b932ecbb_38534_3142174961f8f80cd2c848390dfaa53a.webp"
width="247"
height="300"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Lije Yao (INRIA Saclay)
&lt;/figcaption>&lt;/figure>
&lt;h2 id="franck-multon">Franck Multon&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_franck_hu9c8879c4c5db3e353099dc518ed8460d_119594_f2596967dcf14a4be4fafa7342c5b45f.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_franck_hu9c8879c4c5db3e353099dc518ed8460d_119594_7b160cf11d15b0908808c2ce95176a78.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_franck_hu9c8879c4c5db3e353099dc518ed8460d_119594_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_franck_hu9c8879c4c5db3e353099dc518ed8460d_119594_f2596967dcf14a4be4fafa7342c5b45f.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Franck Multon est directeur de recherche √† Inria et reponsable de l&amp;rsquo;√©quipe MimeTIC (Analysis-Synthesis Approach for Virtual Human Simulation). Depuis septembre 2018, il s&amp;rsquo;occupe d&amp;rsquo;une mission nationale de coordination des actions du centre dans le domaine du num√©rique pour le sport, en lien avec les JOP Paris 2024.&lt;/p>
&lt;p>Il a pr√©sent√© plusieurs travaux autour de l&amp;rsquo;utilisation du num√©rique et de la r√©alit√© virtuelle pour l&amp;rsquo;entrainement des sportifs de haut niveau (autour du rugby ou du football notamment).&lt;/p>
&lt;figure id="figure-franck-multon-univ-rennes-inria--httpspersouniv-rennes2frfranckmulton">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Franck Multon (Univ Rennes, INRIA) : https://perso.univ-rennes2.fr/franck.multon" srcset="
/post/23-06-06-retour-pleinieres-2023/franckM_huc3e2e9df64bacb078d5e2e5db6bde03e_4816_48fea43ec0c6d47c00e1ce0d9cab8d36.webp 400w,
/post/23-06-06-retour-pleinieres-2023/franckM_huc3e2e9df64bacb078d5e2e5db6bde03e_4816_b8c9e7f5c4d8fc276de2d330c4db9007.webp 760w,
/post/23-06-06-retour-pleinieres-2023/franckM_huc3e2e9df64bacb078d5e2e5db6bde03e_4816_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/franckM_huc3e2e9df64bacb078d5e2e5db6bde03e_4816_48fea43ec0c6d47c00e1ce0d9cab8d36.webp"
width="150"
height="150"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Franck Multon (Univ Rennes, INRIA) : &lt;a href="https://perso.univ-rennes2.fr/franck.multon" target="_blank" rel="noopener">https://perso.univ-rennes2.fr/franck.multon&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="thibaut-le-naour-startup-motion-up">Thibaut Le Naour (Startup Motion-Up)&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_motionUp_hu9c8879c4c5db3e353099dc518ed8460d_127687_2f477a174ce30435881c9dc9c4b0067e.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_motionUp_hu9c8879c4c5db3e353099dc518ed8460d_127687_f70b05916290e2a4bd0c3dc125a819c9.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_motionUp_hu9c8879c4c5db3e353099dc518ed8460d_127687_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_motionUp_hu9c8879c4c5db3e353099dc518ed8460d_127687_2f477a174ce30435881c9dc9c4b0067e.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>MotionUp est une entreprise sp√©cialis√©e dans les services informatiques, ax√©e sur la capture de mouvement et la production de solutions num√©riques. Elle propose des services de capture de mouvement pr√©cis et efficaces, permettant la num√©risation des mouvements avec une grande pr√©cision et rapidit√©. En plus de la capture de mouvement, MotionUp propose des solutions num√©riques personnalis√©es, de la conception √† l&amp;rsquo;hebergement.&lt;/p>
&lt;p>Thibat Le Naour, le fondateur de Motion-Up a discut√© des diff√©rentes technologies de motion capture et a pr√©sent√© plusieurs cas d&amp;rsquo;usage des technologies de motion capture pour l&amp;rsquo;apprentissage des gestes.&lt;/p>
&lt;figure id="figure-thibaut-le-naour--httpmotion-upcompersotlenaour">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Thibaut Le Naour : http://motion-up.com/perso/tlenaour/" srcset="
/post/23-06-06-retour-pleinieres-2023/thibautLN_hu2d95b4841be49ae575605f2168e6f15c_35820_612e6cf504afee9bbe9b6c80db0b7a92.webp 400w,
/post/23-06-06-retour-pleinieres-2023/thibautLN_hu2d95b4841be49ae575605f2168e6f15c_35820_a8f800fef2c41b6c84e23aa9677d0b03.webp 760w,
/post/23-06-06-retour-pleinieres-2023/thibautLN_hu2d95b4841be49ae575605f2168e6f15c_35820_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/thibautLN_hu2d95b4841be49ae575605f2168e6f15c_35820_612e6cf504afee9bbe9b6c80db0b7a92.webp"
width="195"
height="195"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Thibaut Le Naour : &lt;a href="http://motion-up.com/perso/tlenaour/" target="_blank" rel="noopener">http://motion-up.com/perso/tlenaour/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;figure id="figure-startup-motion-up--httpswwwmotion-upcom">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Startup Motion-Up : https://www.motion-up.com/" srcset="
/post/23-06-06-retour-pleinieres-2023/motionUp_hu6cd07605589ec653d3a05196a8ac57c6_16926_2a6cee6b9458c3261094b9ea25ae6393.webp 400w,
/post/23-06-06-retour-pleinieres-2023/motionUp_hu6cd07605589ec653d3a05196a8ac57c6_16926_7eca80373bf10bdf049b5cddffa7c16c.webp 760w,
/post/23-06-06-retour-pleinieres-2023/motionUp_hu6cd07605589ec653d3a05196a8ac57c6_16926_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/motionUp_hu6cd07605589ec653d3a05196a8ac57c6_16926_2a6cee6b9458c3261094b9ea25ae6393.webp"
width="300"
height="129"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Startup Motion-Up : &lt;a href="https://www.motion-up.com/" target="_blank" rel="noopener">https://www.motion-up.com/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h1 id="session-art-et-science">Session &amp;ldquo;Art et Science&amp;rdquo;&lt;/h1>
&lt;h2 id="benoit-arbelot-th√©oriz-">Benoit Arbelot (Th√©oriz) :&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_theoriz_hu7fef5788bd28ca160c0fe5ce76757543_136186_1a2edc89d3b1ce1f2ec674448f76465b.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_theoriz_hu7fef5788bd28ca160c0fe5ce76757543_136186_44ae3d3d5442529e9be9600d36aa15f7.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_theoriz_hu7fef5788bd28ca160c0fe5ce76757543_136186_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_theoriz_hu7fef5788bd28ca160c0fe5ce76757543_136186_1a2edc89d3b1ce1f2ec674448f76465b.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Theoriz est un studio de cr√©ation artistique et technologique sp√©cialis√© dans la conception d&amp;rsquo;installations immersives et de spectacles audiovisuels innovants. Compos√© d&amp;rsquo;une √©quipe d&amp;rsquo;ing√©nieurs, d&amp;rsquo;artistes et de d√©veloppeurs cr√©atifs, Theoriz combine recherche artistique et scientifique pour cr√©er de nouvelles exp√©riences uniques. Du m√©lange entre le r√©el, le virtuel et la po√©sie, leurs installations artistiques sont expos√©es √† travers le monde.&lt;/p>
&lt;p>Beno√Æt Arbelot, ing√©nieur √† Theoriz, a pr√©sent√© diff√©rents projets men√©s par le studio et les technologies developp√©es pour ces projets.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/Presentation%20THEORIZ%20IG-RV%202023-05-30.pdf"> Acc√©der √† la pr√©sentation &lt;/a>&lt;/p>
&lt;p>
&lt;figure id="figure-benoit-arbelot">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Benoit Arbelot" srcset="
/post/23-06-06-retour-pleinieres-2023/benoitA_hu08263980ec618ada007391c65888356b_19067_f1075cea404a52fdb6f860460d515b47.webp 400w,
/post/23-06-06-retour-pleinieres-2023/benoitA_hu08263980ec618ada007391c65888356b_19067_d5e0351ea34d52a2725611f1831a6c16.webp 760w,
/post/23-06-06-retour-pleinieres-2023/benoitA_hu08263980ec618ada007391c65888356b_19067_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/benoitA_hu08263980ec618ada007391c65888356b_19067_f1075cea404a52fdb6f860460d515b47.webp"
width="192"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Benoit Arbelot
&lt;/figcaption>&lt;/figure>
&lt;figure id="figure-th√©oriz">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Th√©oriz" srcset="
/post/23-06-06-retour-pleinieres-2023/theoriz_hu080ec4554bb77cb9791d92479736430b_15181_6da81c871544d422287596d0a8140e6d.webp 400w,
/post/23-06-06-retour-pleinieres-2023/theoriz_hu080ec4554bb77cb9791d92479736430b_15181_b3ec9acd9042766eea34f53660aac7bd.webp 760w,
/post/23-06-06-retour-pleinieres-2023/theoriz_hu080ec4554bb77cb9791d92479736430b_15181_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/theoriz_hu080ec4554bb77cb9791d92479736430b_15181_6da81c871544d422287596d0a8140e6d.webp"
width="300"
height="132"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Th√©oriz
&lt;/figcaption>&lt;/figure>&lt;/p>
&lt;h1 id="session-m√©tavers-enjeux-scientifiques-et-impacts">Session &amp;ldquo;M√©tavers: enjeux scientifiques et impacts&amp;rdquo;&lt;/h1>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_metavers2_hu9c8879c4c5db3e353099dc518ed8460d_140385_5df032450ebc378a0eb3762453586a42.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_metavers2_hu9c8879c4c5db3e353099dc518ed8460d_140385_60f216673a916922b3f389952b8e2470.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_metavers2_hu9c8879c4c5db3e353099dc518ed8460d_140385_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_metavers2_hu9c8879c4c5db3e353099dc518ed8460d_140385_5df032450ebc378a0eb3762453586a42.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_metavers_hu5acd42242b1b5ce0f9b4a3a2fbdf55e9_152481_e50d15bc8cd9cb038d0211e847475a89.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_metavers_hu5acd42242b1b5ce0f9b4a3a2fbdf55e9_152481_4cccbde10a5f65303548d991beb3e9d2.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_metavers_hu5acd42242b1b5ce0f9b4a3a2fbdf55e9_152481_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_metavers_hu5acd42242b1b5ce0f9b4a3a2fbdf55e9_152481_e50d15bc8cd9cb038d0211e847475a89.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h2 id="pascal-guitton">Pascal Guitton&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_pascal_hu9c8879c4c5db3e353099dc518ed8460d_118090_83595e6df257e15a36320cc603113e32.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_pascal_hu9c8879c4c5db3e353099dc518ed8460d_118090_45842762334c733ecd70d84fcbf6132e.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_pascal_hu9c8879c4c5db3e353099dc518ed8460d_118090_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_pascal_hu9c8879c4c5db3e353099dc518ed8460d_118090_83595e6df257e15a36320cc603113e32.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Pascal Guitton est professeur √©m√©rite √† l‚Äôuniversit√© de Bordeaux. Ses domaines de recherche sont la r√©alit√© virtuelle et l&amp;rsquo;interaction, notamment dans les syst√®mes num√©riques d&amp;rsquo;enseignement.&lt;/p>
&lt;p>Cette pr√©sentation a abord√© divers questionnements relatifs aux m√©tavers, en mettant en √©vidence leur origine dans des avanc√©es scientifiques, technologiques et culturelles ant√©rieures, ainsi que les implications sp√©cifiques li√©es √† la r√©alit√© virtuelle, aux r√©seaux sociaux, aux jeux vid√©o et les blockchains. Elle a soulev√© des pr√©occupations telles que la protection des donn√©es personnelles, les vols et d√©tournements, les potentielles addictions et manipulations, les probl√®mes de harc√®lement, ainsi que les impacts environnementaux. En conclusion, la pr√©sentation a recommand√© de ne pas √™tre passif face aux m√©tavers, mais d&amp;rsquo;engager des r√©flexions, des recherches et des d√©veloppements appliqu√©s accompagn√©s de questionnements √©thiques, et de consid√©rer la r√©gulation de leur mise en ligne tout en r√©fl√©chissant √† leur utilit√© r√©elle.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/2023%20M%c3%a9tavers%20GDR%20IGRV.pdf"> Acc√©der √† la pr√©sentation &lt;/a>&lt;/p>
&lt;figure id="figure-pascal-guitton-universit√©-de-bordeaux">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Pascal Guitton (Universit√© de Bordeaux)" srcset="
/post/23-06-06-retour-pleinieres-2023/pascalG_hu257b6b91973c7f1feb28ff8993791d90_20319_6b0de9e233947ca3e01e17031ac37e95.webp 400w,
/post/23-06-06-retour-pleinieres-2023/pascalG_hu257b6b91973c7f1feb28ff8993791d90_20319_99c1fc8b985f618b0f4e3645eebe21ec.webp 760w,
/post/23-06-06-retour-pleinieres-2023/pascalG_hu257b6b91973c7f1feb28ff8993791d90_20319_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/pascalG_hu257b6b91973c7f1feb28ff8993791d90_20319_6b0de9e233947ca3e01e17031ac37e95.webp"
width="200"
height="200"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Pascal Guitton (Universit√© de Bordeaux)
&lt;/figcaption>&lt;/figure>
&lt;h2 id="jean-marie-burkhardt">Jean-Marie Burkhardt&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_jmb_hu9c8879c4c5db3e353099dc518ed8460d_144447_d78ae8d6b23979c471398ef1cce62823.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_jmb_hu9c8879c4c5db3e353099dc518ed8460d_144447_45d21e91ff7e640805656ee3a15f48b3.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_jmb_hu9c8879c4c5db3e353099dc518ed8460d_144447_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_jmb_hu9c8879c4c5db3e353099dc518ed8460d_144447_d78ae8d6b23979c471398ef1cce62823.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Jean-Marie Burkhardt est directeur de recherche √† l&amp;rsquo;Univ. Gustave Eiffel au laboratoire de psychologie et d&amp;rsquo;ergonomie appliqu√©es (LaPEA). Il d√©veloppe des recherches en ergonomie et psychologie sur deux axes : d&amp;rsquo;une part des √©tudes sur les activit√©s, les facteurs de risques et la pr√©vention d&amp;rsquo;accidents dans le domaine des mobilit√©s et, d&amp;rsquo;autre part, sur la conception-centr√©e utilit√© des technologies √©mergentes telles que la r√©alit√© virtuelle, augment√©e et mixte.&lt;/p>
&lt;p>Il a pr√©sent√© la m√©thodologie ainsi qu&amp;rsquo;un r√©sum√© du rapport de l&amp;rsquo;ANSES sur l&amp;rsquo;exposition aux technologies de r√©alit√© virtuelle et/ou augment√©e.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/BurkhardtVR&amp;amp;ARHealthEffectsGDRIGRV2023.pdf"> Acc√©der √† la pr√©sentation &lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.anses.fr/fr/system/files/AP2017SA0076Ra.pdf" target="_blank" rel="noopener">Lien vers le rapport ANSES&lt;/a>&lt;/p>
&lt;figure id="figure-jean-marie-burkhardt-universit√©-gustave-eiffel--httpswwwifsttarfrmenu-hautannuairefiche-personnellepersonneburkhardt-jean-marie">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Jean-Marie Burkhardt (Universit√© Gustave Eiffel) : https://www.ifsttar.fr/menu-haut/annuaire/fiche-personnelle/personne/burkhardt-jean-marie/" srcset="
/post/23-06-06-retour-pleinieres-2023/jeanMarieB_hucfca0eb1b5c0afb5dbb0ceab0dda51c7_113984_e3f4ef1a3a3c9fc8846650baa5a5c851.webp 400w,
/post/23-06-06-retour-pleinieres-2023/jeanMarieB_hucfca0eb1b5c0afb5dbb0ceab0dda51c7_113984_a975f74ef6c1ab3348dc9e833b86f0b0.webp 760w,
/post/23-06-06-retour-pleinieres-2023/jeanMarieB_hucfca0eb1b5c0afb5dbb0ceab0dda51c7_113984_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/jeanMarieB_hucfca0eb1b5c0afb5dbb0ceab0dda51c7_113984_e3f4ef1a3a3c9fc8846650baa5a5c851.webp"
width="203"
height="203"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Jean-Marie Burkhardt (Universit√© Gustave Eiffel) : &lt;a href="https://www.ifsttar.fr/menu-haut/annuaire/fiche-personnelle/personne/burkhardt-jean-marie/" target="_blank" rel="noopener">https://www.ifsttar.fr/menu-haut/annuaire/fiche-personnelle/personne/burkhardt-jean-marie/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="r√©mi-ronfard">R√©mi Ronfard&lt;/h2>
&lt;p>R√©mi Ronfard est directeur de recherche √† Inria, et dirige l&amp;rsquo;√©quipe Anima d&amp;rsquo;Inria Grenoble Rhone Alpes. Sa recherche porte sur les mod√®les informatiques de la narration visuelle et de la r√©alisation de films, et plus pr√©cisement sur le d√©veloppement d&amp;rsquo;outils informatiques pour la r√©alisation de films d&amp;rsquo;animation et de jeux interactifs, utilisant des d√©cors virtuels, des acteurs, des cam√©ras et des lumi√®res.&lt;/p>
&lt;p>Il a pr√©sent√© les r√©sultats d&amp;rsquo;une mission exploratoire sur les m√©tavers, en d√©finissant tout d&amp;rsquo;abord les diff√©rents types de metavers puis les principaux axes de reflexion autour d&amp;rsquo;une strat√©gie metaversique, des questions de socit√©t√© soulev√©es par le metavers aux besoins de r√©gulation.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/Metavers%20-%20Mai%202023_R%c3%a9mi%20Ronfard.pdf"> Acc√©der √† la pr√©sentation &lt;/a>&lt;/p>
&lt;figure id="figure-r√©mi-ronfard-inria--httpsteaminriafranimaremi-ronfard">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="R√©mi Ronfard (INRIA) : https://team.inria.fr/anima/remi-ronfard/" srcset="
/post/23-06-06-retour-pleinieres-2023/remiR_hu9c16a90acf421e3d00babe2090f04297_44442_637b1b551e835c60df9a41c0ad8baf04.webp 400w,
/post/23-06-06-retour-pleinieres-2023/remiR_hu9c16a90acf421e3d00babe2090f04297_44442_dfb8f655f6e48cd75f46215658a2d5a2.webp 760w,
/post/23-06-06-retour-pleinieres-2023/remiR_hu9c16a90acf421e3d00babe2090f04297_44442_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/remiR_hu9c16a90acf421e3d00babe2090f04297_44442_637b1b551e835c60df9a41c0ad8baf04.webp"
width="234"
height="300"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
R√©mi Ronfard (INRIA) : &lt;a href="https://team.inria.fr/anima/remi-ronfard/" target="_blank" rel="noopener">https://team.inria.fr/anima/remi-ronfard/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h1 id="session-futur-du">Session &amp;ldquo;futur du&amp;hellip;&amp;rdquo;&lt;/h1>
&lt;h2 id="george-drettakis">George Drettakis&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_george_hu9c8879c4c5db3e353099dc518ed8460d_136296_f587f6a54c6f00212b1e3c549478a415.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_george_hu9c8879c4c5db3e353099dc518ed8460d_136296_0b2ce6c6efb040ede3efba0b81eb1efd.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_george_hu9c8879c4c5db3e353099dc518ed8460d_136296_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_george_hu9c8879c4c5db3e353099dc518ed8460d_136296_f587f6a54c6f00212b1e3c549478a415.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>George Drettakis est Directeur de recherche √† Inria et dirige l&amp;rsquo;√©quipe GraphDeco d&amp;rsquo;Inria Sophia Antipolis Mediterran√©e. Ses recherches portent sur le rendu et les textures √† base d&amp;rsquo;images, l&amp;rsquo;illumination interactive, les ombres, le r√©√©clairage et le rendu interactif en g√©n√©ral.&lt;/p>
&lt;p>Il a pr√©sent√© une perspective personnelle de l&amp;rsquo;√©volution du rendu graphique, remontant dans le temps pour retracer l&amp;rsquo;histoire du rendu graphique, en mettant en √©vidence les probl√®mes ouverts et les avanc√©es majeures, et abordant √©galement les r√©centes avanc√©es dans le domaine du rendu neuronal, ainsi que les opportunit√©s identifi√©es pour l&amp;rsquo;avenir du rendu.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/The%20Future%20of%20RenderingNoVideos.pdf"> Acc√©der √† la pr√©sentation (pdf sans vid√©o)&lt;/a>&lt;/p>
&lt;figure id="figure-george-drettakis-inria-sophia-antipolis---httpwww-sopinriafrmembersgeorgedrettakis">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="George Drettakis (INRIA, Sophia-Antipolis) : http://www-sop.inria.fr/members/George.Drettakis/" srcset="
/post/23-06-06-retour-pleinieres-2023/georgeG_hu72bbbbec7c0329f3a5c49a314d1884d9_17120_35b59389f50208e366425b87190f0fdb.webp 400w,
/post/23-06-06-retour-pleinieres-2023/georgeG_hu72bbbbec7c0329f3a5c49a314d1884d9_17120_fde72d84b2a811cfc1e06cb35cc069e0.webp 760w,
/post/23-06-06-retour-pleinieres-2023/georgeG_hu72bbbbec7c0329f3a5c49a314d1884d9_17120_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/georgeG_hu72bbbbec7c0329f3a5c49a314d1884d9_17120_35b59389f50208e366425b87190f0fdb.webp"
width="224"
height="300"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
George Drettakis (INRIA, Sophia-Antipolis) : &lt;a href="http://www-sop.inria.fr/members/George.Drettakis/" target="_blank" rel="noopener">http://www-sop.inria.fr/members/George.Drettakis/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="tamy-boubekeur">Tamy Boubekeur&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_tamy_hu9c8879c4c5db3e353099dc518ed8460d_138717_116cf2393d099063aa08a3a187d3b539.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_tamy_hu9c8879c4c5db3e353099dc518ed8460d_138717_744ff97b0bc97286aed654d48608148b.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_tamy_hu9c8879c4c5db3e353099dc518ed8460d_138717_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_tamy_hu9c8879c4c5db3e353099dc518ed8460d_138717_116cf2393d099063aa08a3a187d3b539.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Tamy Boubekeur est actuellement directeur de laboratoire et chercheur chez Adobe Research, ainsi que professeur au d√©partement d&amp;rsquo;informatique de l&amp;rsquo;Ecole Polytechnique, Institut Polytechnique de Paris. Ses domaines de recherche personnels se concentrent sur l&amp;rsquo;infographie 3D, avec un int√©r√™t particulier pour la mod√©lisation, le rendu et l&amp;rsquo;apprentissage efficace des donn√©es 3D.&lt;/p>
&lt;p>Il a pr√©sent√© diff√©rents projets autour d&amp;rsquo;outils d&amp;rsquo;√©dition et de cr√©ation de contenu 3D (textures, g√©om√©trie&amp;hellip;), en insistant sur l&amp;rsquo;aspect multi-scalaire de ces diff√©rentes solutions.&lt;/p>
&lt;figure id="figure-tamy-boubekeur-adobe-research-httpsresearchadobecompersontamy-boubekeur">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Tamy Boubekeur (Adobe Research) https://research.adobe.com/person/tamy-boubekeur/" srcset="
/post/23-06-06-retour-pleinieres-2023/tamyB_hub3758cf5bb13ac6ae63ed1850f9b1d9b_30430_9aa187625280cf41b3045cc80a76d935.webp 400w,
/post/23-06-06-retour-pleinieres-2023/tamyB_hub3758cf5bb13ac6ae63ed1850f9b1d9b_30430_8231019291c6feeeaf9e67a1a617b73e.webp 760w,
/post/23-06-06-retour-pleinieres-2023/tamyB_hub3758cf5bb13ac6ae63ed1850f9b1d9b_30430_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/tamyB_hub3758cf5bb13ac6ae63ed1850f9b1d9b_30430_9aa187625280cf41b3045cc80a76d935.webp"
width="300"
height="300"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Tamy Boubekeur (Adobe Research) &lt;a href="https://research.adobe.com/person/tamy-boubekeur/" target="_blank" rel="noopener">https://research.adobe.com/person/tamy-boubekeur/&lt;/a>
&lt;/figcaption>&lt;/figure></description></item><item><title>Retour mobilit√©s inter-laboratoires 2022</title><link>https://gdr-igrv.fr/post/23-04-28-retours-mobilites/</link><pubDate>Fri, 28 Apr 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/23-04-28-retours-mobilites/</guid><description>&lt;p>&lt;em>L&amp;rsquo;action de mobilit√© entre laboratoires fran√ßais via le financement de court s√©jour d&amp;rsquo;un doctorant ou d&amp;rsquo;un enseignant-chercheur/chercheur du GdR a permis la r√©alisation de 5 mobilit√©s en 2022.&lt;/em>&lt;/p>
&lt;h3 id="myriam-servieres--aau-nantes--lab-sticc-brest--8-9-d√©cembre-2022">Myriam Servieres ‚Äì AAU (Nantes) / Lab-STICC (Brest) ‚Äì 8-9 d√©cembre 2022&lt;/h3>
&lt;figure id="figure-exemple-de-reprojection-en-r√©alit√©-augment√©e-dune-maquette-urbaine-25d-sur-site">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Exemple de reprojection en R√©alit√© Augment√©e d&amp;#39;une maquette urbaine 2,5D sur site" srcset="
/post/23-04-28-retours-mobilites/myriam1_hu05c4f0a142292c4bbb2ef93a53ddbc36_1023014_24892c166e53527f877492c285508548.webp 400w,
/post/23-04-28-retours-mobilites/myriam1_hu05c4f0a142292c4bbb2ef93a53ddbc36_1023014_ab6706a7ba6d8e31ffe55cd1a74ae705.webp 760w,
/post/23-04-28-retours-mobilites/myriam1_hu05c4f0a142292c4bbb2ef93a53ddbc36_1023014_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/myriam1_hu05c4f0a142292c4bbb2ef93a53ddbc36_1023014_24892c166e53527f877492c285508548.webp"
width="760"
height="528"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Exemple de reprojection en R√©alit√© Augment√©e d&amp;rsquo;une maquette urbaine 2,5D sur site
&lt;/figcaption>&lt;/figure>
&lt;p>La visite du jeudi 8 au vendredi 9 d√©cembre sur le site de l‚ÄôIMT Atlantique de Myriam Servi√®res a permis de renforcer les collaborations entre les √©quipes AAU - Cr√©nau et Lab-STICC - INUIT. Le groupe de recherche 3V d&amp;rsquo;AAU se concentre sur le triptyque vision-visibilit√©-visualisation qui articule l&amp;rsquo;utilisation de donn√©es urbaines 3D spatiales et temporelles avec la primaut√© de l&amp;rsquo;aspect visuel et l&amp;rsquo;instrumentation num√©rique. L&amp;rsquo;√©quipe INUIT se focalise sur des solutions technologiques immersives et leur √©valuation pour am√©liorer leur naturalit√© et se concentre sur la proposition ou l‚Äôam√©lioration de ces dispositifs d‚Äôinteractions. Lors de cette visite, des collaborations portant sur la perception des visibilit√©s et des affordances dans un contexte urbain (perception d&amp;rsquo;ambiances lumineuses, perception des vuln√©rabilit√©s pour une ville inclusive) ont notamment √©t√© initi√©es.&lt;/p>
&lt;h3 id="charline-grenier--icube-strasbourg--liris-lyon--novembre-2022">Charline Grenier ‚Äì ICube (Strasbourg) / LIRIS (Lyon) ‚Äì novembre 2022&lt;/h3>
&lt;p>
&lt;figure id="figure-repr√©sentation-dun-terrain-√†-deux-√©tapes-d√©dition-par-un-artiste">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Repr√©sentation d&amp;#39;un terrain √† deux √©tapes d&amp;#39;√©dition par un artiste" srcset="
/post/23-04-28-retours-mobilites/charline1_hu1843963492ea4dd6523f38cabcb0fb96_1759404_af661668f8333339c78518dc05c31fc1.webp 400w,
/post/23-04-28-retours-mobilites/charline1_hu1843963492ea4dd6523f38cabcb0fb96_1759404_d851018ecd14b8ff16caea81ce902b99.webp 760w,
/post/23-04-28-retours-mobilites/charline1_hu1843963492ea4dd6523f38cabcb0fb96_1759404_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/charline1_hu1843963492ea4dd6523f38cabcb0fb96_1759404_af661668f8333339c78518dc05c31fc1.webp"
width="760"
height="285"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Repr√©sentation d&amp;rsquo;un terrain √† deux √©tapes d&amp;rsquo;√©dition par un artiste
&lt;/figcaption>&lt;/figure>
&lt;figure id="figure-exemples-de-motifs-proc√©duraux-structur√©s">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Exemples de motifs proc√©duraux structur√©s" srcset="
/post/23-04-28-retours-mobilites/charline2_hu18774e19196f82bf9be7504bf3df1f71_387996_028f5d24e713430d68f36dff028f9d76.webp 400w,
/post/23-04-28-retours-mobilites/charline2_hu18774e19196f82bf9be7504bf3df1f71_387996_b1f651ae26d93a04a9800c973df1dbf6.webp 760w,
/post/23-04-28-retours-mobilites/charline2_hu18774e19196f82bf9be7504bf3df1f71_387996_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/charline2_hu18774e19196f82bf9be7504bf3df1f71_387996_028f5d24e713430d68f36dff028f9d76.webp"
width="760"
height="214"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Exemples de motifs proc√©duraux structur√©s
&lt;/figcaption>&lt;/figure>&lt;/p>
&lt;p>Dans le cadre d&amp;rsquo;une th√®se men√©e au laboratoire ICube portant sur la g√©n√©ration et le rendu de textures proc√©durales, en particulier la synth√®se de motifs structur√©s, une collaboration avec l&amp;rsquo;√©quipe Origami du LIRIS a √©t√© initi√©e √† Lyon. Eric Gu√©rin y travaille sur la cr√©ation, l&amp;rsquo;√©dition et le rendu de terrains virtuels. Il a √©t√© constat√© que des d√©tails structur√©s pr√©sents dans les paysages r√©els sont difficiles √† g√©n√©rer et √† contr√¥ler en utilisant les m√©thodes sp√©cifiques √† la g√©n√©ration de terrains. Ainsi, les m√©thodes de g√©n√©ration de textures structur√©es ont √©t√© explor√©es en vue de leur utilisation pour la g√©n√©ration de terrains, les algorithmes de synth√®se de textures permettant une g√©n√©ration proc√©durale, √† la vol√©e et offrant un bon contr√¥le du r√©sultat final.&lt;/p>
&lt;h3 id="boris-bordeaux--lib-dijon--imag-montpellier--12-16-d√©cembre-2022">Boris Bordeaux ‚Äì LIB (Dijon) / IMAG (Montpellier) ‚Äì 12-16 d√©cembre 2022&lt;/h3>
&lt;figure id="figure-illustration-du-lien-entre-les-empilements-de-sph√®res-et-le-mod√®le-bc-ifs-gauche-et-centre-exemple-3d-dempilements-de-sph√®res-droite">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Illustration du lien entre les empilements de sph√®res et le mod√®le BC-IFS (gauche et centre), Exemple 3D d&amp;#39;empilements de sph√®res (droite)" srcset="
/post/23-04-28-retours-mobilites/boris12_hu036c17802d5fe26f48480c161d879ffc_840337_65ea3045e82dcbf5625ba2b5e7d2f9cb.webp 400w,
/post/23-04-28-retours-mobilites/boris12_hu036c17802d5fe26f48480c161d879ffc_840337_6c685e8397d07f4b4acf1b1742629f9c.webp 760w,
/post/23-04-28-retours-mobilites/boris12_hu036c17802d5fe26f48480c161d879ffc_840337_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/boris12_hu036c17802d5fe26f48480c161d879ffc_840337_65ea3045e82dcbf5625ba2b5e7d2f9cb.webp"
width="760"
height="232"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Illustration du lien entre les empilements de sph√®res et le mod√®le BC-IFS (gauche et centre), Exemple 3D d&amp;rsquo;empilements de sph√®res (droite)
&lt;/figcaption>&lt;/figure>
&lt;p>La mobilit√© s‚Äôinscrit dans le cadre d‚Äôun projet visant √† concevoir des structures
lacunaires fractales. Le LIB d√©veloppe des mod√®les it√©ratifs codant la topologie de structures
fractales. Cependant la conception des structures 3D reste une d√©marche complexe et manuelle.
D‚Äôautre part, l‚ÄôIMAG d√©veloppe des m√©thodes automatiques de construction d‚Äôempilements de
sph√®res, produisant des structures fractales. La compl√©mentarit√© des approches permet d‚Äôenvisager
de d√©velopper des m√©thodes de conceptions automatiques et param√©trables de structures lacunaires
3D.&lt;/p>
&lt;h3 id="manon-vialle--ljk-grenoble--ex-situ-paris-saclay--novembre-d√©cembre-2022">Manon Vialle ‚Äì LJK (Grenoble) / Ex-Situ (Paris-Saclay) ‚Äì novembre-d√©cembre 2022&lt;/h3>
&lt;figure id="figure-danseur-professionnel-utilisant-le-syst√®me-gauche-exemple-de-visualisation-droite">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Danseur professionnel utilisant le syst√®me (gauche), Exemple de visualisation (droite)" srcset="
/post/23-04-28-retours-mobilites/manon12_huab49302ee272980f5597d400c47ae82b_2148048_6dea2bdbd120a40ba61f3b250fa07198.webp 400w,
/post/23-04-28-retours-mobilites/manon12_huab49302ee272980f5597d400c47ae82b_2148048_1bc2a56ec8df231b291ae567912482e7.webp 760w,
/post/23-04-28-retours-mobilites/manon12_huab49302ee272980f5597d400c47ae82b_2148048_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/manon12_huab49302ee272980f5597d400c47ae82b_2148048_6dea2bdbd120a40ba61f3b250fa07198.webp"
width="760"
height="282"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Danseur professionnel utilisant le syst√®me (gauche), Exemple de visualisation (droite)
&lt;/figcaption>&lt;/figure>
&lt;p>Cette mobilit√© s&amp;rsquo;inscrit dans le cadre du projet Isadora, une archive vivante √©labor√©e en collaboration avec les √©quipes Inria Anima et Ex-Situ, le Centre National de la Danse, la danseuse Elisabeth Schwartz et le mocaplab. Le travail de la th√®se associ√©e a consist√© √† √©laborer des mod√®les abstraits du corps des danseurs pour transmettre des qualit√©s intrins√®ques de mouvement telles que la fluidit√©.
Sa th√®se a √©volu√© vers un sujet beaucoup plus centr√© sur l&amp;rsquo;Interaction Humain Machine, notamment dans le cadre de son deuxi√®me projet sur la spatialisation du mouvement. Pour r√©pondre √† ces nouveaux d√©fis, cette mobilit√© de 6 semaines a permis une formation en profondeur dans ce domaine au sein du laboratoire Ex-situ pour profiter de leur expertise et suivre les formations propos√©es par les membres de l&amp;rsquo;√©quipe et la facult√© de Paris Saclay, ainsi qu‚Äôun formation en danse avec la danseuse Elisabeth Schwartz. De plus, un prototype de spatialisation du mouvement en r√©alit√© augment√©e a √©t√© mis au point, en se basant sur une collaboration √©troite avec Elisabeth Schwarz et en suivant une m√©thode de co-design. Ce prototype a √©t√© test√© et √©valu√© lors d‚Äôun workshop avec des danseurs. Tous ces travaux ont men√© √† une publication √† venir dans la conf√©rence Creativity and Cognition 2023.&lt;/p>
&lt;h3 id="florian-beguet--lis-marseille--lib-dijon--d√©cembre-2022">Florian Beguet ‚Äì LIS (Marseille) / LIB (Dijon) ‚Äì d√©cembre 2022&lt;/h3>
&lt;figure id="figure-a-morceau-dune-brique-fragment√©e-sur-lequel-est-plaqu√©-la-dimension-de-corr√©lation-b-graphe-de-reeb-correspondant-√†-a-c-segmentation-de-la-brique-√†-partir-dun-partitionnement-du-graphe">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="A. Morceau d‚Äôune brique fragment√©e sur lequel est plaqu√© la dimension de corr√©lation. B. Graphe de Reeb correspondant √† A. C. Segmentation de la brique √† partir d‚Äôun partitionnement du graphe" srcset="
/post/23-04-28-retours-mobilites/florian1_huf664376d31a2a3a4cd08d922419f6fe8_520290_624ebd8bb7cdbbe7698c102f4c792c4d.webp 400w,
/post/23-04-28-retours-mobilites/florian1_huf664376d31a2a3a4cd08d922419f6fe8_520290_78fb2a621001e25e6fba4f87ac96a38a.webp 760w,
/post/23-04-28-retours-mobilites/florian1_huf664376d31a2a3a4cd08d922419f6fe8_520290_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/florian1_huf664376d31a2a3a4cd08d922419f6fe8_520290_624ebd8bb7cdbbe7698c102f4c792c4d.webp"
width="760"
height="291"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
A. Morceau d‚Äôune brique fragment√©e sur lequel est plaqu√© la dimension de corr√©lation. B. Graphe de Reeb correspondant √† A. C. Segmentation de la brique √† partir d‚Äôun partitionnement du graphe
&lt;/figcaption>&lt;/figure>
&lt;p>Cette mobilit√© se place dans le cadre du projet de recherche intitul√© &amp;ldquo;Caract√©risation de pi√®ces arch√©ologiques&amp;rdquo;, en collaboration entre le laboratoire LIB de l&amp;rsquo;Universit√© de Bourgogne, le laboratoire ArteHis de Dijon et l&amp;rsquo;USTH de Hanoi (Vietnam). L&amp;rsquo;objectif de ce projet est de caract√©riser les zones de fracture sur des mod√®les arch√©ologiques num√©ris√©s afin de les apparier et les reconstruire. Une m√©thode bas√©e sur l&amp;rsquo;utilisation d&amp;rsquo;un graphe de Reeb, calcul√© sur une fonction d&amp;rsquo;indice de forme, a √©t√© d√©velopp√©e pour extraire des caract√©ristiques autosimilaires avec des contraintes a priori sur une surface maill√©e. Cette mobilit√© a √©t√© effectu√©e dans l&amp;rsquo;optique de pr√©senter ces travaux aux √©quipes impliqu√©es dans le projet ainsi que les deux hypoth√®ses suivantes. La premi√®re hypoth√®se est que cette approche pourrait √™tre appliqu√©e pour l&amp;rsquo;extraction de zones de fractures en modifiant la fonction d&amp;rsquo;indice de forme avec une fonction bas√©e sur la g√©om√©trie mais plus adapt√©e. Des premiers r√©sultats issus des discussions avec les √©quipes ont permis d‚Äôidentifier une fonction de rugosit√© bas√©e sur la dimension de corr√©lation. Le graphe de Reeb de cette fonction a ensuite permis d‚Äôisoler les r√©gions rugueuses correspondantes aux zones fractur√©s. La seconde hypoth√®se abord√©e a √©t√© qu‚Äôune approche multi-r√©solution permettrait d&amp;rsquo;√©viter l&amp;rsquo;influence du bruit pour la d√©tection des fractures tout en conservant les informations importantes pour l&amp;rsquo;appariement.&lt;/p>
&lt;h3 id="phuc-ngo--loria-nancy--greyc-caen--d√©cembre-2022">Phuc Ngo ‚Äì Loria (Nancy) / GREYC (Caen) ‚Äì d√©cembre 2022&lt;/h3>
&lt;figure id="figure-exemples-de-courbes-tangentielles-adaptatives-sur-des-courbes-num√©riques-bruit√©es-en-2d-et-3d">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Exemples de courbes tangentielles adaptatives sur des courbes num√©riques bruit√©es en 2D et 3D" srcset="
/post/23-04-28-retours-mobilites/phuc1_hu8213736187bcd5b0f03ce3d45078c0a8_44210_82d20a86fc609d268280bfbab56c07a7.webp 400w,
/post/23-04-28-retours-mobilites/phuc1_hu8213736187bcd5b0f03ce3d45078c0a8_44210_7d75592d6e8c1c6ef2639595b7873694.webp 760w,
/post/23-04-28-retours-mobilites/phuc1_hu8213736187bcd5b0f03ce3d45078c0a8_44210_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/phuc1_hu8213736187bcd5b0f03ce3d45078c0a8_44210_82d20a86fc609d268280bfbab56c07a7.webp"
width="760"
height="253"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Exemples de courbes tangentielles adaptatives sur des courbes num√©riques bruit√©es en 2D et 3D
&lt;/figcaption>&lt;/figure>
&lt;p>Pendant son s√©jour, Phuc Ngo a √©t√© accueillie par Mme Kenmochi ainsi que les membres de l&amp;rsquo;√©quipe Image. Les travaux de recherche ont √©t√© pr√©sent√©s devant l&amp;rsquo;√©quipe, se concentrant notamment sur le th√®me de l&amp;rsquo;&amp;ldquo;√âtude g√©om√©trique des courbes discr√®tes bruit√©es&amp;rdquo;. Des discussions enrichissantes ont eu lieu sur ce sujet, avec des propositions de collaboration pour l&amp;rsquo;exploration d&amp;rsquo;applications li√©es aux Line-arts.&lt;/p></description></item><item><title>Remise du prix de th√®se du GdR et des associations 2022</title><link>https://gdr-igrv.fr/post/22-11-23-remiseprix/</link><pubDate>Wed, 23 Nov 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-11-23-remiseprix/</guid><description>&lt;p>√Ä l&amp;rsquo;occasion des &lt;a href="https://project.inria.fr/jfig2022/" target="_blank" rel="noopener">Journ√©es Fran√ßaises de l&amp;rsquo;Informatique Graphique&lt;/a>, le &lt;a href="https://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">prix de th√®se&lt;/a> du GdR a pu √™tre remis √†
&lt;strong>Marie-Julie Rakotosaona&lt;/strong> pour sa th√®se intitul√©e ¬´ Learning-based representations and methods for 3D shape analysis, manipulation and reconstruction ¬ª effectu√©e sous la direction de Maks Ovsjanikov (Ecole Polytechnique), ainsi qu&amp;rsquo;a l&amp;rsquo;accessit &lt;strong>Mickael Ly&lt;/strong> pour sa th√®se intitul√©e ¬´ Static inverse modelling of cloth ¬ª effectu√©e sous la direction de Florence Bertails-Descoubes et MeÃÅlina Skouras (Universit√© Grenoble Alpes).&lt;/p>
&lt;p>Le prix a √©t√© remis par les organisateurs du Prix de th√®se loic-barthe (Univ Toulouse) et &lt;a href="https://gdr-igrv.fr/author/guillaume-cordonnier/">Guillaume Cordonnier&lt;/a> (INRIA CRISAM), ainsi que les pr√©sidents de l&amp;rsquo;AFIG, &lt;strong>Basile Sauvage&lt;/strong> et du Chapitre Fran√ßais d&amp;rsquo;Eurographics (EGFR), &lt;strong>Eric Gu√©rin&lt;/strong>.&lt;/p>
&lt;p>&lt;em>(photos Adrien Peytavie)&lt;/em>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_172723_hud3ce0b3b38481c0ea27135a835283fab_2805756_60b365b34ce9cb27b1df7769ea051c72.webp 400w,
/post/22-11-23-remiseprix/20221123_172723_hud3ce0b3b38481c0ea27135a835283fab_2805756_29cf4ae4033e9529308c996cd84b1c00.webp 760w,
/post/22-11-23-remiseprix/20221123_172723_hud3ce0b3b38481c0ea27135a835283fab_2805756_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_172723_hud3ce0b3b38481c0ea27135a835283fab_2805756_60b365b34ce9cb27b1df7769ea051c72.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_172743_hua50e7117982b565cc0b0f764b8b3b9d2_2114314_ba3b286d4bea5575349094bd89907b71.webp 400w,
/post/22-11-23-remiseprix/20221123_172743_hua50e7117982b565cc0b0f764b8b3b9d2_2114314_45cfbb7253322098b5a56744af4aa7a0.webp 760w,
/post/22-11-23-remiseprix/20221123_172743_hua50e7117982b565cc0b0f764b8b3b9d2_2114314_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_172743_hua50e7117982b565cc0b0f764b8b3b9d2_2114314_ba3b286d4bea5575349094bd89907b71.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_174320_hu69382911a582d6fbf3859e12ac368478_2303140_8efe182c2c115d143687c91e793400ee.webp 400w,
/post/22-11-23-remiseprix/20221123_174320_hu69382911a582d6fbf3859e12ac368478_2303140_96f2169970216653a294afc252bc33de.webp 760w,
/post/22-11-23-remiseprix/20221123_174320_hu69382911a582d6fbf3859e12ac368478_2303140_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_174320_hu69382911a582d6fbf3859e12ac368478_2303140_8efe182c2c115d143687c91e793400ee.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_173620_hufb48cd73a43893dd483037dc398548de_2050686_fa015a34a99a42d6374f7fd80c354532.webp 400w,
/post/22-11-23-remiseprix/20221123_173620_hufb48cd73a43893dd483037dc398548de_2050686_0622becc3ce7aae721acc505e9d6fc89.webp 760w,
/post/22-11-23-remiseprix/20221123_173620_hufb48cd73a43893dd483037dc398548de_2050686_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_173620_hufb48cd73a43893dd483037dc398548de_2050686_fa015a34a99a42d6374f7fd80c354532.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_173654_hu51f8342bdb8708cc4a8c61c715f51df8_2813139_da9e11338f69ae7a0640206fd081b5d6.webp 400w,
/post/22-11-23-remiseprix/20221123_173654_hu51f8342bdb8708cc4a8c61c715f51df8_2813139_f48b5af28d78b8d9f359a668ba2323d2.webp 760w,
/post/22-11-23-remiseprix/20221123_173654_hu51f8342bdb8708cc4a8c61c715f51df8_2813139_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_173654_hu51f8342bdb8708cc4a8c61c715f51df8_2813139_da9e11338f69ae7a0640206fd081b5d6.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Evelyn Paiz - Visual exploration of historical image collections: an interactive approach through space and time</title><link>https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/</link><pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/</guid><description>&lt;h3 id="what-is-your-current-research-status">What is your current research status?&lt;/h3>
&lt;p>Last year, I finished my PhD at IGN, and defended it in December 2021. I&amp;rsquo;m currently a research and development engineer at Viceversa, a company that aims at transferring object from the real world to the metaverse. For example, a company could own this object and visualize it online. This can also be used for gaming applications.&lt;/p>
&lt;h3 id="can-you-describe-your-research-work-during-your-phd">Can you describe your research work during your PhD?&lt;/h3>
&lt;p>It was how to visualize digitally historical images. My lab was acquiring a lot of pictures and gather them from other institutions. The objective of the PhD was to present a method for people to visualize these pictures digitally, in 3D, and to explore these pictures in time and space. There were two topics. The first was the rendering of these images: how to render these 2D images in 3D? This includes the issue of the distortion of the pictures during acquisition and how to manage this distortion while projecting the image in a 3D space. We came up with a method to extrapolate the distortion function of these images to be able to correct them during the projection. The second topic was more about how user can interact with the pictures in the 3D space. We presented to the users different methods to be able to interact with the pictures.&lt;/p>
&lt;figure id="figure-3d-city-model-and-various-projected-2d-images">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="3D city model and various projected 2D images. " srcset="
/post/22-10-18-jc-evelynpaiz/image1_hu0a3f105d61626774883345e89c18e174_334289_9ff28b603e9d83b328253b6fd8460143.webp 400w,
/post/22-10-18-jc-evelynpaiz/image1_hu0a3f105d61626774883345e89c18e174_334289_07bde55e15ad20bd96854a1c01c6e0c0.webp 760w,
/post/22-10-18-jc-evelynpaiz/image1_hu0a3f105d61626774883345e89c18e174_334289_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/image1_hu0a3f105d61626774883345e89c18e174_334289_9ff28b603e9d83b328253b6fd8460143.webp"
width="747"
height="587"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
3D city model and various projected 2D images.
&lt;/figcaption>&lt;/figure>
&lt;p>We had different types of data: 2D images but also 3D models, a bit like Google Maps where you can have those two kinds of visualization. IGN has this kind of data for France, and we were using these 3D data and project our &amp;ldquo;old&amp;rdquo; pictures on the model to be able to fill the voids of the images. I was focusing on the distortion part, for the user to have a rectangular image. When you do a projection of a 3D model, you must consider the distortion, otherwise you will have a distortion between the 3D world and the 2D image. If you consider it, your image will be distorted, and you have to correct its shape.&lt;/p>
&lt;p>The second part of the PhD was more tackling how the user can interact with these images when they are in 3D. I was exploring methods like heatmaps, viewpoint markers, adding frames or color values to the images for user to be able to quickly find images among many in 3D.&lt;/p>
&lt;figure id="figure-heatmaps-projected-over-the-3d-scenes-composed-of-point-cloud-geometries">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Heatmaps projected over the 3D scenes composed of point cloud geometries. " srcset="
/post/22-10-18-jc-evelynpaiz/image2_hu6bbd2543e9e115d97f1f9e325937b4e6_192053_26d76d2c3be9b7e954c77fdd9958ff4c.webp 400w,
/post/22-10-18-jc-evelynpaiz/image2_hu6bbd2543e9e115d97f1f9e325937b4e6_192053_269870c228f9c9ecab677a14c76b6b09.webp 760w,
/post/22-10-18-jc-evelynpaiz/image2_hu6bbd2543e9e115d97f1f9e325937b4e6_192053_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/image2_hu6bbd2543e9e115d97f1f9e325937b4e6_192053_26d76d2c3be9b7e954c77fdd9958ff4c.webp"
width="760"
height="433"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Heatmaps projected over the 3D scenes composed of point cloud geometries.
&lt;/figcaption>&lt;/figure>
&lt;p>We presented the images to the user on a screen, to be able to explore the web option. Images came from different institutions, and they all wanted to connect to the same platform. For the interaction we wanted the users to be able to go to the point of view where the image was taken, to be able to see what happen between the contemporary 3D model and the old data that came from the pictures. We also had a timeline where the user was able to filter, for example, just the images of a specific time.&lt;/p>
&lt;figure id="figure-a-timeline-next-to-3d-view-in-histovis-only-five-photos-1946-are-shown-from-the-filtered-selection-credits-to-ignfrejus-collection">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="A timeline next to 3D view in HISTOVIS. Only five photos (1946) are shown from the filtered selection. Credits to IGN/Frejus collection." srcset="
/post/22-10-18-jc-evelynpaiz/image3_hu218bf9f3debedd4e547b8ac03499eacd_571553_ba5ae24f8f0acab802044b992f32db04.webp 400w,
/post/22-10-18-jc-evelynpaiz/image3_hu218bf9f3debedd4e547b8ac03499eacd_571553_33097a98e4848f35a9d9c678d7d4c0a2.webp 760w,
/post/22-10-18-jc-evelynpaiz/image3_hu218bf9f3debedd4e547b8ac03499eacd_571553_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/image3_hu218bf9f3debedd4e547b8ac03499eacd_571553_ba5ae24f8f0acab802044b992f32db04.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
A timeline next to 3D view in HISTOVIS. Only five photos (1946) are shown from the filtered selection. Credits to IGN/Frejus collection.
&lt;/figcaption>&lt;/figure>
&lt;p>The targeted end users were mainly researchers: historian, archivists since we were working with museums. Actually, my PhD was funded by the Alegoria project. The objective was to valorize historical images. This project was conducted by the IGN, the National Archives, and the Nic√©phore Ni√©pce Museum.&lt;/p>
&lt;h3 id="what-is-your-proudest-research-result">What is your proudest research result?&lt;/h3>
&lt;p>I wouldn&amp;rsquo;t cite something specific but rather just reaching and showing the results that I was getting to the final users. When we were working in the Alegoria project, we were having meetings every 6 months and I was able to show results, received feedback and was able to improve on this. I liked that part a lot.&lt;/p>
&lt;h3 id="what-are-your-long-term-perspectives-you-are-working-in-the-industry-now-are-you-done-with-academia">What are your long-term perspectives? You are working in the industry now. Are you done with academia?&lt;/h3>
&lt;p>I think academia was not my long-term target. I did a PhD because I wanted to explore a bit more about research, but I knew that I didn&amp;rsquo;t want to become a teacher. I wanted to go back to industry when the PhD was done. Since I am in the research department of my company, I can still do research but it has some benefits, like being able to produce things faster. We can give to the user some products while sometimes, the users will never see what you do in academic research.&lt;/p>
&lt;h3 id="what-do-you-currently-work-on-in-your-company">What do you currently work on in your company?&lt;/h3>
&lt;p>It&amp;rsquo;s a brand-new company, I just started this month. We are created digital models of luxurious brands. The brands come to create digital models from products that they have, and we use photogrammetry to reproduce the objects. We are also trying to improve the methods they are using to add techniques like photometry to be able to reproduce the objects more accurately. In the end, it enables brands to offer both virtual and real products.&lt;/p>
&lt;h3 id="interesting-and-what-would-be-the-final-utility-of-such-virtual-products">Interesting, and what would be the final utility of such virtual products?&lt;/h3>
&lt;p>We will see in the future! But we envision uses where you can combine the physical and the virtual object to be able to control and to use the virtual object thanks to the real one. Though, my job is more on the technical, photogrammetry and computer graphics side. I also have a background on color science, so that is why we will be working in photometry too.&lt;/p>
&lt;h3 id="are-there-some-collaborations-with-the-gdr-that-would-be-interesting-in-your-current-work">Are there some collaborations with the GDR that would be interesting in your current work?&lt;/h3>
&lt;p>We have no ongoing collaborations with GDR members yet. Nevertheless, it could be a possibility. We are currently interested in exploring new topics regarding graphics, vision, and even virtual reality. I think GDR is a good place to search for all of these research subjects.&lt;/p>
&lt;p>&lt;em>Thank you for your presentation and time. I&amp;rsquo;m sure it would be very interesting for future collaboration, and also for PhD students that are wondering what could be done in industry after a PhD!&lt;/em>&lt;/p></description></item><item><title>Zoom sur... Les collaborations du GDR IG-RV avec le GDR MAGIS et MADICS autour des sciences de l‚Äôinformation g√©ographique</title><link>https://gdr-igrv.fr/post/22-08-25-info-geo-gillesg/</link><pubDate>Thu, 25 Aug 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-08-25-info-geo-gillesg/</guid><description>&lt;p>&lt;em>&lt;a href="https://liris.cnrs.fr/page-membre/gilles-gesquiere" target="_blank" rel="noopener">&lt;strong>Gilles Gesqui√®re&lt;/strong>&lt;/a> pr√©sente les activit√©s transverses entre les GDR IG-RV et les GDR MAGIS et MADICS autour des sciences de l‚Äôinformation g√©ographique qu&amp;rsquo;il coordonne :&lt;/em>&lt;/p>
&lt;p>Je suis membre du Laboratoire LIRIS, UMR 5205. Je fais partie de la communaut√© informatique graphique, o√π j‚Äôai travaill√© en mod√©lisation g√©om√©trique (surfaces implicites, d√©formations de maillages, reconstruction par ing√©nierie inverse, ‚Ä¶). Depuis 2008, mes recherches sont plus ax√©es vers les repr√©sentations et la dynamique de la ville. On y retrouve un besoin tr√®s fort en informatique graphique, en particulier avec une pr√©sence toujours plus importante de donn√©es 3D (polygones, mais aussi nuages de points) repr√©sentant l‚Äôint√©rieur, ou l‚Äôext√©rieur de b√¢timents, voire des territoires plus vastes sur des milliers de km2. Nos recherches am√®nent √† aller au-del√† de l‚Äôinformatique graphique. C‚Äôest en ce sens que le projet que je dirige depuis 2013 (&lt;a href="https://projet.liris.cnrs.fr/vcity/" target="_blank" rel="noopener">Projet Vcity&lt;/a>) est constitu√© de sp√©cialistes en informatique graphique, mais aussi en sciences de donn√©es, deux expertises fortes au laboratoire LIRIS. Un lien tr√®s fort est mis en place avec des entreprises et collectivit√©s.
Cette recherche, au service des territoires, m√™le informatique graphique avec les sciences de l‚Äôinformation g√©ographique et peut donc se retrouver √† l‚Äôinterface entre plusieurs GDR. Le GDR IG-RV y apporte ses comp√©tences en mod√©lisation g√©om√©trique, mais aussi rendu, visualisation et r√©alit√© virtuelle et/ ou augment√©e. Le GDR Magis apporte ses comp√©tences en informatique (en particulier sciences des donn√©es), mais aussi g√©ographie afin de permettre une meilleure compr√©hension des donn√©es, mais aussi des possibles usages. Il est aussi facile de faire des liens avec les GDR MADICS ou le GDR ISIS sur l‚Äôobservation de la terre, l‚Äôacquisition des donn√©es gr√¢ce √† des capteurs toujours plus performants, et la reconstruction 3D. C‚Äôest d‚Äôailleurs en ce sens que nous organisons des √©v√®nements conjoints (voir par exemple la &lt;a href="https://github.com/VCityTeam/MAGIS-AP3D/blob/master/Media/JourneeObservation3D.md" target="_blank" rel="noopener">journ√©e d‚Äô√©tude entre GDR MAGIS, MADICS et IG-RV en novembre 2021&lt;/a>. Nous organisons aussi depuis deux ans un webinaire sur la 3D et le g√©ospatial ; il a lieu tous les premiers jeudi de chaque mois de 12h30 √† 13h30. Il s‚Äôagit de profiter de ces moments pour renforcer encore les liens entre les GDR, en particulier en croisant les expertises (voir &lt;a href="https://github.com/VCityTeam/MAGIS-AP3D/blob/master/Media/README.md" target="_blank" rel="noopener">ici&lt;/a>).&lt;/p>
&lt;p>L‚Äôav√®nement des doubles num√©riques nous am√®ne aujourd‚Äôhui √† pouvoir profiter de nombreuses donn√©es sur nos territoires ; il y a encore 10 ans, les donn√©es 3D √©taient assez difficiles √† obtenir. Comme le montre &lt;a href="https://github.com/VCityTeam/MAGIS-AP3D/blob/master/data.md" target="_blank" rel="noopener">cette liste en cours de construction&lt;/a>, il existe aujourd‚Äôhui de nombreuses sources de donn√©es repr√©sentant des territoires toujours plus vastes, que ce soit sous la forme de donn√©es polygonales (enrichie de donn√©es attributaires dans des formats comme CityGML ou IFC par exemple), ou de nuages de points. La livraison en cours par l‚ÄôIGN du nuage de points Haute D√©finition permettra d‚Äôailleurs d‚Äôavoir un √©chantillon √† l‚Äô√©chelle de la France enti√®re (√† voir &lt;a href="https://geoservices.ign.fr/lidarhd" target="_blank" rel="noopener">ici&lt;/a>). Au-del√† de cette donn√©e volumineuse, pouvant souffrir d‚Äôerreur d‚Äôacquisition, d‚Äôerreur dans leur mod√©lisation, il s‚Äôagit d‚Äôune r√©elle opportunit√© d‚Äôavoir √† disposition des jeux de donn√©es qui permettent de mettre en avant les algorithmes que nous d√©veloppons dans nos laboratoires de recherche. L√† encore, le lien avec le GDR Magis, mais aussi avec les entreprises et collectivit√©s permettent de d√©montrer la forte pertinence de nos algorithmes. Les exemples ne manquent pas et j‚Äôen propose ici quelques uns pour illustration.
L‚Äôexemple le plus imm√©diat est la (g√©o) visualisation de ces donn√©es 3D, voire 3D+Temps.&lt;/p>
&lt;figure id="figure-visualisation-3dtemps-de-la-ville-√†-gauche-gaillard-et-al-2018-√†-droite-jaillot-2020">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Visualisation 3D&amp;#43;temps de la ville (√† gauche (Gaillard et al 2018), √† droite (Jaillot, 2020))" srcset="
/post/22-08-25-info-geo-gillesg/image1_hu8e05bc591dac43f0cb0f47ae87674aca_1495231_be454da5c57fe7d795dacd5dea0c7974.webp 400w,
/post/22-08-25-info-geo-gillesg/image1_hu8e05bc591dac43f0cb0f47ae87674aca_1495231_cdecb4c1e09df6df823f4dbf43cd63d7.webp 760w,
/post/22-08-25-info-geo-gillesg/image1_hu8e05bc591dac43f0cb0f47ae87674aca_1495231_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-08-25-info-geo-gillesg/image1_hu8e05bc591dac43f0cb0f47ae87674aca_1495231_be454da5c57fe7d795dacd5dea0c7974.webp"
width="760"
height="222"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Visualisation 3D+temps de la ville (√† gauche (Gaillard et al 2018), √† droite (Jaillot, 2020))
&lt;/figcaption>&lt;/figure>
&lt;p>Prenons un autre exemple avec les probl√©matiques d‚Äôintervisibilit√©s et ombres port√©s. Tr√®s vite, les algorithmes de rendus peuvent sur ces grande masse de donn√©es apporter des solutions. Comment calculer l‚Äôimpact de la v√©g√©tation ou des immeubles de grande hauteur ? Comment calculer, gr√¢ce √† des informations s√©mantiques li√©es aux donn√©es 3D, la composition du territoire ou un skyline ?&lt;/p>
&lt;figure id="figure-intervisibilit√©-et-composition-du-territoire-p√©drinis-2017">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Intervisibilit√© et composition du territoire (P√©drinis, 2017)" srcset="
/post/22-08-25-info-geo-gillesg/image2_hu919a44f9388784fa17122bcbb5413708_285651_30eb5df60cc1bf24c1f323b0aa00989d.webp 400w,
/post/22-08-25-info-geo-gillesg/image2_hu919a44f9388784fa17122bcbb5413708_285651_4e9ec9f1b52befa7d965ab185d5c478c.webp 760w,
/post/22-08-25-info-geo-gillesg/image2_hu919a44f9388784fa17122bcbb5413708_285651_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-08-25-info-geo-gillesg/image2_hu919a44f9388784fa17122bcbb5413708_285651_30eb5df60cc1bf24c1f323b0aa00989d.webp"
width="600"
height="600"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Intervisibilit√© et composition du territoire (P√©drinis, 2017)
&lt;/figcaption>&lt;/figure>
&lt;p>Ces travaux permettent ensuite d‚Äôenvisager les possibles √©volutions des territoires (ou comment d√©tecter une √©volution dans des nuages de points ou des mod√®les 3D polygonaux ?). Il est n√©cessaire de mettre en coh√©rence donn√©es 2D et 3D, comportant des erreurs inh√©rentes √† leur cr√©ation/ acquisition, red√©couper une donn√©es 3D issue de prises de vues a√©riennes avec des donn√©es cadastrales 2D. Il est aussi n√©cessaire de comparer les mod√®les 3D issus de plusieurs mill√©simes afin de pouvoir mesurer les changements et ainsi apporter des √©l√©ments d‚Äô√©volution de la ville (P√©drinis, 2017), (Jaillot, 2020).
Enfin, il faut pouvoir faire le lien entre donn√©es g√©om√©triques, mais aussi topologiques et s√©mantiques, voire aussi avec d‚Äôautres m√©dias (photos, images, vid√©o). Comment apporter une coh√©rence entre ces donn√©es h√©t√©rog√®nes afin de pouvoir aller plus loin qu‚Äôune simple interrogation de la g√©om√©trie ? (Jaillot et al, 2021), (Vinasco et al, 2021)&lt;/p>
&lt;p>La constitution du projet Vcity au LIRIS en 2013 permet aujourd‚Äôhui de r√©pondre √† des besoins √† l‚Äôinterface entre informatique graphique et sciences des donn√©es mobilisant les donn√©es du territoire. Les expertises n√©cessaires sont multiples et doivent pouvoir s‚Äôorchestrer afin de pouvoir mieux r√©pondre aux challenges auxquels sont confront√©s nos territoires. Bien s√ªr, les comp√©tences n√©cessaires sont plus nombreuses comme le d√©montre le recherches men√©es au sein du &lt;a href="https://imu.universite-lyon.fr/" target="_blank" rel="noopener">LabEx Intelligences des Mondes Urbains&lt;/a> que je dirige depuis 2016 (600 chercheurs, 30 disciplines diff√©rentes, et 40 laboratoires r√©unis).
Au niveau national, les GDR MAGIS et IG-RV apportent de r√©elles comp√©tence que l‚Äôon sait compl√©ter au sein du CNRS par exemple en simulation (INSIS), mais aussi par des comp√©tences plus th√©matiques (avec l‚ÄôINEE et l‚ÄôINSHS (d√©j√† pr√©sents en partie au sein du GDR MAgis)). Cette recherche pluridisciplinaire apporte une nouvelle modalit√© permettant de mettre en avant la qualit√© des recherches que nous menons en France (voir par exemple la partie territoire du futur du &lt;a href="https://www.cnrs.fr/sites/default/files/download-file/COP_CNRS1_0.pdf" target="_blank" rel="noopener">Contrat d‚ÄôObjectif et de Performance du CNRS&lt;/a>).&lt;/p>
&lt;h3 id="bibliographie">Bibliographie&lt;/h3>
&lt;ul>
&lt;li>(Gaillard et al, 2018) J√©r√©my Gaillard, Adrien Peytavie, Gilles Gesqui√®re. Visualisation and personalisation of multi-representations city models. International Journal of Digital Earth, 2018, pp.1-18. ‚ü®hal-01946770‚ü©&lt;/li>
&lt;li>(Jaillot, 2020) Vincent Jaillot. 3D, temporal and documented cities : formalization, visualization and navigation. Computer Vision and Pattern Recognition [cs.CV]. Universit√© de Lyon, 2020. English. ‚ü®NNT : 2020LYSE2026‚ü©. ‚ü®tel-03228436‚ü©&lt;/li>
&lt;li>(Jaillot et al, 2021) Vincent Jaillot, Valentin Rigolle, Sylvie Servigne, John Samuel Samuel, Gilles Gesqui√®re. Integrating multimedia documents and time‚Äêevolving 3D city models for web visualization and navigation. Transactions in GIS, Wiley, 2021, 25 (3), pp.1419-1438. ‚ü®10.1111/tgis.12734‚ü©. ‚ü®hal-03178005‚ü©&lt;/li>
&lt;li>(P√©drinis, 2017) FreÃÅdeÃÅric Pedrinis. Repr√©sentations et dynamique de la ville virtuelle. Intelligence artificielle [cs.AI]. Universit√© de Lyon, 2017. Fran√ßais. ‚ü®NNT : 2017LYSE2092‚ü©. ‚ü®tel-01624392v2‚ü©&lt;/li>
&lt;li>(Vinasco et al, 2021) Diego Vinasco-Alvarez, John Samuel Samuel, Sylvie Servigne, Gilles Gesqui√®re. Towards Limiting Semantic Data Loss In 4D Urban Data Semantic Graph Generation. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2021, VIII-4/W2-2021, pp.37-44. ‚ü®10.5194/isprs-annals-VIII-4-W2-2021-37-2021‚ü©. ‚ü®hal-03375084‚ü©&lt;/li>
&lt;/ul></description></item><item><title>Mobilit√©s inter-laboratoires 2022</title><link>https://gdr-igrv.fr/post/22-06-30-mobilite/</link><pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-06-30-mobilite/</guid><description>&lt;p>Bonjour √† tous,&lt;/p>
&lt;p>Pour cette fin d&amp;rsquo;ann√©e 2022, le GdR met en place son action de mobilit√© entre laboratoires fran√ßais via le financement de court s√©jour d&amp;rsquo;un doctorant ou d&amp;rsquo;un enseignant-chercheur/chercheur. Le financement sera √† hauteur de 1000 euros par mission (mission de 4-5 jours en moyenne). L&amp;rsquo;appel est tr√®s large sur ce qui est attendu (√©changes scientifiques, montage de projet, exp√©rimentations&amp;hellip;), n&amp;rsquo;h√©sitez pas √† nous solliciter si vous avez des questions.&lt;/p>
&lt;p>La contrainte forte est que cette mission se d√©roule sur l&amp;rsquo;automne/hiver 2022.&lt;/p>
&lt;p>Le dossier pour postuler doit comprendre :&lt;/p>
&lt;ul>
&lt;li>une lettre de justification de la personne qui part (+ une lettre de son encadrant pour les doctorants)&lt;/li>
&lt;li>une lettre de justification de l&amp;rsquo;&amp;lsquo;√©quipe / personne qui accueille&lt;/li>
&lt;li>un budget pr√©visionnel&lt;/li>
&lt;/ul>
&lt;p>La date limite pour l&amp;rsquo;envoi du dossier est le &lt;strong>1er septembre 2022&lt;/strong> (par mail √† David et Maud), une d√©cision tr√®s rapide devrait arriver dans la foul√©e pour la mise en place de la mission.&lt;/p>
&lt;p>Merci √† tous de relayer l&amp;rsquo;information,
Tr√®s cordialement,
David &amp;amp; Maud&lt;/p></description></item><item><title>Axel Paris : Mod√©lisation et g√©n√©ration de sc√®nes naturelles dans le contexte de l'informatique graphique</title><link>https://gdr-igrv.fr/post/22-05-10-jc-axel-paris/</link><pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-05-10-jc-axel-paris/</guid><description>&lt;h3 id="peux-tu-nous-dire-quelle-est-ta-situation-actuelle-en-mati√®re-de-recherche-">Peux-tu nous dire quelle est ta situation actuelle en mati√®re de recherche ?&lt;/h3>
&lt;p>Je suis en 3√®me ann√©e de th√®se au &lt;a href="https://liris.cnrs.fr" target="_blank" rel="noopener">LIRIS&lt;/a> √† Lyon, encadr√© par Eric Galin et Eric Gu√©rin de l‚Äô√©quipe &lt;a href="https://projet.liris.cnrs.fr/origami/" target="_blank" rel="noopener">Origami&lt;/a>. J‚Äôai r√©alis√© une c√©sure de th√®se de 6 mois pour faire un stage de recherche dans une entreprise, chez Adobe Research, et je d√©bute pour cela ma troisi√®me ann√©e en d√©cal√© en Mars.&lt;/p>
&lt;h3 id="peux-tu-nous-d√©crire-en-quelques-mots-et-de-mani√®re-accessible-aux-membres-du-gdr-igrv-en-quoi-tes-travaux-de-recherche-consistent-exactement">Peux-tu nous d√©crire en quelques mots, et de mani√®re accessible aux membres du GDR-IGRV, en quoi tes travaux de recherche consistent exactement?&lt;/h3>
&lt;p>Ma th√®se porte sur la mod√©lisation et la g√©n√©ralisation de ph√©nom√®nes naturels. Concr√®tement sur les ph√©nom√®nes naturels, on imagine une sc√®ne d‚Äôext√©rieur, naturelle, compos√©e, en g√©n√©ral, d&amp;rsquo;un terrain, de la v√©g√©tation, des fluides (e.g. des rivi√®res, des nuages), et je m‚Äôint√©resse √† la g√©n√©ration de terrains r√©alistes. Il s‚Äôagit donc de reproduire ce qu‚Äôon appelle des ¬´ model√©s ¬ª, des ¬´ formes de terrains ¬ª qu‚Äôon voit dans la vraie vie, par des algorithmes, par des simulations d‚Äô√©rosion, etc.&lt;/p>
&lt;p>Plus sp√©cifiquement, je m‚Äôint√©resse aux ph√©nom√®nes naturels qu‚Äôon nomme ¬´ tridimensionnels ¬ª : les ph√©nom√®nes volumiques qui ne peuvent pas √™tre repr√©sent√©s uniquement par une surface lisse. Je m‚Äôint√©resse aux concavit√©s, comme les grottes, les surplombs, les arches, etc. et donc √† leur g√©n√©ration.&lt;/p>
&lt;p>√áa a deux applications principalement : une application plut√¥t dans l‚Äôindustrie du loisir, notamment le cin√©ma et le jeu vid√©o, o√π souvent on veut cr√©er des sc√®nes naturelles par ordinateur (e.g. le dernier Avengers). Dans ces sc√®nes naturelles, il y a souvent un terrain et se sont des artistes qui vont le cr√©er et le texturer. C‚Äôest un processus de moins en moins manuel : il est semi-manuel, et beaucoup d‚Äôalgorithmes sont d√©j√† utilis√©s par des artistes pour commencer √† faire le sketching, placer les formes, etc. Dans ce contexte, on va donc chercher √† faire des applications qui donnent plut√¥t du contr√¥le aux artistes. La deuxi√®me application est √† l‚Äôinterface entre la g√©ologie et l‚Äôinformatique. Imaginons qu‚Äôon regarde une cha√Æne de montagnes et qu‚Äôon veuille savoir comment elle a √©t√© form√©e. On va essayer de r√©tro-ing√©ni√©rer les processus par des algorithmes pour comprendre comment la montagne s‚Äôest form√©e, et √ßa peut nous aider √† pr√©dire l‚Äô√©volution de la montagne avec des ¬´ m√©thodes inverses ¬ª.&lt;/p>
&lt;figure id="figure-simulation-de-terrains-volumiques-par-invasion-percolation">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Simulation de terrains volumiques par invasion-percolation" srcset="
/post/22-05-10-jc-axel-paris/SeaErosion03_hu2d38d96411c8b1476604947d5d3cebdd_246241_57bd1752e2762daa3358325f33c7cdac.webp 400w,
/post/22-05-10-jc-axel-paris/SeaErosion03_hu2d38d96411c8b1476604947d5d3cebdd_246241_619dcaecdf595bf58918ab458155c5d4.webp 760w,
/post/22-05-10-jc-axel-paris/SeaErosion03_hu2d38d96411c8b1476604947d5d3cebdd_246241_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-05-10-jc-axel-paris/SeaErosion03_hu2d38d96411c8b1476604947d5d3cebdd_246241_57bd1752e2762daa3358325f33c7cdac.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Simulation de terrains volumiques par invasion-percolation
&lt;/figcaption>&lt;/figure>
&lt;h4 id="est-ce-que-c√¥t√©-technologie-tu-arriverais-√†-d√©crire-un-peu-les-outils-que-tu-utilises-">Est-ce que c√¥t√© technologie tu arriverais √† d√©crire un peu les outils que tu utilises ?&lt;/h4>
&lt;p>Dans ma th√®se, je me suis focalis√© principalement sur les mod√®les √† base de surfaces implicites. Tr√®s succinctement, c‚Äôest une repr√©sentation tr√®s compacte de formes g√©om√©triques. On ne les repr√©sente non pas comme des maillages, mais comme des √©quations (des √©quations de distance √† la forme), et √ßa prend tr√®s peu de place en m√©moire. On peut repr√©senter de tr√®s grandes sc√®nes avec √ßa! Ca a aussi d‚Äôautres avantages au niveau contr√¥le : il y a des op√©rateurs de m√©lange, on peut m√©langer des formes (tr√®s utile pour les artistes). C‚Äôest un mod√®le tr√®s expressif. Dans le cadre de ma th√®se, il s‚Äôagit de regarder tout ce qu‚Äôil est possible de faire avec les surfaces implicites pour les ph√©nom√®nes naturels. J‚Äôai aussi travaill√© sur les mod√®les 2D de cartes de hauteur.&lt;/p>
&lt;h3 id="quel-est-ton-r√©sultat-de-recherche-dont-tu-es-le-plus-fier">Quel est ton r√©sultat de recherche dont tu es le plus fier?&lt;/h3>
&lt;p>J‚Äôai eu l‚Äôoccasion de travailler dans ma th√®se sur des sujets assez diff√©rents qui m‚Äôont tous beaucoup plu. Si je devais revenir sur juste un, je dirais le dernier qui concernait la g√©n√©ration de r√©seaux de grottes. Je l‚Äôai trouv√© particuli√®rement int√©ressant car on a pu collaborer avec quelqu‚Äôun de l‚Äôext√©rieur, une g√©ologue, qui avait des connaissances que nous n‚Äôavions pas du tout (Pauline Colon, de l‚Äôuniversit√© de Lorraine). Elle nous a apport√© beaucoup de connaissances en g√©ologie et en g√©omorphologie. On a r√©dig√© un article ensemble o√π le c√¥t√© pluridisciplinaire ressort beaucoup, et chacun a apport√© des connaissances √† l‚Äôautre. La collaboration continue d‚Äôailleurs avec des stages en suite de ce papier.&lt;/p>
&lt;figure id="figure-simulation-de-paysages-d√©sertiques-dunes-nabkha">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Simulation de paysages d√©sertiques: Dunes Nabkha" srcset="
/post/22-05-10-jc-axel-paris/nabkha_1_huee0d455830741d157102e10d7a7baf97_1491283_42dacb72a6404de2a89ec26e5e23cbf1.webp 400w,
/post/22-05-10-jc-axel-paris/nabkha_1_huee0d455830741d157102e10d7a7baf97_1491283_e8ce5921d5872b62e904aa06db6c30c4.webp 760w,
/post/22-05-10-jc-axel-paris/nabkha_1_huee0d455830741d157102e10d7a7baf97_1491283_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-05-10-jc-axel-paris/nabkha_1_huee0d455830741d157102e10d7a7baf97_1491283_42dacb72a6404de2a89ec26e5e23cbf1.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Simulation de paysages d√©sertiques: Dunes Nabkha
&lt;/figcaption>&lt;/figure>
&lt;h3 id="quelles-sont-tes-perspectives-√†-long-terme--apr√®s-la-th√®se-ou-le-post-doc-ec-cr">Quelles sont tes perspectives √† long terme ? (Apr√®s la th√®se ou le post-doc, EC, CR..)&lt;/h3>
&lt;p>√áa n&amp;rsquo;est pas simple‚Ä¶ j‚Äôai pleins d‚Äôid√©es ! Disons que rien ne me semble ‚Äúpas attractif‚Äù, m√™me si j‚Äôai quelques pr√©f√©rences. Si je devais choisir maintenant, je m‚Äôorienterais dans la recherche d‚Äôun post-doc √† l‚Äô√©tranger dans une √©quipe qui fait des choses en lien avec ce que je fais .. ou pas .. j‚Äôaime aussi l‚Äôid√©e de changer un peu. Mes projets √† plus long terme demandent encore √† se pr√©ciser. Ma c√©sure en entreprise m‚Äôa permis de tester √† la fois le priv√© et le public, et je vois que les deux ont des avantages et des inconv√©nients, je me laisse donc encore du temps pour r√©fl√©chir.&lt;/p>
&lt;h3 id="quelles-sont-les-recherchesexp√©riencesth√©matiques-que-tu-r√™verais-daborder-dans-ton-laboratoire-id√©al-">Quelles sont les recherches/exp√©riences/th√©matiques que tu r√™verais d&amp;rsquo;aborder dans ton laboratoire id√©al ?&lt;/h3>
&lt;p>Bonne question‚Ä¶ ! Suite √† mes derniers travaux en collaboration avec une g√©ologue, j‚Äôai compris l‚Äôenjeu et b√©n√©fice de la dimension pluridisciplinaire que peut prendre la recherche, et j‚Äôaimerais beaucoup pouvoir retrouver cela dans un futur laboratoire.&lt;/p>
&lt;p>&lt;em>Toutes les illustrations de cet article ont √©t√© fournies par Axel et le d√©tail de ses travaux est disponible sur &lt;a href="https://aparis69.github.io/" target="_blank" rel="noopener">son site web&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Zoom sur... Aldo Napoli du Centre de recherche sur les Risques et les Crises (CRC) (Mines Paris | PSL)</title><link>https://gdr-igrv.fr/post/22-05-05-zoom-aldo-napoli/</link><pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-05-05-zoom-aldo-napoli/</guid><description>&lt;p>&lt;a href="https://www.minesparis.psl.eu/Services/Annuaire/aldo-napoli" target="_blank" rel="noopener">&lt;strong>Aldo Napoli&lt;/strong>&lt;/a>, membre du &lt;a href="https://www.crc.mines-paristech.fr/fr/" target="_blank" rel="noopener">&lt;strong>Centre de recherche sur les Risques et les Crises&lt;/strong>&lt;/a> (CRC), s&amp;rsquo;int√©resse √† la gestion des risques maritimes dus √† la navigation de navires. Les trajectoires des navires sont enregistr√©es en permanence et sont analys√©es par des op√©rateurs responsables de r√©agir face √† des situations de risque. Aldo Napoli travaille sur des m√©thodes d&amp;rsquo;analyses des trajectoires de navires pour l&amp;rsquo;aide √† la d√©cision, mais aussi sur leur visualisation. En lien avec le GdR, c&amp;rsquo;est plut√¥t de ses travaux autour de la visualisation qu&amp;rsquo;il a souhait√© nous parler.&lt;/p>
&lt;h4 id="est-ce-que-vous-pourriez-nous-d√©crire-votre-projet-de-recherche-et-comment-il-sinscrit-dans-le-gdr-igrv">Est-ce que vous pourriez nous d√©crire votre projet de recherche et comment il s‚Äôinscrit dans le GdR IGRV?&lt;/h4>
&lt;p>Dans le cadre d‚Äôune th√®se de doctorat men√©e de 2012 √† 2014, nous avons con√ßu et d√©velopp√© un environnement d‚Äôaide √† l‚Äôanalyse g√©ovisuelle, qui permet de guider l‚Äôutilisateur dans la visualisation et l‚Äôanalyse d‚Äôinformations pour l‚Äô√©tude des risques maritimes. Les outils de visualisation des trajectoires maritimes sont aujourd&amp;rsquo;hui nombreux, mais requiert un certain apprentissage de la part des op√©rateurs ainsi que d&amp;rsquo;analyser une tr√®s large quantit√© de donn√©es sur plusieurs moniteurs. Le but de cette th√®se √©tait de concevoir un syst√®me √† base de connaissances, afin de proposer des m√©thodes ad√©quates pour la visualisation et l‚Äôanalyse des trajectoires de navires.&lt;/p>
&lt;h4 id="quels-sont-les-principaux-verrous-techniques-ou-m√©thodologiques-en-lien-avec-le-gdr-que-vous-essayez-de-r√©soudre">Quels sont les principaux verrous techniques ou m√©thodologiques (en lien avec le GdR) que vous essayez de r√©soudre?&lt;/h4>
&lt;p>Cette derni√®re d√©cennie, les laboratoires de R&amp;amp;D ainsi que les grands groupes li√©s aux sciences de l‚Äôinformation g√©ographique (GIScience) proposent et d√©veloppent de nouvelles mani√®res de cartographier l‚Äôespace et visualiser l‚Äôinformation spatio-temporelle. Cependant, devant une trop grande panoplie d‚Äôoutils disponibles, il est aujourd‚Äôhui compliqu√© de savoir quelle m√©thode, quel algorithme, quel logiciel utiliser pour mener un processus d‚Äôanalyse d‚Äôinformation √† composantes spatiales.&lt;/p>
&lt;p>L‚Äôun des grands d√©fis pos√©s par la communaut√© GIScience ces derni√®res ann√©es n‚Äôest donc plus de proposer de nouvelles m√©thodes de visualisation de l‚Äôinformation, mais de consolider l‚Äôutilisation de la visualisation, en √©tudiant le r√©el apport de ces nombreuses m√©thodes par rapport aux questions de l‚Äôutilisateur. Le point fondamental n‚Äôest donc pas de d√©velopper une nouvelle m√©thode pour l‚Äôanalyse g√©ovisuelle des trajectoires, mais de rechercher comment guider l‚Äôutilisateur dans le processus d‚Äôanalyse g√©ovisuelle.&lt;/p>
&lt;p>Nous avons d√©fini un environnement d‚Äôaide √† l‚Äôanalyse g√©ovisuelle qui permet de soutenir l‚Äôanalyse d‚Äôinformations par l‚Äôutilisation de m√©thodes visuelles adapt√©es au cas d‚Äôutilisation. Nous avons identifi√© plusieurs profils d‚Äôutilisateurs qui auraient besoin de ce type d‚Äôenvironnement, √† savoir les personnes li√©s √† la prise de d√©cision √† partir de l‚Äôanalyse de donn√©es de mouvement (les contr√¥leurs, les analystes, etc.), mais aussi les scientifiques amen√©s √† analyser l‚Äôinformation g√©ographique afin de mod√©liser les risques maritimes. Ces nombreux utilisateurs, par leur profil, leur formation et leurs habitudes, sont amen√©s √† utiliser des visualisations vari√©es, dans des contextes diff√©rents. Notre environnement les guide dans le choix de la visualisation ad√©quate.&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-05-05-zoom-aldo-napoli/image-choix_huaa019a8b8e18f6bab88f09c91da10c72_309098_b9dbec8fac67c60fa248071f52f7d0be.webp 400w,
/post/22-05-05-zoom-aldo-napoli/image-choix_huaa019a8b8e18f6bab88f09c91da10c72_309098_db2d000dde6d1cd7bb028b40e0f38a3a.webp 760w,
/post/22-05-05-zoom-aldo-napoli/image-choix_huaa019a8b8e18f6bab88f09c91da10c72_309098_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-05-05-zoom-aldo-napoli/image-choix_huaa019a8b8e18f6bab88f09c91da10c72_309098_b9dbec8fac67c60fa248071f52f7d0be.webp"
width="760"
height="542"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h4 id="est-ce-quil-y-a-dautres-verrous-que-vous-aimeriez-voir-r√©solus-mais-sur-lesquels-vous-ne-travaillez-pas-vous-m√™me-">Est-ce qu‚Äôil y a d‚Äôautres verrous que vous aimeriez voir r√©solus, mais sur lesquels vous ne travaillez pas vous-m√™me ?&lt;/h4>
&lt;p>Depuis l‚Äôinterface que nous avons propos√©e, il est encore compliqu√© pour un utilisateur quelconque de pouvoir √©valuer son profil selon les trois niveaux de comp√©tence et d‚Äôexp√©rience identifi√©s. Une perspective importante pour ce travail de recherche serait d‚Äôapprofondir la mod√©lisation de l‚Äôutilisateur et de son environnement, afin de rendre le profil plus intuitif, et moins empirique. Plusieurs travaux de mod√©lisation de l‚Äôutilisateur et de son environnement ont pu √™tre propos√©s, cette question √©tant un point de recherche √† part enti√®re ; tandis que nous avons pr√©f√©r√© exploiter la mod√©lisation de la visualisation elle-m√™me.&lt;/p>
&lt;p>La mod√©lisation des m√©thodes de visualisation d‚Äôinformation que nous avons propos√©e ne prend pas en compte la dynamique du processus d‚Äôanalyse et de d√©cision. Pourtant, comme le montre les diff√©rents processus de gestion des risques, l‚Äôanalyse et la d√©finition des comportements √† risque doit √™tre un processus it√©ratif. Une am√©lioration d‚Äôint√©r√™t serait de prendre en compte l‚Äôordre et la r√©currence de ces t√¢ches d‚Äôanalyse g√©ovisuelle dans la mod√©lisation des strat√©gies de visualisation, et d‚Äôavoir un impact sur les r√©sultats propos√©s : ordre des propositions, m√©thode la plus importante car plus demand√©e, etc.&lt;/p>
&lt;p>&lt;em>Travaux men√©s dans le cadre de la th√®se de Gabriel Vatin (dirig√©e par Aldo Napoli) de 2012 √† 2014&lt;/em>&lt;/p></description></item><item><title>Yann Glemarec : Une approche narrative interactive pour les audiences virtuelles</title><link>https://gdr-igrv.fr/post/22-03-21-jc-yann-glemarec/</link><pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-03-21-jc-yann-glemarec/</guid><description>&lt;h3 id="peux-tu-nous-dire-quelle-est-ta-situation-actuelle-en-mati√®re-de-recherche-">Peux-tu nous dire quelle est ta situation actuelle en mati√®re de recherche ?&lt;/h3>
&lt;p>Je suis actuellement en th√®se, en 3√®me ann√©e. La particularit√© c‚Äôest que je suis en cotutelle entre le &lt;a href="https://labsticc.fr/fr" target="_blank" rel="noopener">Lab-STICC&lt;/a> (&lt;a href="https://www.enib.fr/fr/" target="_blank" rel="noopener">ENIB&lt;/a>, Brest) et le &lt;a href="http://hci.uni-wuerzburg.de/" target="_blank" rel="noopener">laboratoire HCI de l‚Äôuniversit√© de W√ºrzburg&lt;/a>. J‚Äôai donc moiti√© du temps en France et moiti√© du temps en Allemagne, o√π je suis actuellement. La fin de th√®se est pr√©vue pour la fin de l‚Äô√©t√© 2022.&lt;/p>
&lt;h3 id="peux-tu-nous-d√©crire-en-quelques-mots-et-de-mani√®re-accessible-aux-membres-du-gdr-igrv-en-quoi-tes-travaux-de-recherche-consistent-exactement">Peux-tu nous d√©crire en quelques mots, et de mani√®re accessible aux membres du GDR-IGRV, en quoi tes travaux de recherche consistent exactement?&lt;/h3>
&lt;p>On utilise le potentiel des agents virtuels (diff√©rents des avatars car ils ne sont pas contr√¥l√©s par un humain) afin de fournir les meilleurs syst√®mes d‚Äôentra√Ænement ou de th√©rapie en r√©alit√© virtuelle. Un exemple de syst√®me d‚Äôentra√Ænement est l‚Äôentra√Ænement √† la prise de parole en public, je travaille souvent l√†-dessus. Cela marche aussi pour les th√©rapies, pour les personnes atteintes d‚Äôangoisses √† la prise de parole en public, du point de vue de psychologie clinique. Si je rentre dans le d√©tail, on utilise le comportement non verbal des agents pour cr√©er des comportements et donc g√©n√©rer des r√©actions chez l‚Äôutilisateur. √áa nous permet de cr√©er des environnements cr√©dibles, plausibles pour les utilisateurs, mais aussi pour les instructeurs et th√©rapeutes qui eux peuvent mettre en place des sc√©narios de formations, de th√©rapies, en utilisant ces ¬´ audiences virtuelles ¬ª, pour entra√Æner les gens √† parler en public, faire des pr√©sentations.&lt;/p>
&lt;video autoplay loop >
&lt;source src="https://gdr-igrv.fr/post/22-03-21-jc-yann-glemarec/NextStep.mp4" type="video/mp4">
&lt;/video>
&lt;h4 id="donc-du-coup-la-sp√©cificit√©-de-tes-travaux-cest-vraiment-d√©tudier-comment-g√©n√©rer-cette-audience-et-comment-la-contr√¥ler">Donc du coup la sp√©cificit√© de tes travaux c‚Äôest vraiment d‚Äô√©tudier comment g√©n√©rer cette audience et comment la contr√¥ler?&lt;/h4>
&lt;p>Oui en fait nous on cr√©e des audiences on fait des √©tudes perceptives pour savoir comment les gens per√ßoivent ces audiences, en terme d‚Äô√©motions par exemple. ¬´ Quelle est l‚Äôattitude per√ßue ? ¬ª ¬´ Est-ce qu‚Äôils sont int√©ress√©s par ce que je dis ? ¬ª. Derri√®re, ce qui nous int√©resse c‚Äôest de permettre aux instructeurs de contr√¥ler cette perception qu‚Äôauront les utilisateurs de l‚Äôaudience virtuelles pour faire ressentir une √©motion particuli√®re.&lt;/p>
&lt;h4 id="il-y-a-donc-une-dimension-assez-technique-pour-d√©velopper-la-plateforme-mais-il-y-a-aussi-toute-la-facette-perception-parce-que-vous-apportez-aussi-avec-un-bagage-de-connaissance-sur-comment-les-audiences-de-la-plateforme-sont-per√ßues">Il y a donc une dimension assez technique pour d√©velopper la plateforme, mais il y a aussi toute la facette perception parce que vous apportez aussi avec un bagage de connaissance sur comment les audiences de la plateforme sont per√ßues.&lt;/h4>
&lt;p>Exactement. Nous ne sommes pas une √©quipe de psychologues, mais nous nous basons sur des mod√®les de psychologie cognitive de perception des √©motions par exemple, comme l‚Äô√©chelle connue de la ¬´ valence-arousal ¬ª. Ce sont deux axes qui permettent d‚Äôun c√¥t√© d‚Äô√©valuer, dans ce contexte li√© √† l‚Äôaudience (si elle est positive ou n√©gative) et l‚Äôarousal correspondrait √† son engagement (attentive ou non).&lt;/p>
&lt;h4 id="sur-quels-types-de-dispositifs-travailles-tu-">Sur quels types de dispositifs travailles-tu ?&lt;/h4>
&lt;p>En terme de mat√©riel, on s‚Äôest concentr√©s au d√©but sur les casques de r√©alit√© virtuelle. On se sert aussi des CAVEs. On a fait face √† des gens ayant des r√©ticences √† utiliser les casques de r√©alit√© virtuelle et qui pr√©f√©raient par cons√©quent ce type de syst√®mes immersifs, mais le tracking du participant est plus complexe dans ce type de configuration.&lt;/p>
&lt;h3 id="quel-est-ton-r√©sultat-de-recherche-dont-tu-es-le-plus-fier">Quel est ton r√©sultat de recherche dont tu es le plus fier?&lt;/h3>
&lt;p>On a r√©ussi √† int√©grer notre syst√®me d‚Äôaudience virtuelle dans un syst√®me qu‚Äôon utilise ici pour des √©tudiants lors d‚Äôun cours o√π ils apprennent √† faire des pr√©sentations scientifiques, donc typiquement des pr√©sentations d‚Äôarticles. On leur permet de faire un entra√Ænement en r√©alit√© virtuelle, comme une conf√©rence virtuelle, et nous √ßa nous permet de tester nos audiences, pendant deux semestres.&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-03-21-jc-yann-glemarec/TherapistGUI_hu35804965efff09982f91d5d80062d3b5_11137492_f3ca61e96b85b69e07e6fcfe6a34639f.webp 400w,
/post/22-03-21-jc-yann-glemarec/TherapistGUI_hu35804965efff09982f91d5d80062d3b5_11137492_9754dc2b37189b194c168c17eacf07bf.webp 760w,
/post/22-03-21-jc-yann-glemarec/TherapistGUI_hu35804965efff09982f91d5d80062d3b5_11137492_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-03-21-jc-yann-glemarec/TherapistGUI_hu35804965efff09982f91d5d80062d3b5_11137492_f3ca61e96b85b69e07e6fcfe6a34639f.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h3 id="quelles-sont-tes-perspectives-√†-long-terme--apr√®s-la-th√®se-ou-le-post-doc-ec-cr">Quelles sont tes perspectives √† long terme ? (Apr√®s la th√®se ou le post-doc, EC, CR..)&lt;/h3>
&lt;p>&lt;em>(rigole)&lt;/em> C‚Äôest une question qui est au c≈ìur des √©changes avec mes encadrants en ce moment. Pour le moment je me dirige vers la recherche acad√©mique. Le plan serait de peut-√™tre me diriger vers un poste d‚ÄôATER pour donner un peu plus de cours et pour pouvoir aussi finaliser et poursuivre un peu mes travaux de th√®se. J‚Äôenvisage aussi la possibilit√© d‚Äôun post-doc, sans avoir encore de pr√©f√©rence entre un poste de ma√Ætre de conf√©rences ou charg√© de recherche.&lt;/p>
&lt;h3 id="quelles-sont-les-recherchesexp√©riencesth√©matiques-que-tu-r√™verais-daborder-dans-ton-laboratoire-id√©al-">Quelles sont les recherches/exp√©riences/th√©matiques que tu r√™verais d&amp;rsquo;aborder dans ton laboratoire id√©al ?&lt;/h3>
&lt;p>Si je devais r√©fl√©chir √† un laboratoire id√©al, ce serait surtout un laboratoire cross-disciplinaire. Par exemple j‚Äôai beaucoup aim√© pendant ma th√®se pouvoir travailler avec des psychologues, c‚Äôest super int√©ressant. J‚Äôaimerais continuer dans mon domaine, la r√©alit√© virtuelle, mais si possible avec des personnes d‚Äôautres domaines comme la psychologie par exemple. J‚Äôaime le c√¥t√© applicable des travaux de recherches, o√π il y a un potentiel de valorisation assez √©lev√©, comme ici avec un syst√®me qui pourra √™tre utilis√© dans l‚Äô√©ducation.&lt;/p>
&lt;p>&lt;em>Toutes les illustrations de cet article ont √©t√© fournies par Yann et le d√©tail de ses travaux est disponible sur &lt;a href="https://www.enib.fr/~glemarec/" target="_blank" rel="noopener">son site web&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Zoom sur... L'√©quipe PIROS du laboratoire ISIR, avec Catherine Pelachaud</title><link>https://gdr-igrv.fr/post/22-02-11-zoom-catherine-pelachaud/</link><pubDate>Fri, 11 Feb 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-02-11-zoom-catherine-pelachaud/</guid><description>&lt;p>&lt;a href="http://pages.isir.upmc.fr/~pelachaud/" target="_blank" rel="noopener">&lt;strong>Catherine Pelachaud&lt;/strong>&lt;/a> nous explique les travaux men√©s dans l&amp;rsquo;√©quipe &lt;strong>&lt;a href="https://www.isir.upmc.fr/equipes/piros/" target="_blank" rel="noopener">PIROS&lt;/a>&lt;/strong> (laboratoire ISIR), o√π la r√©alit√© virtuelle et la simulation sont utilis√©s pour mod√©liser des agents conversationnels anim√©s (ACAs) expressifs capables d‚Äôinteragir √©motionnellement et socialement avec des interlocuteurs humains:&lt;/p>
&lt;p>&amp;ldquo;Nous avons d√©velopp√© des mod√®les computationnels du comportement communicatif non-verbal et socio-√©motionnel de l‚Äôagent. Avec des coll√®gues de l‚ÄôUTC, en particulier Indira Thouvenin, nous nous int√©ressons au toucher social et souhaitons comprendre comment mod√©liser la prise en compte du toucher tant du point de vue de l‚Äôhumain que de l‚Äôagent dans un environnement de r√©alit√© virtuelle, menant ainsi au d√©veloppement d‚Äôun agent touchant et touch√©. Nous nous focalisons aussi sur les mod√®les d‚Äôinteraction entre un humain et un agent, donnant √† l‚Äôagent la capacit√© d‚Äôadapter son comportement √† plusieurs niveaux (conversationnel, comportemental, signal) pour contr√¥ler l‚Äôimpression qu‚Äôil donne √† son interlocuteur humain et/ou pour qu‚Äôil maintienne l‚Äôengagement de celui-ci dans leur interaction.&lt;/p>
&lt;p>Ainsi nos th√©matiques de recherche s‚Äôint√®grent dans l‚Äôaxe GT animation et simulation et derni√®rement dans celui sur la r√©alit√© virtuelle.
Nous faisons face √† de nombreux verrous techniques tels que la cr√©ation d‚Äôanimation expressive. Nous utilisons des mod√®les proc√©duraux qui nous permet un grand contr√¥le mais offre une qualit√© insuffisante. Un autre verrou est de mod√©liser des agents cr√©dibles, pas n√©cessairement r√©alistes. Cela demande de comprendre quand et quel comportement l‚Äôagent doit montrer, quel en sera l‚Äôimpact sur la perception de son interlocuteur humain.
Mod√©liser une interaction humain-agent requi√®re de nombreux composants comme la reconnaissance et la compr√©hension du langage, des expressions du locuteur, mais aussi un mod√®le de dialogue, d‚Äô√©motion, de repr√©sentation des connaissances, pour en nommer quelques-uns. Pour y palier nous utilisons des modules d√©velopp√©s par d‚Äôautres chercheurs et mis √† disposition √† la communaut√© de recherche.&amp;rdquo;&lt;/p></description></item><item><title>Prix de th√®se du GDR IG-RV 2021</title><link>https://gdr-igrv.fr/post/21-10-06-prix-these-2021/</link><pubDate>Wed, 06 Oct 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/21-10-06-prix-these-2021/</guid><description>&lt;p>&lt;strong>R√©sultats du prix de th√®se du GDR IG-RV 2021 en collaboration avec l‚ÄôAssociation Fran√ßaise d‚ÄôInformatique Graphique, l‚ÄôAssociation Fran√ßaise de la XR et le Chapitre Fran√ßais d‚ÄôEurographics.&lt;/strong>&lt;/p>
&lt;p>Pour cette cinqui√®me √©dition, la participation au concours √©tait ouverte aux docteurs ayant soutenu leur th√®se entre le 01/01/2020 et le 31/12/2020. Il y a eu 11 soumissions, toutes d‚Äôun excellent niveau scientifique et couvrant largement les th√©matiques du GDR IG-RV.&lt;/p>
&lt;p>Cette ann√©e, le jury de s√©lection a √©t√© anim√© par David Coeurjolly et Lo√Øc Barthe et il √©tait compos√© de Florence Bertails-Descoubes, Georges-Pierre Bonneau, George Drettakis, Samuel Hornus, Daniel Mestre, Alexis Paljic et Julien Tierny.&lt;/p>
&lt;p>Le prix de th√®se du GDR IG-RV 2021 est d√©cern√© √† :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Rebecca Fribourg&lt;/strong> pour sa th√®se intitul√©e &lt;em>¬´ Contribution to the study of factors influencing the sense of embodiment towards avatars in virtual reality ¬ª&lt;/em>, effectu√©e sous la direction d‚ÄôAnatole L√©cuyer, Ferran Argelaguet et Ludovic Hoyet √† l‚ÄôUniversit√© de Rennes 1.&lt;/li>
&lt;/ul>
&lt;p>Un accessit a aussi √©t√© d√©cern√© √† :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Pierre Ecormier-Nocca&lt;/strong> pour sa th√®se intitul√©e &lt;em>¬´ Authoring consistent, animated ecosystems: Efficient learning from partial data ¬ª&lt;/em>, effectu√©e sous la direction de Marie-Paule Cani et Pooran Memari √† l‚ÄôEcole Polytechnique.&lt;/li>
&lt;/ul>
&lt;p>Nous tenons √† remercier l‚Äôensemble des candidats pour leur participation,&lt;/p>
&lt;p>Les animateurs du prix de th√®se 2021,
David Coeurjolly et Lo√Øc Barthe&lt;/p></description></item><item><title>De nouveaux r√©dacteurs scientifiques rejoignent l'√©quipe de r√©daction du site</title><link>https://gdr-igrv.fr/post/21-09-30-new-redactors/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/21-09-30-new-redactors/</guid><description>&lt;p>&lt;a href="https://gdr-igrv.fr/author/johanna-delanoy/">Johanna&lt;/a>, &lt;a href="https://gdr-igrv.fr/author/rebecca-fribourg/">Rebecca&lt;/a> et &lt;a href="https://gdr-igrv.fr/author/etienne-corman/">√âtienne&lt;/a> rejoignent l&amp;rsquo;√©quipe de r√©daction du site web du GdR. Ils participeront √† la r√©daction des articles et br√®ves du site et √† la communication du GdR. Merci √† eux !&lt;/p></description></item><item><title>La gazette du GT ¬´ ModeÃÅlisation geÃÅomeÃÅtrique ¬ª, n¬∞0</title><link>https://gdr-igrv.fr/post/20-12-02-gtmg-gazette/</link><pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/20-12-02-gtmg-gazette/</guid><description>&lt;p>Le &lt;a href="https://gdr-igrv.fr/gts/gt-mg/">GT MG&lt;/a> a lanc√© le &lt;a href="https://gtmg.u-bourgogne.fr/wp-content/uploads/2021/07/gazette-GTMG_n0_16juillet2021.pdf" target="_blank" rel="noopener">premier num√©ro&lt;/a> de sa gazette.&lt;/p></description></item></channel></rss>