<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GdR IG-RV</title><link>https://gdr-igrv.fr/</link><atom:link href="https://gdr-igrv.fr/index.xml" rel="self" type="application/rss+xml"/><description>GdR IG-RV</description><generator>Wowchemy (https://wowchemy.com)</generator><language>fr-fr</language><lastBuildDate>Thu, 09 Oct 2025 10:00:00 +0000</lastBuildDate><image><url>https://gdr-igrv.fr/media/icon_hu6ab350bd9da14bf3d770a252e9dc8f37_21017_512x512_fill_lanczos_center_3.png</url><title>GdR IG-RV</title><link>https://gdr-igrv.fr/</link></image><item><title>Financement de missions pour journées du GdR</title><link>https://gdr-igrv.fr/actions/missions/</link><pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/actions/missions/</guid><description>&lt;p>Le GdR a la possibilité de financer quelques missions à tout membre souhaitant assister à une journée soutenue par le GdR (journées de GT, journées thématiques, journées inter-GdR&amp;hellip;), et qui ne pourrait
se financer par ailleurs. L&amp;rsquo;objectif est ici de favoriser au maximum les interactions et échanges scientifiques au sein de ses communautés.&lt;/p>
&lt;p>La procédure est nécessairement au fil de l&amp;rsquo;eau, et contrainte par la situation budgétaire du GdR. Si vous souhaitez bénéficier de cette procédure, merci de contacter à la fois la direction du GdR et les organisateurs de la journée en question.&lt;/p></description></item><item><title>Mobilité</title><link>https://gdr-igrv.fr/actions/mobilite/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/actions/mobilite/</guid><description>&lt;p>Le GdR met en place des actions de mobilités internes à destination des doctorant.e.s et
jeunes chercheuses.eurs. Que ce soit pour initier des
collaborations, ou se former auprès d&amp;rsquo;autres équipes, ces mobilités
sont d&amp;rsquo;une grande utilité en tant que levier pour des collaborations de recherche nouvelles, avec un format court et
léger de candidature et de financement.&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
&lt;h2 id="demander-le-soutien-du-gdr-pour-une-mobilité">Demander le soutien du GdR pour une mobilité&lt;/h2>
&lt;p>Le GdR a mis en place deux appels avec pour date limite de dépot des dossiers le &lt;strong>15 mars&lt;/strong> et le &lt;strong>15 septembre&lt;/strong>.&lt;/p>
&lt;p>La date du 15 mars serait pour une mission d&amp;rsquo;avril à septembre (inclus), celle de septembre pour une mobilité d&amp;rsquo;octobre à mars (inclus) de l&amp;rsquo;année suivante.&lt;/p>
&lt;p>Le dossier pour postuler doit comprendre :&lt;/p>
&lt;ul>
&lt;li>une lettre de justification de la personne qui part (+ une lettre de son encadrant pour les doctorants)&lt;/li>
&lt;li>une lettre de justification de l&amp;rsquo;équipe / personne qui accueille&lt;/li>
&lt;li>un budget prévisionnel (1000 euros maximum, prévoir au plus juste pour nous puissions financer un maximum de collaborations)&lt;/li>
&lt;li>les dates de la mission&lt;/li>
&lt;/ul>
&lt;p>Une décision très rapide devrait arriver dans la foulée pour la mise en place de la mission. Le dossier est à envoyer à &lt;a href="mailto:direction@gdr-igrv.fr">direction@gdr-igrv.fr&lt;/a> (&lt;a href="https://gdr-igrv.fr/author/maud-marchal/">Maud Marchal&lt;/a>, &lt;a href="https://gdr-igrv.fr/author/david-coeurjolly/">David Coeurjolly&lt;/a>)&lt;/p>
&lt;/div>
&lt;/div>
&lt;h2 id="mobilités-passées">Mobilités passées&lt;/h2>
&lt;h3 id="en-2023-">En 2023 :&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/" target="_blank" rel="noopener">Retour sur les mobilités 2023&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="en-2022-">En 2022 :&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/" target="_blank" rel="noopener">Retour sur les mobilités 2022&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="en-2020-">En 2020 :&lt;/h3>
&lt;ul>
&lt;li>Nouvelle collaboration entre IRIT, ICube (IGG) et XLIM (IG), faisant suite à la journée thématique inter-GT GTAS/GTMG 2019 du GDR IG-RV Gestion de la Topologie en Animation, Simulation et Réalité Virtuelle et le GTMG2020, et concernant la mise en œuvre d&amp;rsquo;un algorithme de génération de maillage volumique à partir de squelette et en particulier un maillage quad autour d’une sphère pour les embranchements.&lt;/li>
&lt;/ul>
&lt;h3 id="en-2017-">En 2017 :&lt;/h3>
&lt;p>*Nouvelle collaboration et co-encadrement en le CReSTIC et CAOR (Mines Paris Tech) sur la simulation basée image: Des moyens de calculs aux moyens de restitution,
*Collaboration et co-encadrement entre XLIM (axe ASALI) et ICube (IGG) sur la synthèse de texture procédurale multi-résolution,&lt;/p>
&lt;ul>
&lt;li>Nouvelle collaboration entre le LORIA (Adagio) et LIGIM (A3SI) sur l&amp;rsquo;invariance géométrique par transformations rigides digitales,&lt;/li>
&lt;li>Co-encadrement de thèse entre le LE2i (MSGI) et l&amp;rsquo;IRIT (Vortex) sur l&amp;rsquo;analyse d&amp;rsquo;images pour la reconstruction 3D à base de squelettes,&lt;/li>
&lt;li>Co-encadrement de thèse entre ICA et XLIM (SIR) autour d&amp;rsquo;un nouveau pipeline de modélisation et de simulation temps réel pour l’animation d’images par modèles physiques : MIMESIS Temps-réel,&lt;/li>
&lt;li>Nouvelle collaboration entre l&amp;rsquo;IRISA (FRVSENSE) et l&amp;rsquo;IRIT (Vortex) sur l&amp;rsquo;étude des aspects perceptuels pour l’interpolation contrainte de palettes de couleurs.&lt;/li>
&lt;li>En 2016 :&lt;/li>
&lt;li>Collaboration entre XLIM (axe ASALI) et LIGM (A3SI) sur la reconnaissance de coniques,&lt;/li>
&lt;li>Collaboration entre Lab-STICC (IHSEV) et XLIM (SIR) sur la représentation de vagues déferlantes en synthèse d’image,&lt;/li>
&lt;li>Collaboration entre LE2i (MSGI) et ICube (IGG) pour l&amp;rsquo;écriture d&amp;rsquo;un ouvrage sur sur la modélisation géométrique par contraintes,&lt;/li>
&lt;li>Collaboration entre ICube (IGG) et LIP6 (Pequan) sur la génération de maillaqe pour l&amp;rsquo;animation multi-résolution d&amp;rsquo;objets déformables en temps-réel.&lt;/li>
&lt;/ul>
&lt;h3 id="en-2015">En 2015&lt;/h3>
&lt;ul>
&lt;li>Collaboration associant l&amp;rsquo;expertise en modélisation géométrique et algèbre géométrique du laboratoire XLIM-SIC (IG) avec l&amp;rsquo;expérience en vision par ordinateur et géométrie discrète (GdR ISIS) du laboratoire LIGM,&lt;/li>
&lt;li>Collaboration internationale visant à intégrer une architecture cognitive basée sur le principe de simulation mentale à un agent conversationnel animé dans le contexte d&amp;rsquo;une application médicale entre Lab-STICC (IHSEV) et Florida International University (soutien partiel du GdR IG-RV),&lt;/li>
&lt;li>Collaboration entre ICube (IGG) et IRISA (Hybrid) autour de la réalité virtuelle pour le WEB ,&lt;/li>
&lt;li>Collaboration entre XLIM (SIR) et ICA sur la modélisation physico-topologique,
*Collaboration entre IRIT (Vortex) et LIRIS (M2DISCO) sur la visualisation et d&amp;rsquo;édition collaborative de modèles 3D dans un environnement web,&lt;/li>
&lt;li>Collaboration entre IRIT (Vortex) et le LIRMM (ICAR) sur l&amp;rsquo;analyse géométrique et morphométrique pour la caractérisation et le recalage des objets 3D,&lt;/li>
&lt;li>Collaboration entre le LSIS (G-Mod) et le LIRIS (M2DISCO) sur la génération de maillages 3D avec les hiérarchies de diamants,&lt;/li>
&lt;li>Collaboration entre ICube (IGG) et LJK (Imagine) sur la génération de textures dynamiques sur des surfaces animées,&lt;/li>
&lt;/ul>
&lt;h3 id="en-2014">En 2014&lt;/h3>
&lt;ul>
&lt;li>Collaboration entre le Lab-STICC (IHSEV) et l&amp;rsquo;Institut du Mouvement sur l’interaction utilisateur - humain virtuel en environnement immersif,&lt;/li>
&lt;li>Collaboration entre l&amp;rsquo;IRIT (Vortex) et le Le2i (MSGI) sur la représentation multi-résolution de modèles 3D à partir de squelettes en vue d&amp;rsquo;application à la reconstruction, l&amp;rsquo;édition et la compression.&lt;/li>
&lt;/ul></description></item><item><title>Actions inter-GdR</title><link>https://gdr-igrv.fr/actions/inter-gdr/</link><pubDate>Mon, 20 Sep 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/actions/inter-gdr/</guid><description>&lt;p>Le GdR collabore avec d&amp;rsquo;autres GdR et structures d&amp;rsquo;animation de la recherche autour de journées thématiques spécifiques.&lt;/p>
&lt;h2 id="en-collaboration-avec-le-gdr-ifm">En collaboration avec le GdR IFM&lt;/h2>
&lt;p>Le GDR IM, en partenariat avec le GDR IG-RV, lance une année « Géométrie » pour 2023-2024. L’objectif est d’illustrer la richesse des recherches scientifiques autour de l’informatique géométrique, d’identifier les enjeux importants du domaine, et de favoriser de nouveaux projets et collaborations sur ces thèmes. Au programme, des journées thématiques, des événements pour les doctorants et post-doctorants et une conférence « Geometry and Computing » à l’automne 2024.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>EVÉNEMENTS&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;em>Journées thématiques&lt;/em>
&lt;ul>
&lt;li>Journée « Apprentissage pour la Géométrie », 26 octobre 2023, Institut Henri Poincaré. &lt;a href="https://ml4geo.sciencesconf.org" target="_blank" rel="noopener">https://ml4geo.sciencesconf.org&lt;/a>&lt;/li>
&lt;li>Journée des doctorants en Géométrie, 27 octobre 2023, Institut Henri Poincaré. &lt;a href="https://jcgeo.sciencesconf.org" target="_blank" rel="noopener">https://jcgeo.sciencesconf.org&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Conférence « Geometry &amp;amp; Computing », CIRM, Luminy, du 21 au 25 octobre 2024, co-localisation des journées des trois GT Géométrie.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>COMITÉ DE PILOTAGE&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Pilotage : Jacques-Olivier Lachaud (LAMA, Université Savoie Mont Blanc) &amp;amp; Mathieu Desbrun (LIX, Polytechnique et INRIA)&lt;/li>
&lt;li>GT Géométrie Algorithmique : Théo Lacombe (LIGM, Université Gustave Eiffel), Clément Maria (INRIA Sophia), Xavier Goaoc (LORIA, Université Lorraine)&lt;/li>
&lt;li>GT Géométrie Discrète et Morphologie Mathématique : Jean Cousty (LIGM, ESIEE), Isabelle Sivignon (Gipsa-lab, CNRS, Université Grenoble Alpes), Aldo Gonzalez-Lorenzo (LIS, Aix-Marseille Université)&lt;/li>
&lt;li>GT Modélisation Géométrique : Géraldine Morin (IRIT, Université de Toulouse), Romain Raffin (LIB, Université de Bourgogne), Julie Digne (LIRIS, CNRS)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="en-collaboration-avec-le-gdr-ia">En collaboration avec le GdR IA&lt;/h2>
&lt;ul>
&lt;li>« L&amp;rsquo;IA des personnages autonomes dans les mondes virtuels» : 7 novembre 2019 au LIP6 – Jussieu, Journée co-organisée par le GT IA et Jeux du GdR IA et le GdR IGRV.&lt;/li>
&lt;/ul>
&lt;h2 id="en-collaboration-avec-le-gdr-isis">En collaboration avec le GdR ISIS&lt;/h2>
&lt;ul>
&lt;li>« Explication des modèles des réseaux profonds en problèmes de classification, d&amp;rsquo;amélioration et d&amp;rsquo;interprétation des images et des signaux/données », lundi 11 octobre 2021. &lt;a href="http://www.gdr-isis.fr/index.php/reunion/460/" target="_blank" rel="noopener">http://www.gdr-isis.fr/index.php/reunion/460/&lt;/a>&lt;/li>
&lt;li>« Computational photography », jeudi 4 juin 2020 la 1ère partie à distance.&lt;/li>
&lt;li>« Compression et Représentation des Signaux Audiovisuels », CORESA 2014 dans le cadre de Reims Image 2014
&lt;a href="http://reimsimage2014.univ-reims.fr/coresa-2014/" target="_blank" rel="noopener">http://reimsimage2014.univ-reims.fr/coresa-2014/&lt;/a>&lt;/li>
&lt;li>« De l’acquisition à la compression des objets 3D – AC3D » : Journée organisée dans le cadre de l&amp;rsquo;action Maillage et Animation 3D / Thème D du GdR ISIS, en collaboration avec le GdR IG-RV (et précédemment GdR IG)
&lt;a href="http://www.i3s.unice.fr/~fpayan/gdr-isis.php" target="_blank" rel="noopener">http://www.i3s.unice.fr/~fpayan/gdr-isis.php&lt;/a>
&lt;ul>
&lt;li>AC3D’15, 26-28 Juin 2015 à Furiani (Corse)&lt;/li>
&lt;li>AC3D’14, Juin 2014 à Porquerolles&lt;/li>
&lt;li>AC3D’13, Mai 2013 à Porquerolles&lt;/li>
&lt;li>AC3D’11, 26-27 avril 2011 à Porquerolles&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>« La chaine numérique 3D : de l’acquisition à la compression des données », 24-30 Juin 2012 à Peyresq, 7ème école d’été en traitement du signal et des images du Gretsi.&lt;/li>
&lt;/ul>
&lt;h2 id="en-collaboration-avec-le-gdr-magis">En collaboration avec le GdR MAGIS&lt;/h2>
&lt;ul>
&lt;li>Journées &lt;a href="http://gdr-igrv.fr/event/journee-territoires-immersions-2024/" target="_blank" rel="noopener">&amp;ldquo;Journées Territoires et Immersion(s) 2024 - Lyon&amp;rdquo;&lt;/a>&lt;/li>
&lt;li>Journées &lt;a href="https://gdr-igrv.fr/event/journee-territoires-immersions-2023/" target="_blank" rel="noopener">&amp;ldquo;Journée Territoires et Immersion(s) 2023 - Nantes&amp;rdquo;&lt;/a>&lt;/li>
&lt;li>Série de webinars &amp;ldquo;Autour de la 3D&amp;rdquo;, &lt;a href="https://github.com/VCityTeam/MAGIS-AP3D/blob/master/Media/README.md" target="_blank" rel="noopener">programme 2021-2022 détaillé et les présentations 2020-2021&lt;/a>.&lt;/li>
&lt;li>« 3D et géospatial », prévue en 2021.&lt;/li>
&lt;li>« Visualisation &amp;amp; HCI for Crowd-Sourcing », mardi 25 juin 2019 à Clermont-Ferrand, en collaboration avec le GdR MAGIS.&lt;/li>
&lt;/ul>
&lt;h2 id="en-collaboration-avec-le-gdr-appamat-section-8-du-conrs-de-linsis">En collaboration avec le GdR APPAMAT (section 8 du CoNRS) de l&amp;rsquo;INSIS&lt;/h2>
&lt;ul>
&lt;li>« Matériaux réels / Matériaux virtuels », vendredi 12 juin 2020 la 1ère partie à distance avec le GdR APPAMAT.
En collaboration avec le feu-GdR STIC Santé :&lt;/li>
&lt;li>« Conception de simulateurs médico-chirurgicaux ? - Comment concevoir la partie numérique d’un simulateur interactif pour l’apprentissage de gestes médicaux ? » : 30 Juin au 4 Juillet 2014 à Lyon, Ecole thématique nationale organisée dans le cadre des actions du Thème F du GdR STIC Santé, en collaboration avec le GdR IG-RV
&lt;a href="http://ecole-simu2014.sciencesconf.org/" target="_blank" rel="noopener">http://ecole-simu2014.sciencesconf.org/&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Journées Territoires et Immersion(s)</title><link>https://gdr-igrv.fr/event/journee-territoires-immersions-2025/</link><pubDate>Thu, 09 Oct 2025 10:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee-territoires-immersions-2025/</guid><description>&lt;h1 id="journées-territoires-et-immersions-2025---9-et-10-octobre---bordeaux-pessac">Journées Territoires et Immersion(s) 2025 - 9 et 10 octobre - Bordeaux (Pessac)&lt;/h1>
&lt;p>Rencontre géomatique, informatique graphique et humanités numériques&lt;/p>
&lt;p>&lt;strong>Mots clés&lt;/strong> : 3D ; Immersion ; Réalités étendues ; Territoires augmentés ; Visualisation ; Interaction ; Collaboration ; Pluridisciplinarité ; Données multidimensionnelles&lt;/p>
&lt;p>Les journées d’étude « Territoires et immersion(s) » explorent l’immersion comme moyen de saisir l’essence d’un territoire. L’immersion, qu’elle soit liée à l’usage des réalités étendues, ou prise dans son acception plus large comme un moyen d’explorer des données interconnectées sur les plans spatial, géométrique, ou encore sémantique, a prouvé sa valeur pédagogique pour représenter les espaces physiques et les objets abstraits. Cette immersion, qui se base sur des représentations interactives visant l’analyse collective, le partage d’information ou la découverte d’un territoire, constitue un espace commun de discussion. Il s’agit donc d’un objet de médiation dont les contours sont à définir selon les usages, et les usages selon les capacités de la représentation à restituer les notions clés.&lt;/p>
&lt;p>Nous partagerons les avancées de la recherche sur ces enjeux, soulèverons des perspectives et thématiques émergentes, et échangerons autour de retours d’expériences sur des cas d’étude concrets, ainsi que dans un atelier proposé par le Consortium 3DHN : Sauvegarde pérenne des données 3D.&lt;/p>
&lt;h1 id="participation-">Participation :&lt;/h1>
&lt;p>Pour soumettre une présentation, vous pouvez envoyer vos propositions de communications en soumettant un résumé d’environ 500 mots avant le 12 septembre à l’adresse : &lt;a href="mailto:territoires_et_immersions@crenau.archi.fr">territoires_et_immersions@crenau.archi.fr&lt;/a>&lt;/p>
&lt;p>Liste de thèmes (non exhaustive) :&lt;/p>
&lt;ul>
&lt;li>Réalités étendues&lt;/li>
&lt;li>Usages de l’immersion&lt;/li>
&lt;li>Visualisation et analyse de données multidimensionnelles&lt;/li>
&lt;li>Modalités sensorielles&lt;/li>
&lt;li>Modalités d’interaction&lt;/li>
&lt;li>Approches collaboratives et pluridisciplinaires&lt;/li>
&lt;/ul>
&lt;p>Exemples de domaines d’applications :&lt;/p>
&lt;ul>
&lt;li>Patrimoine culturel&lt;/li>
&lt;li>Urbanisme&lt;/li>
&lt;li>Géographie&lt;/li>
&lt;li>Santé&lt;/li>
&lt;/ul>
&lt;h1 id="programme-prévisionnel-">Programme prévisionnel :&lt;/h1>
&lt;p>9 octobre - Journée Territoires et Immersions&lt;/p>
&lt;ul>
&lt;li>Présentation de la plateforme Archeovision&lt;/li>
&lt;li>Présentations scientifiques&lt;/li>
&lt;li>Démonstrations : SIR 3D, Lalibela, Iroungou,&lt;/li>
&lt;/ul>
&lt;p>10 octobre matin - Atelier : Sauvegarde pérenne des données 3D&lt;/p>
&lt;ul>
&lt;li>Initiation aux enjeux de la préservation des données 3D, démonstration de dépôt de jeux de données dans le Conservatoire national des données 3D à l&amp;rsquo;aide du logiciel aLTAG3D. Les participants sont invités à venir avec leurs propres jeux de données (modèle 3D / txt / jpg / etc.) afin de tester l’outil.&lt;/li>
&lt;/ul>
&lt;p>Pour compléter le programme des présentations sélectionnées et de l’atelier, trois démonstrations immersives viendront questionner les usages concrets de l’immersion appliquée aux territoires et alimenter les échanges interdisciplinaires sur les modalités de représentation, de médiation et d’analyse :&lt;/p>
&lt;p>SIR 3D : un système d’information référencé en 3D temps réel, permettant le croisement de données spatiales hétérogènes sur support 3D, sera présenté comme outil de suivi patrimonial et d’aide à la recherche.
La visite augmentée des églises rupestres de Lalibela : proposée en réalité mixte sur casques Hololens, illustrera une expérience immersive guidée dans un lieu patrimonial d’exception.
Iroungou VR : Une visite virtuelle de la grotte d’Iroungou via des casques Quest, offrant une exploration d’un espace riche en vestiges et objets archéologiques enfouis depuis le XIVème siècle.
Inscriptions :&lt;/p>
&lt;p>&lt;strong>Inscriptions gratuites et obligatoires, à la journée de présentation et/ou à l&amp;rsquo;atelier avant le 20 septembre à sur &lt;a href="https://forms.gle/FisZ6rv4X45GyEKk6" target="_blank" rel="noopener">ce formulaire&lt;/a>.&lt;/strong>&lt;/p>
&lt;h1 id="organisation-">Organisation :&lt;/h1>
&lt;p>Myriam Servières (AAU, Centrale Nantes), Violette Arbergel (MAP, CNRS), Vincent Tourre (AAU, Centrale Nantes), Mehdi Chayani (Archeoscience Bordeaux, CNRS), Florent Laroche (LS2N, Centrale Nantes), Xavier Granier (LP2N, IOA)&lt;/p></description></item><item><title>Journée GT Rendu 2025</title><link>https://gdr-igrv.fr/event/journee_gtrendu2025/</link><pubDate>Mon, 15 Sep 2025 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrendu2025/</guid><description>&lt;p>La prochaine journée du Groupe de Travail Rendu du GDR IGRV aura lieu dans les locaux d&amp;rsquo;Inria Paris le 15 septembre 2025.&lt;/p>
&lt;p>Venez faire vivre ces journées en contribuant ou simplement pour rencontrer et discuter avec la communauté graphique française !
Les thèmes abordés peuvent être variés pour aggrémenter les discussions et avoir un aperçu des activités françaises dans le domaine du rendu :&lt;/p>
&lt;ul>
&lt;li>travaux actuels, aboutis ou non, publiés ou non&lt;/li>
&lt;li>tours d&amp;rsquo;horizons sur des thèmes/approches/outils émergents&lt;/li>
&lt;li>travaux d&amp;rsquo;une équipe de recherche sur les dernières années&lt;/li>
&lt;li>etc.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>INSCRIPTIONS&lt;/strong>
Pour assister aux présentations, merci d&amp;rsquo;ajouter votre prénom/nom/organisme dans ce framapad :&lt;/p>
&lt;p>&lt;a href="https://mypads2.framapad.org/mypads/?/mypads/group/gt-rendu-a5vlb9h6/pad/view/gt-rendu-2025-4f3q239ue" target="_blank" rel="noopener">https://mypads2.framapad.org/mypads/?/mypads/group/gt-rendu-a5vlb9h6/pad/view/gt-rendu-2025-4f3q239ue&lt;/a>&lt;/p>
&lt;p>La liste des participants sera transmise à Inria 3 jours avant le début du GT et une pièce d&amp;rsquo;identité vous sera demandée à l&amp;rsquo;entrée.&lt;/p>
&lt;p>&lt;strong>CONTRIBUTIONS&lt;/strong>
Pour présenter, envoyez un email à Romain P., George et moi même contenant [GT Rendu] dans le sujet, avec les informations suivantes :&lt;/p>
&lt;ul>
&lt;li>Prénom, nom, organisme de l&amp;rsquo;orateur&lt;/li>
&lt;li>Titre de la présentation&lt;/li>
&lt;li>Eventuellement un lien vers une page web s&amp;rsquo;il s&amp;rsquo;agit d&amp;rsquo;un travail déjà publié/diffusé.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>ADRESSE&lt;/strong>
Centre de Recherche Inria de Paris&lt;/p>
&lt;p>48 Rue Barrault CS 61534
75 647 Paris Cedex - France
Salle : auditorium Jacques-Louis Lions au RDC du bâtiment A
Retrouvez les présentations des années précédentes sur le blog du GT : &lt;a href="http://gtrendu.blogspot.com/" target="_blank" rel="noopener">http://gtrendu.blogspot.com/&lt;/a>&lt;/p>
&lt;p>A très bientôt et en espérant vous voir nombreux pour cette occasion,&lt;/p>
&lt;p>Romain Pacanowski, George Drettakis &amp;amp; Romain Vergne&lt;/p></description></item><item><title>Journées du GT GDMM 2025</title><link>https://gdr-igrv.fr/event/journee_gtgdmm2025/</link><pubDate>Wed, 09 Jul 2025 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtgdmm2025/</guid><description>&lt;h2 id="dates-importantes">DATES IMPORTANTES&lt;/h2>
&lt;p>Proposition d&amp;rsquo;exposé (titre et résumé) : 13/06/2025&lt;/p>
&lt;p>Inscription : 20/06/2025&lt;/p>
&lt;p>Journées du GT-GDMM : les 9 et 10 Juillet 2025&lt;/p>
&lt;h2 id="gdmm--géométrie-discrète-et-morphologie-mathématiques">GDMM : Géométrie Discrète et Morphologie Mathématiques&lt;/h2>
&lt;h3 id="la-géométrie-discrète">La géométrie discrète&lt;/h3>
&lt;p>Le contexte de la géométrie discrète s’intègre dans le cadre général de la modélisation et l’analyse géométrique et topologique d’objets définis sur des structures régulières (ex. des grilles de pixels ou de voxels) ou combinatoires (graphes, cartes, etc.). Généralement, les axiomes et propriétés de la géométrie euclidienne classique ne sont plus valides lorsque l’on considère des ensembles de pixels. La définition de concepts et notions adaptés à des structures discrètes, mais néanmoins compatibles avec les concepts et notions continus, est alors requise. L’originalité de cette approche réside dans le fait qu’en exploitant les propriétés du support sur lequel sont décrits les objets, nous pouvons obtenir des algorithmes efficaces, certifiés et précis pour répondre à des problèmes de caractérisation géométrique ou topologique d’objets discrets (2D, 3D, nD, etc.). Le caractère discret des données à traiter, et donc l’utilité de l’approche discrète, se retrouvent dans de nombreux contextes applicatifs (analyse et traitements d’images, imagerie médicale, ingénierie des matériaux, etc.).&lt;/p>
&lt;h3 id="la-morphologie-mathématique">La morphologie mathématique&lt;/h3>
&lt;p>La morphologie mathématique est une théorie essentiellement non-linéaire, utilisée en particulier en analyse d’images, dont le but est l&amp;rsquo;étude des objets en fonction de leur forme, de leur taille, des relations avec leur voisinage (en particulier topologiques), de leur texture, et de leurs niveaux de gris ou de leur couleur. Par les transformations qu’elle propose, elle se situe à différents niveaux du traitement d’images (filtrage, segmentation, mesures, analyse de texture) et fournit ainsi des outils pour la reconnaissance des formes. La morphologie mathématique, développée à l’origine pour l&amp;rsquo;étude des matériaux poreux, trouve maintenant ses applications dans de nombreux domaines du traitement d’images, aussi bien 2D que 3D, en biologie et cytologie quantitative, en imagerie médicale, en imagerie aérienne et satellitaire, en robotique et vision par ordinateur, en contrôle industriel non destructif, dans les études sur les documents et les œuvres d’art. Hors du domaine du traitement des images, on trouve des applications par exemple en analyse de données, ou encore en théorie des jeux.&lt;/p></description></item><item><title>27èmes journées du Groupe de Travail Animation et Simulation</title><link>https://gdr-igrv.fr/event/journee_gtas2025/</link><pubDate>Mon, 07 Jul 2025 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtas2025/</guid><description>&lt;p>Les 27èmes Journées du GTAS, GT Animation et Simulation du GDR IG-RV du CNRS, se dérouleront les lundi 7 et mardi 8 juillet 2025 dans l&amp;rsquo;amphithéâtre Choquet-Bruhat de l&amp;rsquo;Institut Henri Poincaré, 11 rue Pierre et Marie Curie, 75231 Paris.&lt;/p>
&lt;p>Merci à Pascal Guehl, Mathieu Desbrun et l&amp;rsquo;équipe du LIX de l&amp;rsquo;École Polytechnique de nous accueillir cette année.&lt;/p>
&lt;p>Pour vous inscrire, c&amp;rsquo;est ici / Register here : &lt;a href="https://gtas2025.sciencesconf.org/" target="_blank" rel="noopener">https://gtas2025.sciencesconf.org/&lt;/a>&lt;/p>
&lt;p>L&amp;rsquo;inscription est gratuite mais obligatoire. Registration is free but mandatory&lt;/p>
&lt;h2 id="programme-provisoire">Programme provisoire&lt;/h2>
&lt;h3 id="lundi-7-juillet-2025">Lundi 7 juillet 2025&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>10h - 12h30&lt;/strong> : Atelier SOFA&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>12h30 - 13h55&lt;/strong> : Pause repas&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>13h55 – 14h00&lt;/strong> : Ouverture du GTAS&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>14h00 – 15h00&lt;/strong> : &lt;strong>Keynote&lt;/strong>&lt;br>
&lt;em>Kiwon Um&lt;/em> — &lt;em>AI for animation and physics simulations&lt;/em>, Télécom Paris&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>15h00 – 15h45&lt;/strong> : &lt;strong>Session 1&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;em>15h00 – 15h20&lt;/em> : &lt;strong>Open-source framework for interactive mechanical simulation – Innovation catalyst in medicine and robotics&lt;/strong>, Hugo Talbot (Inria)&lt;/li>
&lt;li>&lt;em>15h25 – 15h45&lt;/em> : &lt;strong>Analytical Geometry for fluid simulations based on Partial Optimal Transport&lt;/strong>, Cyprien Plateau-Holleville &amp;amp; Bruno Lévy (Inria Saclay)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>15h50 – 16h10&lt;/strong> : Pause café&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>16h10 – 17h45&lt;/strong> : &lt;strong>Session 2&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;em>16h10 – 16h50&lt;/em> : &lt;strong>Présentation du GDR MORPHEA&lt;/strong>, Jean-Sébastien Kroll-Rabotin&lt;/li>
&lt;li>&lt;em>16h55 – 17h15&lt;/em> : &lt;strong>Simulation de fluides avec LBM&lt;/strong>, Allan Blanchard &amp;amp; Benoît Crespin (XLIM – Université de Limoges)&lt;/li>
&lt;li>&lt;em>17h20 – 17h40&lt;/em> : &lt;strong>Unified speech and co-speech gesture synthesis using gated linear attention&lt;/strong>, Téo Guichoux, Théodore Lemerle, Laure Soulier, Nicolas Obin, Catherine Pelachaud (Sorbonne Université, ISIR, IRCAM, STMS Lab)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>18h00 – 19h00&lt;/strong> : &lt;strong>Moment artistique&lt;/strong>&lt;br>
&lt;em>Jean-Marc Chomaz&lt;/em>, artiste-physicien, professeur à l’École polytechnique et co-fondateur de la Chaire Arts &amp;amp; Sciences&lt;br>
&lt;a href="https://chaire-arts-sciences.org" target="_blank" rel="noopener">https://chaire-arts-sciences.org&lt;/a>&lt;br>
&lt;em>Lieu : à préciser&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>19h30&lt;/strong> : Dîner au restaurant (&lt;em>lieu à confirmer&lt;/em>), offert par le GDR&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="mardi-8-juillet-2025">Mardi 8 juillet 2025&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>09h00&lt;/strong> : Accueil&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>09h00 – 10h30&lt;/strong> : &lt;strong>Session spéciale &amp;ldquo;Animation et contrôle des animations par les artistes&amp;rdquo;&lt;/strong> + discussions&lt;/p>
&lt;ul>
&lt;li>&lt;em>09h00 – 09h20&lt;/em> : &lt;strong>SMACC: Sketching Motion for Articulated Characters with Comics-based annotations&lt;/strong>, Amandine Legrand, Amal Dev Parakkat &amp;amp; Damien Rohmer (Télécom Paris &amp;amp; École Polytechnique)&lt;/li>
&lt;li>&lt;em>09h25 – 09h45&lt;/em> : &lt;strong>Le &amp;ldquo;control rig&amp;rdquo; comme abstraction du mouvement : simplifier l&amp;rsquo;animation pour l&amp;rsquo;algorithme comme pour l&amp;rsquo;artiste&lt;/strong>, Théo Cheynel (Kinetix)&lt;/li>
&lt;li>&lt;em>09h50 – 10h10&lt;/em> : &lt;strong>Édition d’animation 3D via contrôle multimodal d’un espace latent&lt;/strong>, Théo Gérard, Marc Christie, Ludovic Hoyet, Pierre Hellier (VirtUs, Combo, IRISA)&lt;/li>
&lt;li>&lt;em>10h15 – 10h30&lt;/em> : Discussions prospectives&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>10h30 – 10h45&lt;/strong> : Pause café&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>10h45 – 11h35&lt;/strong> : &lt;strong>Session 4&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>10h45 – 11h05&lt;/em> : &lt;strong>MoCoSys: Human Motion Correction based on Deep Learning Coupled with 3D+t Laplacian Motion Representation&lt;/strong>, &lt;u>Mansour Tchenegnon&lt;/u>, Sylvie Gibet et Thibaut Le Naour, Expression IRISA&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>11h10 – 11h25&lt;/em> : &lt;strong>Pipeline pour la capture et l’annotation à grande échelle de mouvements humains 3D à partir de vidéos collectées automatiquement&lt;/strong>, Nathan Salazar (LIRIS)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>11h35 – 12h30&lt;/strong> : Discussions prospectives&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="appel-à-présentations">Appel à présentations&lt;/h2>
&lt;p>Toutes les thématiques de l’animation et de la simulation sont les bienvenues. Nous recherchons également des interventions sur l&amp;rsquo;enseignement de l&amp;rsquo;animation et de la simulation ou encore des démos pour le moment artistique.&lt;/p>
&lt;p>Pour soumettre une proposition, envoyez un mail à &lt;strong>&lt;a href="mailto:caroline.larboulette@univ-ubs.fr">caroline.larboulette@univ-ubs.fr&lt;/a>&lt;/strong> et &lt;strong>&lt;a href="mailto:benoit.crespin@unilim.fr">benoit.crespin@unilim.fr&lt;/a>&lt;/strong> avec les informations suivantes :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Titre&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Auteurs &amp;amp; affiliations&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Mots-clés ou court résumé&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Une image (600 pixels de haut) si possible&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Durée souhaitée&lt;/strong> (standard : 20 minutes + questions)&lt;/li>
&lt;/ul>
&lt;p>Tous les orateurs sont les bienvenus, qu&amp;rsquo;ils soient doctorants, post-doctorants, ingénieurs ou permanents.&lt;/p>
&lt;p>Comme aux précédentes éditions, les contributions peuvent être :&lt;/p>
&lt;ul>
&lt;li>Présentations de résultats récents sur tous les thèmes de l’animation et de la simulation, notamment par des jeunes chercheurs (présentation d’articles récemment publiés, sujets doctoraux, avancées réalisées, synthèses de thèse ou post-doctorat…)&lt;/li>
&lt;li>Présentations à plus large spectre : rétrospectives, points de vue sur les problématiques du domaine, HDR, état de l’art…&lt;/li>
&lt;li>Moments d’échanges conviviaux et sessions thématiques ouvertes à d&amp;rsquo;autres formats !&lt;/li>
&lt;/ul>
&lt;h3 id="thématiques-particulières-de-cette-édition">Thématiques particulières de cette édition&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Focus spécial : &amp;ldquo;Animation et contrôle des animations par les artistes&amp;rdquo;&lt;/strong> avec une session dédiée.&lt;/li>
&lt;li>&lt;strong>Atelier-discussion sur l&amp;rsquo;enseignement de l’animation et simulation&lt;/strong> et son usage en pédagogie – retours d’expériences bienvenus.&lt;/li>
&lt;li>&lt;strong>Moment artistique&lt;/strong> : partage de travaux artistiques en lien avec les thématiques GTAS – idées et contacts bienvenus !&lt;/li>
&lt;/ul>
&lt;h2 id="modalités-pratiques">Modalités pratiques&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Participation gratuite&lt;/strong> (inscription bientôt ouverte, réservez vos dates !)&lt;/li>
&lt;li>&lt;strong>Présentations en français ou en anglais&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Les jeunes chercheurs sont encouragés à préparer leurs slides en anglais&lt;/strong> pour les utiliser lors d’événements internationaux.&lt;/li>
&lt;li>&lt;strong>Un soutien financier peut être proposé pour certaines missions&lt;/strong> – contactez-nous si besoin.&lt;/li>
&lt;/ul>
&lt;p>N’hésitez pas à nous contacter pour toute question !&lt;/p>
&lt;p>&lt;em>Avec le soutien du GdR IG-RV, de l’INS2i du CNRS.&lt;/em>&lt;/p></description></item><item><title>Journées Scientifiques GT-RV 2025</title><link>https://gdr-igrv.fr/event/journees_gtrv2025/</link><pubDate>Thu, 03 Jul 2025 14:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journees_gtrv2025/</guid><description>&lt;p>Le GT-RV est désormais commun aux GDR IG-RV et GDR IHM. Ce dernier ayant été créé en fin d&amp;rsquo;année 2024, il nous a semblé particulièrement important de réunir les membres des deux communautés pour partager ensemble durant ce temps de rencontres et d’échanges. Pour cela, nous avons choisi d’accoler nos journées à la journée de lancement du GDR IHM.&lt;/p>
&lt;p>Les journées du GT-RV auront donc lieu les &lt;strong>3 juillet après-midi et 4 juillet matin 2025&lt;/strong> à l’&lt;strong>INSA Lyon&lt;/strong>, à la suite de la journée de lancement du GDR IHM qui aura lieu au même endroit le 3 juillet 2025.&lt;/p>
&lt;h1 id="inscriptions">Inscriptions&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>Les inscriptions aux journées du GT-RV sont gratuites, mais vous devez vous inscrire avant le 17 juin 2025 via ce lien d’inscription : &lt;a href="https://evento.renater.fr/survey/participation-au-gt-rv-a-la-suite-des-journees-de-lancement-du-gdr-ihm-lrc0uty5" target="_blank" rel="noopener">https://evento.renater.fr/survey/participation-au-gt-rv-a-la-suite-des-journees-de-lancement-du-gdr-ihm-lrc0uty5&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Pour la soirée du 3 juillet, nous nous proposons d’essayer d’organiser un dîner, où chacun devra régler sa part, afin de pouvoir nous retrouver ensemble. Vous pourrez nous indiquer si vous souhaitez participer à ce dîner, là aussi jusqu’au 17 juin via le même lien ci-dessus.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Pour la journée du 3 juillet, si vous souhaitez participer à toute la journée de lancement du GDR IHM (déjeuner et pauses inclus), il vous faudra vous inscrire séparément à cet événement (inscription payante).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="planning-prévisionnel">Planning prévisionnel&lt;/h1>
&lt;h3 id="jeudi-3-juillet-2025-après-midi">Jeudi 3 juillet 2025 après-midi&lt;/h3>
&lt;p>Les journées du GT-RV seront intégrées à la journée de lancement du GDR IHM, et plus particulièrement consistera en un atelier sur la prospective scientifique des domaines adressés par le GT-RV. L’objectif de cet atelier de prospective est d’approfondir le travail initié depuis 2019. Cet exercice de prospective est important pour la vie de notre communauté et l’avenir des GDR. Il est souhaitable de réunir un panel de jeunes, et moins jeunes, chercheurs, traitant de sujets variés. Un des objectifs de ce séminaire de prospective est de pouvoir remonter des sujets « chauds » qui servent au CNRS à la fois à des fins internes (fléchages d’appels à projets, etc.) et externes (p. ex. contribuer à la construction des appels européens).&lt;/p>
&lt;h4 id="soirée">Soirée&lt;/h4>
&lt;ul>
&lt;li>Repas dans un restaurant (à vos frais malheureusement)&lt;/li>
&lt;/ul>
&lt;h3 id="vendredi-4-juillet-2025-matin">Vendredi 4 juillet 2025 matin&lt;/h3>
&lt;p>La matinée sera « exclusive » au GT-RV, elle sera composée de présentations scientifiques, où nous souhaitons mettre en avant des contributions de jeunes chercheuses et jeunes chercheurs de la communauté ainsi que d’une keynote.&lt;/p>
&lt;ul>
&lt;li>9h00-9h10 : Ouverture&lt;/li>
&lt;li>9h15-10h00 : Keynote&lt;/li>
&lt;li>Pause café (offerte)&lt;/li>
&lt;li>10h30-12h : Présentations JC&lt;/li>
&lt;li>12h00-12h30 : Fermeture&lt;/li>
&lt;/ul>
&lt;p>Sous réserve de budget suffisant (et en fonction du nombre d’inscriptions) nous essaierons de vous proposer un buffet le &lt;strong>4 juillet midi avant&lt;/strong> votre départ. Nous reviendrons vers vous concernant cela une fois les inscriptions terminées.&lt;/p>
&lt;h1 id="appel-à-présentations">Appel à présentations&lt;/h1>
&lt;p>Lors des journées du GT-RV, nous souhaitons mettre en avant des contributions de jeunes chercheuses et jeunes chercheurs de la communauté. Contactez-nous par mail si vous souhaitez proposer une présentation, que ce soit des travaux actuels, aboutis ou non, publiés ou non, un tour d&amp;rsquo;horizon sur des thèmes/approches/outils émergents, des travaux d&amp;rsquo;une équipe de recherche sur les dernières années ou autres, d’une envie de monter un projet&amp;hellip; Toute contribution est bienvenue !&lt;/p>
&lt;ul>
&lt;li>Cédric Fleury : firstname.lastname [at] imt-atlantique.fr&lt;/li>
&lt;li>Jean-Marie Normand : firstname.lastname [at] ec-nantes.fr&lt;/li>
&lt;/ul>
&lt;p>Les présentations sont prévues pour durer une quinzaine de minutes maximum (hors questions).&lt;/p>
&lt;p>Merci de préciser dans votre mail :&lt;/p>
&lt;ul>
&lt;li>vos prénoms et noms&lt;/li>
&lt;li>votre laboratoire&lt;/li>
&lt;li>Si vous souhaitez faire une présentation : le titre de votre présentation (complété de quelques mots clés si nécessaire).&lt;/li>
&lt;/ul>
&lt;p>Dans un deuxième temps, vous devrez fournir un résumé de la présentation qui restera accessible à la suite de la journée.&lt;/p>
&lt;h1 id="comment-venir">Comment venir&lt;/h1>
&lt;p>Les journées du GT-RV se dérouleront à INSA Lyon sur le site de LyonTech-la Doua (20, avenue Albert Einstein - 69621 Villeurbanne). Vous trouverez ici les informations pour nous venir :&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.insa-lyon.fr/fr/plan-d-acces" target="_blank" rel="noopener">https://www.insa-lyon.fr/fr/plan-d-acces&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Journées Visu 2025</title><link>https://gdr-igrv.fr/event/journee_visu2025/</link><pubDate>Mon, 16 Jun 2025 13:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_visu2025/</guid><description>&lt;p>La prochaine journée du groupe de travail Visualisation du GdR IG-RV se déroulera cette année encore sur deux demi-journées : l’après-midi du 16 juin et le matin du 17 juin 2025.
Les équipes du LICIIS avec le soutien du CEA vous accueilleront dans les locaux de l&amp;rsquo;IUT de Reims - amphithéâtre 2 du bâtiment C - sur le campus Moulin de la Housse.&lt;/p>
&lt;p>&lt;a href="https://visu-25.sciencesconf.org/" target="_blank" rel="noopener">https://visu-25.sciencesconf.org/&lt;/a>&lt;/p>
&lt;p>Sont admises des soumissions sur résumé (jusqu’à deux pages), en français ou en anglais, qui présentent des travaux originaux. Il peut s&amp;rsquo;agir de :&lt;/p>
&lt;p>travaux de recherche finalisés ou en cours, de projets ANR, européens ou autres, de retours d&amp;rsquo;expériences industriels, etc. Si une vidéo pré-enregistrée existe elle pourra être diffusée pendant la journée.
travaux qui ont été soumis (soumis à tout évènement de type conférence, workshop, meeting, sous toutes les formes usuelles : papier, papier court, poster, abstract &amp;hellip;) mais pas acceptés, et qui seront donc présentés dans le but de les améliorer en vue d&amp;rsquo;une nouvelle soumission ou tout simplement de &amp;ldquo;valoriser&amp;rdquo; l&amp;rsquo;investissement.
travaux non encore soumis, et qui seront présentés en vue d&amp;rsquo;avoir un premier retour de la communauté.
L&amp;rsquo;objectif n&amp;rsquo;est pas de faire de la sélection mais bien de permettre à chacun, au contraire, de présenter ses travaux.&lt;/p>
&lt;p>DATES IMPORTANTES&lt;/p>
&lt;ul>
&lt;li>19 mars 2025 : Ouverture du site et des inscriptions&lt;/li>
&lt;li>12 mai 2025 : Date limite de soumission des articles&lt;/li>
&lt;li>30 mai 2025 : Notifications d&amp;rsquo;acceptation&lt;/li>
&lt;li>16 et 17 juin 2025 : Journée Visu à Reims (IUT de Reims)&lt;/li>
&lt;/ul>
&lt;p>INSCRIPTIONS&lt;/p>
&lt;p>La journée Visu 2025 est gratuite et ouverte à toutes et tous dans la limite des capacités d&amp;rsquo;accueil. Les inscriptions sont cependant obligatoires.
Merci de vous inscrire le plus tôt possible afin de faciliter la logistique afférente à cet évènement. La date de clôture des inscriptions est fixée au 9 juin 2025.&lt;/p>
&lt;p>N’hésitez pas i) à prendre contact avec nous pour toutes demandes d&amp;rsquo;informations complémentaires et ii) à diffuser l&amp;rsquo;information auprès de vos étudiants et collègues.
Merci pour votre intérêt.&lt;/p>
&lt;p>A bientôt à Reims, l&amp;rsquo;équipe organisatrice&lt;/p>
&lt;hr>
&lt;p>** English version **&lt;/p>
&lt;p>The upcoming day of the IG-RV working group on visualization will be take place over two half-days again this year: the afternoon of June 16 and the morning of June 17, 2025.
The LICIIS staff, with the support of the CEA, will welcome you at the IUT de Reims - amphitheater 2 of building C - on the Moulin de la Housse campus.&lt;/p>
&lt;p>&lt;a href="https://visu-25.sciencesconf.org/" target="_blank" rel="noopener">https://visu-25.sciencesconf.org/&lt;/a>&lt;/p>
&lt;p>We welcome abstract submissions (up to two pages), in English or French, presenting original work. These may include :&lt;/p>
&lt;p>research projects completed or in progress, ANR, European or other projects, feedback from industry, etc. If a pre-recorded video exists, it can be shown during the day.
work that has been submitted (submitted to any conference, workshop or meeting, in all the usual forms: paper, short paper, poster, abstract, etc.) but not accepted, and which will therefore be presented with the aim of improving it with a view to a new submission, or simply to “promote” the investment.
work not yet submitted, and which will be presented with a view to obtaining initial feedback from the community.
The aim is not to be selective, but to give everyone the opportunity to present their work.&lt;/p>
&lt;p>IMPORTANT DATES&lt;/p>
&lt;ul>
&lt;li>March 19, 2025: Opening of the website and registration&lt;/li>
&lt;li>May 12, 2025: Deadline for submission of articles&lt;/li>
&lt;li>May 30, 2025: Notification of acceptance&lt;/li>
&lt;li>June 16 and 17, 2025: Vis&amp;rsquo;Day in Reims (IUT de Reims)&lt;/li>
&lt;/ul>
&lt;p>REGISTRATION&lt;/p>
&lt;p>Vis&amp;rsquo;Day 2025 is free and open to all, subject to capacity. However, registration is compulsory.
Please register as soon as possible to facilitate the logistics of this event. The closing date for registrations is June 9, 2025.&lt;/p>
&lt;p>Do not hesitate to i) get in touch with us if you need any further information and ii) share the information with your students and colleagues.
Thank you for your interest.&lt;/p>
&lt;p>See you soon in Reims, the organizing team&lt;/p></description></item><item><title>Résultats du prix de thèse du GdR et des associations AFIG et EGFR 2025</title><link>https://gdr-igrv.fr/post/25-07-10-prixthese/</link><pubDate>Sat, 14 Jun 2025 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/25-07-10-prixthese/</guid><description>&lt;p>&lt;strong>Résultats du prix de thèse du GDR IG-RV 2025
en collaboration avec l’Association Française d’Informatique Graphique et le Chapitre Français d’Eurographics.&lt;/strong>&lt;/p>
&lt;p>&lt;a href="http://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">Page des prix de thèse pour plus de détails sur les lauréats&lt;/a>&lt;/p>
&lt;p>Pour cette neuvieme édition, la participation au concours était ouverte aux docteurs ayant soutenu leur thèse entre le 01/01/2024 et le 31/12/2024. Il y a eu 12 soumissions, toutes d’un excellent niveau scientifique et couvrant largement les thématiques du GDR IG-RV. Le jury 2025 a été animé par Georges-Pierre Bonneau et Guillaume Cordonnier. Il était composé de Rebecca Fribourg, Fanny Chevalier, Jean-Michel Dischler, Bruno Levy, Damien Rohmer et Eric Galin.
Le prix de thèse du GDR IG-RV 2024 est décerné à :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Cyprien Plateau-Holleville&lt;/strong> (XLIM, Université de Limoges) pour sa thèse intitulée « &lt;em>Construction efficace de géométrie pour l&amp;rsquo;analyse structurelle de grands systèmes moléculaires&lt;/em> » effectuée sous la direction de Maxime Maria et Stéphane Mérillou&lt;/li>
&lt;/ul>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2025/CPH-prix-these.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://theses.hal.science/tel-04906696v1" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>Avec deux accessits :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Souhaib Attaiki&lt;/strong> (Ecole Polytechnique) pour sa thèse intitulée « &lt;em>Robust Deep Learning-based Methods for Non-Rigid Shape Correspondence&lt;/em> » effectuée sous la direction de Maks Ovsjanikov&lt;/li>
&lt;/ul>
&lt;!--
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2024/LoannGio_igrv_jfig_v3.mp4" type="video/mp4">
&lt;/video> -->
&lt;p>&lt;a href="https://theses.hal.science/tel-04956932v1" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>&lt;strong>Antonin Cheymol&lt;/strong> (INSA Rennes) pour sa thèse intitulée « &lt;em>Reshaping the virtual body’s appearance and movements : A contribution to the study of avatar alteration in virtual reality&lt;/em> » effectuée sous la direction de Ferran Argelaguet, Jean-Marie Normand, Anatole Lecuyer et Rebecca Fribourg.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2025/videoAntoninCheymol.mp4" type="video/mp4">
&lt;/video>
&lt;p>Nous tenons à remercier l’ensemble des candidats pour leur participation,&lt;/p></description></item><item><title>Résultats du prix 2025</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2025/</link><pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2025/</guid><description>&lt;h2 id="lauréat">Lauréat&lt;/h2>
&lt;p>&lt;strong>Cyprien Plateau-Holleville&lt;/strong> (XLIM, Université de Limoges) pour sa thèse intitulée « &lt;em>Construction efficace de géométrie pour l&amp;rsquo;analyse structurelle de grands systèmes moléculaires&lt;/em> » effectuée sous la direction de Maxime Maria et Stéphane Mérillou&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2025/CPH-prix-these.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://theses.hal.science/tel-04906696v1" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;h2 id="accessits">Accessits&lt;/h2>
&lt;p>&lt;strong>Souhaib Attaiki&lt;/strong> (Ecole Polytechnique) pour sa thèse intitulée « &lt;em>Robust Deep Learning-based Methods for Non-Rigid Shape Correspondence&lt;/em> » effectuée sous la direction de Maks Ovsjanikov&lt;/p>
&lt;!--
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2024/LoannGio_igrv_jfig_v3.mp4" type="video/mp4">
&lt;/video> -->
&lt;p>&lt;a href="https://theses.hal.science/tel-04956932v1" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>&lt;strong>Antonin Cheymol&lt;/strong> (INSA Rennes) pour sa thèse intitulée « &lt;em>Reshaping the virtual body’s appearance and movements : A contribution to the study of avatar alteration in virtual reality&lt;/em> » effectuée sous la direction de Ferran Argelaguet, Jean-Marie Normand, Anatole Lecuyer et Rebecca Fribourg.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2025/videoAntoninCheymol.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://theses.hal.science/tel-04986119v1" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>&lt;em>Le jury 2025 a été animé par Georges-Pierre Bonneau et Guillaume Cordonnier. Il était composé de Rebecca Fribourg, Fanny Chevalier, Jean-Michel Dischler, Bruno Levy, Damien Rohmer et Eric Galin.&lt;/em>&lt;/p></description></item><item><title>jcgeo25 Jeunes Chercheuses et Chercheurs en Géométrie</title><link>https://gdr-igrv.fr/event/journee-jeunes-geometrie-2025/</link><pubDate>Wed, 04 Jun 2025 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee-jeunes-geometrie-2025/</guid><description>&lt;h2 id="dates-importantes">DATES IMPORTANTES&lt;/h2>
&lt;p>Demande financement mission : 19 mai
Inscription : 23 mai
Dépôt slides présentation courte : 30 mai
Journée Jeunes Chercheuses et Chercheurs en Géométrie : 4 Juin&lt;/p></description></item><item><title>Journées plénières du GdR IG-RV</title><link>https://gdr-igrv.fr/event/pleniere2025/</link><pubDate>Mon, 02 Jun 2025 12:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/pleniere2025/</guid><description>&lt;p>Programme scientifique en construction.&lt;/p></description></item><item><title>Journées du GTMG</title><link>https://gdr-igrv.fr/event/journee_gtmg2025/</link><pubDate>Wed, 19 Mar 2025 11:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtmg2025/</guid><description/></item><item><title>Prix de thèse Gilles Kahn et prix de thèse du GdR IG-RV 2024 – Félicitations aux lauréats !</title><link>https://gdr-igrv.fr/post/25-02-24-prix-gilles-kahn-news-cnrs/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/25-02-24-prix-gilles-kahn-news-cnrs/</guid><description>&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table des matières&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#émilie-yu-des-outils-pionniers-pour-la-création-3d--prix-de-thèse-gilles-kahn-2024">Émilie Yu, des outils pionniers pour la création 3D – Prix de thèse Gilles Kahn 2024&lt;/a>&lt;/li>
&lt;li>&lt;a href="#le-prix-de-thèse-du-gdr-ig-rv-2024-et-la-mise-à-lhonneur-dans-la-newsletter-cnrs">Le prix de thèse du GdR IG-RV 2024 et la mise à l&amp;rsquo;honneur dans la newsletter CNRS&lt;/a>&lt;/li>
&lt;li>&lt;a href="#julie-digne-à-lhonneur-pour-ses-travaux-en-optimisation">Julie Digne à l&amp;rsquo;honneur pour ses travaux en optimisation&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;h2 id="émilie-yu-des-outils-pionniers-pour-la-création-3d--prix-de-thèse-gilles-kahn-2024">Émilie Yu, des outils pionniers pour la création 3D – Prix de thèse Gilles Kahn 2024&lt;/h2>
&lt;p>Le &lt;strong>prix de thèse Gilles Kahn 2024&lt;/strong>, décerné par la &lt;strong>Société Informatique de France (SIF)&lt;/strong> et l&amp;rsquo;&lt;strong>Académie des Sciences&lt;/strong>, a été attribué à &lt;strong>Émilie Yu&lt;/strong> pour ses travaux en informatique graphique et en réalité virtuelle.&lt;/p>
&lt;p>Sa thèse, intitulée &lt;em>Designing Tools for 3D Content Authoring Based on 3D Sketching&lt;/em>, explore la &lt;strong>création, l’édition et l’animation de formes tridimensionnelles à partir d’esquisses&lt;/strong>. Alors que le dessin et les esquisses 2D sont des outils largement répandus dans la création graphique et le design industriel, proposer un équivalent en &lt;strong>dessin 3D&lt;/strong> accessible et intuitif représente un défi majeur.&lt;/p>
&lt;p>Les recherches d’Émilie Yu se basent sur les concepts de &lt;strong>« coup de crayon 3D »&lt;/strong>, &lt;strong>« esquisse 3D »&lt;/strong> et &lt;strong>« couches d’édition 3D »&lt;/strong>, permettant aux graphistes et designers d’exprimer leurs idées en 3D aussi facilement qu’en 2D. Sa méthodologie, fondée sur des entretiens avec des professionnels du domaine, assure une forte &lt;strong>adéquation des outils développés avec les besoins réels des créateurs&lt;/strong>.&lt;/p>
&lt;p>Ces travaux, réalisés sous la direction d’&lt;strong>Adrien Bousseau&lt;/strong> au sein de l’&lt;strong>équipe-projet GraphDeco&lt;/strong> du &lt;strong>Centre Inria d’Université Côte d’Azur&lt;/strong>, ont abouti à un manuscrit &lt;strong>remarquablement didactique et agréable à lire&lt;/strong>. Aujourd’hui, Émilie Yu poursuit ses recherches en tant que &lt;strong>post-doctorante à l’Expressive Computation Lab de l’UC Santa Barbara, Californie&lt;/strong>.&lt;/p>
&lt;p>Le jury du prix Gilles Kahn a souligné &lt;strong>la qualité exceptionnelle des résultats obtenus, publiés au meilleur niveau international&lt;/strong>, ainsi que &lt;strong>la rigueur et l&amp;rsquo;approche utilisateur&lt;/strong> qui ont guidé ses recherches.&lt;/p>
&lt;h2 id="le-prix-de-thèse-du-gdr-ig-rv-2024-et-la-mise-à-lhonneur-dans-la-newsletter-cnrs">Le prix de thèse du GdR IG-RV 2024 et la mise à l&amp;rsquo;honneur dans la newsletter CNRS&lt;/h2>
&lt;p>Le &lt;strong>GDR IG-RV&lt;/strong> (Informatique Géométrique et Graphique, Réalité Virtuelle et Visualisation) a décerné son &lt;strong>prix de thèse 2024&lt;/strong> à &lt;strong>Émilie Yu&lt;/strong> pour ses recherches sur la conception d&amp;rsquo;outils de création 3D basés sur le dessin 3D. Ses travaux proposent des interactions innovantes pour permettre aux créateurs d’exploiter la spontanéité et la précision du dessin dans des environnements tridimensionnels.&lt;/p>
&lt;p>En plus du prix principal, deux &lt;strong>accessits&lt;/strong> ont été attribués :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Loann Giovannangeli&lt;/strong>, pour ses travaux sur l’utilisation de l’intelligence artificielle pour la génération et l’évaluation de visualisations d’information, réalisés au &lt;strong>LaBRI – Université de Bordeaux&lt;/strong>.&lt;/li>
&lt;li>&lt;strong>Axel Paris&lt;/strong>, pour sa thèse sur la &lt;strong>modélisation et simulation des terrains virtuels&lt;/strong>, menée au &lt;strong>LIRIS – Université Claude Bernard Lyon 1&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;p>Le prix de thèse du GdR IG-RV a été mis en avant dans la dernière &lt;strong>newsletter CNRS Sciences Informatiques&lt;/strong>, aux côtés d’autres travaux de pointe en &lt;strong>création numérique, intelligence artificielle et simulation de terrains&lt;/strong>.&lt;/p>
&lt;p>🔗 &lt;a href="https://www.ins2i.cnrs.fr/fr/cnrsinfo/creation-numerique-et-ia-le-gdr-ig-rv-distingue-des-recherches-de-pointe-en-3d-ia-et" target="_blank" rel="noopener">Lire l&amp;rsquo;article sur le prix de thèse du GdR IG-RV&lt;/a>&lt;br>
🔗 &lt;a href="https://gdr-igrv.fr/post/24-06-14-prixthese/" target="_blank" rel="noopener">Annonce du prix de thèse du GdR IG-RV sur le site du GdR&lt;/a>&lt;/p>
&lt;h2 id="julie-digne-à-lhonneur-pour-ses-travaux-en-optimisation">Julie Digne à l&amp;rsquo;honneur pour ses travaux en optimisation&lt;/h2>
&lt;p>La newsletter CNRS met également en avant &lt;strong>Julie Digne&lt;/strong>, directrice de recherche au &lt;strong>LIRIS - CNRS/INSA de Lyon/Université Claude Bernard Lyon 1&lt;/strong>, pour ses recherches en &lt;strong>traitement numérique de la géométrie et optimisation&lt;/strong>.&lt;/p>
&lt;p>L&amp;rsquo;optimisation joue un rôle clé dans ses travaux, notamment pour le &lt;strong>recalage de modèles sur des formes&lt;/strong>, une technique utilisée pour estimer la posture d&amp;rsquo;êtres humains ou d&amp;rsquo;objets scannés. Elle développe des méthodes spécifiques permettant &lt;strong>d&amp;rsquo;effectuer des calculs efficaces sur des données géométriques complexes&lt;/strong>.&lt;/p>
&lt;p>Dans ses recherches récentes, elle s&amp;rsquo;est intéressée aux &lt;strong>problèmes posés par l’apprentissage automatique appliqué aux données géométriques&lt;/strong>, qui nécessitent des approches d’optimisation adaptées du fait de la difficulté à représenter des surfaces géométriques sous forme de grilles.&lt;/p>
&lt;p>À l’avenir, elle souhaite explorer des &lt;strong>applications low tech&lt;/strong>, notamment le développement de &lt;strong>réseaux de neurones très légers&lt;/strong> pouvant être utilisés pour des tâches d’analyse de formes tout en limitant les ressources de calcul nécessaires.&lt;/p>
&lt;p>🔗 &lt;a href="https://www.ins2i.cnrs.fr/fr/cnrsinfo/optimisation-conversation-avec-julie-digne" target="_blank" rel="noopener">Lire l&amp;rsquo;article sur Julie Digne dans la newsletter CNRS&lt;/a>&lt;/p>
&lt;p>Ces distinctions témoignent de l&amp;rsquo;excellence et de la diversité des recherches menées en informatique au sein de la communauté scientifique.&lt;/p>
&lt;p>Félicitations à &lt;strong>Émilie Yu, Julie Digne, Loann Giovannangeli, Axel Paris et tous les lauréats&lt;/strong> pour ces contributions remarquables.&lt;/p></description></item><item><title>Réunion 'Compression et évaluation de la qualité des nuages de points (GdR IASIS - GdR IG-RV)'</title><link>https://gdr-igrv.fr/event/journee-compression-nuages-points-2024/</link><pubDate>Mon, 02 Dec 2024 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee-compression-nuages-points-2024/</guid><description>&lt;h1 id="présentation">Présentation&lt;/h1>
&lt;p>Avec le développement rapide des technologies 3D et des applications immersives telles que la réalité augmentée, la réalité virtuelle et la modélisation 3D à grande échelle, les nuages de points sont devenus un format incontournable pour représenter des scènes et objets en trois dimensions. Cependant, leur utilisation soulève de nouveaux défis, notamment en ce qui concerne la compression et l&amp;rsquo;évaluation de leur qualité.&lt;/p>
&lt;p>La compression des nuages de points devient primordiale pour optimiser le stockage et la transmission de ces données volumineuses, en particulier dans des contextes où la bande passante est limitée, comme pour les véhicules autonomes, ou la surveillance par drones. L&amp;rsquo;objectif de la compression est de réduire la quantité de données nécessaire tout en maintenant un niveau de qualité suffisant pour les applications, qu&amp;rsquo;il s&amp;rsquo;agisse d&amp;rsquo;analyse automatique par des algorithmes de vision par ordinateur ou de visualisation humaine.&lt;/p>
&lt;p>L&amp;rsquo;évaluation de la qualité des nuages de points, quant à elle, est cruciale pour mesurer l&amp;rsquo;impact des algorithmes de compression sur la fidélité des données 3D. Il s&amp;rsquo;agit de garantir que la compression ou d&amp;rsquo;autres traitements ne dégradent pas les caractéristiques critiques du nuage, comme la géométrie des points ou les textures, qui sont essentielles pour des tâches telles que la reconstruction 3D ou la détection d&amp;rsquo;objets. Des métriques objectives sont nécessaires pour quantifier ces effets, prenant en compte à la fois les besoins des algorithmes de traitement automatique et les perceptions humaines.&lt;/p>
&lt;p>Cette journée scientifique, en collaboration entre le GdR-IASIS et le GdR IGRV, propose de rassembler des experts du domaine pour explorer les dernières avancées en matière de compression et d&amp;rsquo;évaluation de la qualité des nuages de points notamment à l&amp;rsquo;ère de l&amp;rsquo;apprentissage profond. Seront abordées des questions techniques telles que les nouvelles approches de compression (basées sur des réseaux neuronaux ou des approches géométriques), l&amp;rsquo;évaluation perceptuelle, les critères spécifiques aux applications immersives, etc. L&amp;rsquo;objectif est de partager des connaissances, de discuter des défis actuels, et de poser les bases de recherches futures dans ce domaine en pleine expansion.&lt;/p>
&lt;h1 id="appel-à-communications">Appel à communications&lt;/h1>
&lt;p>Le programme inclura des présentations, seniors et juniors, pour lesquelles un appel à contributions est lancé. Si vous souhaitez présenter vos travaux, merci d&amp;rsquo;envoyer vos propositions pour le 30 Octobre 2024 au plus tard (titre, auteurs, affiliation, un résumé de 5-10 lignes) aux organisateurs :&lt;/p>
&lt;ul>
&lt;li>Chaker Larabi, XLIM, &lt;a href="mailto:chaker.larabi@univ-poitiers.fr">chaker.larabi@univ-poitiers.fr&lt;/a>&lt;/li>
&lt;li>Giuseppe Valenzise, L2S, &lt;a href="mailto:giuseppe.valenzise@l2s.centralesupelec.fr">giuseppe.valenzise@l2s.centralesupelec.fr&lt;/a>&lt;/li>
&lt;li>Guillaume Lavoué, LIRIS, &lt;a href="mailto:guillaume.lavoue@enise.ec-lyon.fr">guillaume.lavoue@enise.ec-lyon.fr&lt;/a>&lt;/li>
&lt;li>Aladine Chetouani, L2TI, &lt;a href="mailto:aladine.chetouani@univ-paris13.fr">aladine.chetouani@univ-paris13.fr&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="orateurs-invités">Orateurs invités&lt;/h1>
&lt;ul>
&lt;li>Fernando Pereira (Instituto de Telecomunicações - Lisbonne - Portugal) : &amp;ldquo;Learning-based point cloud coding: unifying man and machine representations&amp;rdquo;&lt;/li>
&lt;li>Nicolas Mellado (IRIT, CNRS) : &amp;ldquo;Point cloud denoising and processing from a Computer Graphics perspective&amp;rdquo;&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul></description></item><item><title>Conférence « Geometry &amp; Computing »</title><link>https://gdr-igrv.fr/event/conference-geometrie2024/</link><pubDate>Mon, 21 Oct 2024 12:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/conference-geometrie2024/</guid><description>&lt;p>Dans le cadre de l&amp;rsquo;année thématique Géométrie soutenue par les GdRs IM et IG-RV, vous êtes conviés à assister à la conférence &amp;ldquo;Géométrie &amp;amp; Informatique&amp;rdquo;, qui aura lieu au CIRM (Marseille, France) du 21 au 25 octobre 2024.&lt;/p>
&lt;p>&lt;a href="https://geocomp2024.sciencesconf.org/" target="_blank" rel="noopener">https://geocomp2024.sciencesconf.org/&lt;/a>&lt;/p>
&lt;p>La conférence propose 25 exposés invités donnés par des experts renommés du domaine. Les participants ont aussi l&amp;rsquo;opportunité de présenter un poster pendant la semaine. La conférence hébergera aussi les réunions annuelles des 3 GT géométries des GdR IFM et IG-RV (GT GéoAlgo, MG et DGMM).&lt;/p>
&lt;p>Nous encourageons la participation des jeunes chercheurs avec des financements possibles. L&amp;rsquo;inscription est ouverte jusqu&amp;rsquo;au 8 juillet.&lt;/p>
&lt;p>Sincèrement
Les organisateurs&lt;/p></description></item><item><title>Journées 'Territoires et Immersions'</title><link>https://gdr-igrv.fr/event/journee-territoires-immersions-2024/</link><pubDate>Thu, 03 Oct 2024 10:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee-territoires-immersions-2024/</guid><description>&lt;p>Voici le programme des journées Territoires et Immersions : une rencontre entre géomatique, informatique graphique et humanités numériques, organisée dans le cadre de l’action de recherche « Au-delà de la 3D » du GdR MAGIS et en collaboration avec le GdR IG-RV et le Consortium 3DHN, .&lt;/p>
&lt;p>&lt;em>Mots clés :&lt;/em> 3D ; Immersion ; Réalités étendues ; Territoires augmentés ; Visualisation ; Interaction ; Collaboration ; Pluridisciplinarité ; Données multidimensionnelles&lt;/p>
&lt;p>&lt;em>Programme :&lt;/em>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Jeudi 3 octobre (urbanLAB - ERASME)&lt;/p>
&lt;ul>
&lt;li>10h : Présentation invitée de Gilles Gesquière (LIRIS, Université Lumière Lyon 2)&lt;/li>
&lt;li>11h : Session Jumeau numérique :
&lt;ul>
&lt;li>Représentations dynamiques, virtuelles et tangibles de la ville (présentation Corentin Gautier, LIRIS)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>11h30 : Visite du laboratoire ERASME&lt;/li>
&lt;li>14h : Session patrimoine :
&lt;ul>
&lt;li>Analyse multidimensionnelle et exploration de données scientifiques du patrimoine en réalité mixte (présentation Melvin Hersent, MAP)&lt;/li>
&lt;li>Projet TIBRE: Tester, Interagir et Bâtir en Réalités Etendues (présentation Renato Saleri, MAP)&lt;/li>
&lt;li>L’interopérabilité HBIM-SIG au service de l&amp;rsquo;étude archéologique du théâtre antique d&amp;rsquo;Orange : L&amp;rsquo;enjeu des données territoriales (Présentation Sandrine Borel‐Dubourg, IRAA)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>16h : Session risques :
&lt;ul>
&lt;li>Développement d’un outil immersif de sensibilisation à la montée des eaux et aux changements climatique sur le littoral par la réalité virtuelle (Présentation Jin-A Choi, AAU)&lt;/li>
&lt;li>Mapping Multi-Hazard Susceptibility Using Machine Learning: MaxEnt Method (présentation Hedieh Soltanpour, CITERES)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Vendredi 4 octobre matin (Campus LyonTech-la Doua)&lt;/p>
&lt;ul>
&lt;li>9h-12h : Atelier iTowns (&lt;a href="http://www.itowns-project.org/" target="_blank" rel="noopener">http://www.itowns-project.org/&lt;/a>)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;em>Inscriptions :&lt;/em>
Inscriptions gratuites et obligatoires, à la journée de présentation et/ou à l&amp;rsquo;atelier iTowns jusqu&amp;rsquo;au 20 septembre à sur ce formulaire &lt;a href="https://forms.gle/FisZ6rv4X45GyEKk6" target="_blank" rel="noopener">https://forms.gle/FisZ6rv4X45GyEKk6&lt;/a>.&lt;/p>
&lt;p>&lt;em>Organisation :&lt;/em>&lt;/p>
&lt;ul>
&lt;li>Préparation journées : Myriam Servières (AAU, Centrale Nantes), Violette Arbergel (MAP, CNRS), Vincent Tourre (AAU, Centrale Nantes), Mehdi Chayani (Archeoscience Bordeaux, CNRS), Xavier Granier (LP2N, IOA)&lt;/li>
&lt;li>Atelier iTowns : Mathieu Brédif (LASTIG, IGN), Gérald Choqueux (LASTIG, IGN), Éric Boix (LIRIS, CNRS)&lt;/li>
&lt;/ul></description></item><item><title>Retour mobilités inter-laboratoires 2023</title><link>https://gdr-igrv.fr/post/24-06-24-retours-mobilites/</link><pubDate>Mon, 29 Jul 2024 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/24-06-24-retours-mobilites/</guid><description>&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table des matières&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>
&lt;ul>
&lt;li>&lt;a href="#thierry-bay--ceramaths-hauts-de-france--irit-toulouse-et-xlim-poitiers--2023">Thierry Bay – CERAMATHS (Hauts-de-France) / IRIT (Toulouse) et XLIM (Poitiers) – 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#deise-santana--cristal-lille--esiee-paris--2023">Deise Santana – CRIStAL (Lille) / ESIEE (Paris) – 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#marc-hartley--lirmm-montpellier--esiee-paris--2023">Marc Hartley – LIRMM (Montpellier) / ESIEE (Paris) – 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#romain-pascual--mics-centralesupélec--liris-lyon--22-24-mai-2023">Romain Pascual – MICS (CentraleSupélec) / LIRIS (Lyon) – 22-24 mai 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#flavien-lécuyer---icube-strasbourg--inria-rennes--2023">Flavien Lécuyer - ICube (Strasbourg) / Inria (Rennes) – 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clément-poull---lib-dijon--xlim-poitiers---décembre-2023">Clément Poull - LIB (Dijon) / XLIM (Poitiers) - Décembre 2023&lt;/a>&lt;/li>
&lt;li>&lt;a href="#julien-mendes-forte---greyc-caen--ligm-champs-sur-marne---20-24-novembre-2023">Julien Mendes Forte - GREYC (Caen) / LIGM (Champs-sur-Marne) - 20-24 novembre 2023&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;p>&lt;em>L&amp;rsquo;action de mobilité entre laboratoires français via le financement de court séjour d&amp;rsquo;un doctorant ou d&amp;rsquo;un enseignant-chercheur/chercheur du GdR a permis la réalisation de 7 mobilités en 2023.&lt;/em>&lt;/p>
&lt;h3 id="thierry-bay--ceramaths-hauts-de-france--irit-toulouse-et-xlim-poitiers--2023">Thierry Bay – CERAMATHS (Hauts-de-France) / IRIT (Toulouse) et XLIM (Poitiers) – 2023&lt;/h3>
&lt;figure id="figure-courbes-algébriques-trigonométriques-à-hodographe-pythagorien-atph-surface-trigonométrique-à-partir-de-laquelle-les-données-ont-été-échantillonnées-et-la-courbe-atph-spatiale-reconstruite">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Courbes Algébriques Trigonométriques à Hodographe Pythagorien (ATPH): surface trigonométrique à partir de laquelle les données ont été échantillonnées et la courbe ATPH spatiale reconstruite." srcset="
/post/24-06-24-retours-mobilites/thierry1_hu2495901ea778ed007616ceb7e6a997b8_103438_7e15659fdc57dab0c67ae6dae12d08ae.webp 400w,
/post/24-06-24-retours-mobilites/thierry1_hu2495901ea778ed007616ceb7e6a997b8_103438_ac6bf73083a92f0d4651c10dc18f5b88.webp 760w,
/post/24-06-24-retours-mobilites/thierry1_hu2495901ea778ed007616ceb7e6a997b8_103438_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/thierry1_hu2495901ea778ed007616ceb7e6a997b8_103438_7e15659fdc57dab0c67ae6dae12d08ae.webp"
width="620"
height="530"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Courbes Algébriques Trigonométriques à Hodographe Pythagorien (ATPH): surface trigonométrique à partir de laquelle les données ont été échantillonnées et la courbe ATPH spatiale reconstruite.
&lt;/figcaption>&lt;/figure>
&lt;p>Thierry Bay, du Département Mathématiques du CERAMATHS à Valenciennes, a réalisé une mobilité inter-laboratoires pour collaborer avec Laura Saini (CERAMATHS), Géraldine Morin (IRIT, Toulouse), et Samuel Peltier (XLIM, Poitiers). L&amp;rsquo;objectif était d&amp;rsquo;utiliser les courbes Algébriques Trigonométriques à Hodographe Pythagorien (ATPH) pour développer des modèles 3D à partir de squelettes.&lt;/p>
&lt;p>Les courbes ATPH permettent de modéliser précisément des formes circulaires et leurs offsets, offrant une représentation paramétrique exacte. Le projet a débuté par la création de formes 2D paramétrées par des courbes ATPH, permettant de calculer explicitement la longueur d&amp;rsquo;arc. Ensuite, l&amp;rsquo;équipe a étendu ces travaux en 3D et aux surfaces, en utilisant des espaces algébriques trigonométriques.&lt;/p>
&lt;p>La mission a permis de renforcer les collaborations existantes, d&amp;rsquo;explorer de nouvelles méthodes de modélisation géométrique, et de poser les bases pour des généralisations futures des modèles splines, polynomiaux et ATPH.&lt;/p>
&lt;h3 id="deise-santana--cristal-lille--esiee-paris--2023">Deise Santana – CRIStAL (Lille) / ESIEE (Paris) – 2023&lt;/h3>
&lt;figure id="figure-illustration-dun-image-de-son-gradient-et-de-diverses-cartes-de-saillance-et-de-partitions-basées-sur-les-bassins-versants-hiérarchiques-et-les-attributs-de-circularité">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Illustration d&amp;#39;un image, de son gradient, et de diverses cartes de saillance et de partitions basées sur les bassins versants hiérarchiques et les attributs de circularité" srcset="
/post/24-06-24-retours-mobilites/deise1_hu78911f42bd5b19a46799146f0717a3ae_963130_9990ce655ca72d61bb29865e275284d3.webp 400w,
/post/24-06-24-retours-mobilites/deise1_hu78911f42bd5b19a46799146f0717a3ae_963130_e71e20de5cbb335dfcf0252a53fdb9f7.webp 760w,
/post/24-06-24-retours-mobilites/deise1_hu78911f42bd5b19a46799146f0717a3ae_963130_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/deise1_hu78911f42bd5b19a46799146f0717a3ae_963130_9990ce655ca72d61bb29865e275284d3.webp"
width="760"
height="521"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Illustration d&amp;rsquo;un image, de son gradient, et de diverses cartes de saillance et de partitions basées sur les bassins versants hiérarchiques et les attributs de circularité
&lt;/figcaption>&lt;/figure>
&lt;p>Deise Santana, chercheuse en informatique à l’université de Lille et membre du laboratoire CRIStAL (UMR 9189), a effectué une mission de deux semaines à ESIEE Paris pour collaborer sur un projet de recherche portant sur le calcul des lignes de partage des eaux hiérarchiques dans le cadre de graphes pondérés.&lt;/p>
&lt;h3 id="marc-hartley--lirmm-montpellier--esiee-paris--2023">Marc Hartley – LIRMM (Montpellier) / ESIEE (Paris) – 2023&lt;/h3>
&lt;figure id="figure-environnement-sous-marins-simulés-virtual-worlds-for-testing-robot-navigation-a-study-on-the-difficulty-level-thierry-sotiropoulos-jérémie-guiochet-félix-ingrand-hélène-waeselynck-in-proceedings-of-the-european-dependable-computing-conference-edcc-2016">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Environnement sous-marins simulés *Virtual Worlds for Testing Robot Navigation: a Study on the Difficulty Level. Thierry Sotiropoulos, Jérémie Guiochet, Félix Ingrand, Hélène Waeselynck. In Proceedings of the European Dependable Computing Conference (EDCC 2016).*" srcset="
/post/24-06-24-retours-mobilites/marc1_hu81caa448037adfc8e271a9be0543be2e_101753_916adbc22c9b7020d9145c6c78610981.webp 400w,
/post/24-06-24-retours-mobilites/marc1_hu81caa448037adfc8e271a9be0543be2e_101753_07d29c46948e847ffade6b6faaeba789.webp 760w,
/post/24-06-24-retours-mobilites/marc1_hu81caa448037adfc8e271a9be0543be2e_101753_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/marc1_hu81caa448037adfc8e271a9be0543be2e_101753_916adbc22c9b7020d9145c6c78610981.webp"
width="760"
height="262"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Environnement sous-marins simulés &lt;br>&lt;em>Virtual Worlds for Testing Robot Navigation: a Study on the Difficulty Level. Thierry Sotiropoulos, Jérémie Guiochet, Félix Ingrand, Hélène Waeselynck. In Proceedings of the European Dependable Computing Conference (EDCC 2016).&lt;/em>
&lt;/figcaption>&lt;/figure>
&lt;p>Marc Hartley, doctorant au LIRMM à Montpellier, a réalisé une mission de recherche à ESIEE Paris, portant sur le développement d&amp;rsquo;un simulateur d&amp;rsquo;environnements sous-marins. Ce projet international et interdisciplinaire vise à évaluer et améliorer les protocoles d&amp;rsquo;observation de la biodiversité et à valider des systèmes robotiques sous-marins.&lt;/p>
&lt;p>Durant son séjour, Marc Hartley a collaboré avec les chercheurs d&amp;rsquo;ESIEE Paris pour avancer sur la génération procédurale d&amp;rsquo;environnements sous-marins. Son travail a porté sur la création de fonds marins, adaptés aux scénarios de validation des missions robotiques. Il a particulièrement exploré la modélisation des bordures d&amp;rsquo;îles coralliennes et des réseaux karstiques.&lt;/p>
&lt;p>La mission a permis de développer des méthodes procédurales contrôlables pour générer des environnements réalistes, intégrant des obstacles et des caractéristiques topologiques spécifiques.&lt;/p>
&lt;h3 id="romain-pascual--mics-centralesupélec--liris-lyon--22-24-mai-2023">Romain Pascual – MICS (CentraleSupélec) / LIRIS (Lyon) – 22-24 mai 2023&lt;/h3>
&lt;figure id="figure-g-carte-associée-à-un-objet-géométrique-romain-pascual-pascale-le-gall-hakim-belhaouari-agnès-arnould-une-approche-pour-inférer-les-expressions-de-calcul-géométrique-en-modélisation-à-base-topologique-22ème-journées-des-approches-formelles-dans-lassistance-au-développement-de-logiciels-afadl23-jun-2023-rennes-france">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="G-carte associée à un objet géométrique *Romain Pascual, Pascale Le Gall, Hakim Belhaouari, Agnès Arnould. Une approche pour inférer les expressions de calcul géométrique en modélisation à base topologique. 22ème Journées des Approches Formelles dans l’Assistance au Développement de Logiciels, AFADL’23., Jun 2023, Rennes, France.*" srcset="
/post/24-06-24-retours-mobilites/romain1_hudec8a329174fc37849e265970269706a_52664_94624722607d55fd92a89dc65a4344d3.webp 400w,
/post/24-06-24-retours-mobilites/romain1_hudec8a329174fc37849e265970269706a_52664_986e88e6ab2851638931e8d3f2020bd0.webp 760w,
/post/24-06-24-retours-mobilites/romain1_hudec8a329174fc37849e265970269706a_52664_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/romain1_hudec8a329174fc37849e265970269706a_52664_94624722607d55fd92a89dc65a4344d3.webp"
width="760"
height="159"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
G-carte associée à un objet géométrique &lt;br>&lt;em>Romain Pascual, Pascale Le Gall, Hakim Belhaouari, Agnès Arnould. Une approche pour inférer les expressions de calcul géométrique en modélisation à base topologique. 22ème Journées des Approches Formelles dans l’Assistance au Développement de Logiciels, AFADL’23., Jun 2023, Rennes, France.&lt;/em>
&lt;/figcaption>&lt;/figure>
&lt;p>Romain Pascual, ATER au laboratoire MICS de CentraleSupélec, a effectué une mission de trois jours au LIRIS de Lyon afin d&amp;rsquo;initier une collaboration autour de l&amp;rsquo;utilisation de signatures topologiques pour des opérations d&amp;rsquo;édition de maillages volumiques.&lt;/p>
&lt;p>Durant son séjour, Romain Pascual a travaillé étroitement avec Guillaume Damiand et Vincent Nivoliers du LIRIS. Leur objectif commun était d&amp;rsquo;explorer l&amp;rsquo;application des techniques de réécriture de graphes pour la modélisation géométrique, en s&amp;rsquo;inspirant des méthodes de cherche-remplace sur les cartes combinatoires développées par leurs homologues lyonnais.&lt;/p>
&lt;p>Cette collaboration a permis de poser les bases d&amp;rsquo;un projet visant à étendre la représentation des signatures de la méthode cherche-remplace en intégrant des idées issues des techniques de réécriture. L&amp;rsquo;approche proposée cherche à appliquer cette méthode à plusieurs cellules topologiques, ouvrant ainsi de nouvelles perspectives pour la modélisation géométrique basée sur des graphes.&lt;/p>
&lt;h3 id="flavien-lécuyer---icube-strasbourg--inria-rennes--2023">Flavien Lécuyer - ICube (Strasbourg) / Inria (Rennes) – 2023&lt;/h3>
&lt;figure id="figure-environnement-virtuel-pour-une-thérapie-en-réalité-virtuelle-thomas-lehoux-christelle-nithart-porche-antonio-capobianco-miguel-gervilla-flavien-lecuyer-et-al-towards-virtual-reality-exposure-therapy-for-cocaine-use-disorder-a-feasibility-study-of-inducing-cocaine-craving-through-virtual-reality-addictive-behaviors-reports-2024-19-pp100549">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Environnement virtuel pour une thérapie en Réalité Virtuelle *Thomas Lehoux, Christelle Nithart Porche, Antonio Capobianco, Miguel Gervilla, Flavien Lecuyer, et al.. Towards virtual reality exposure therapy for cocaine use disorder: A feasibility study of inducing cocaine craving through virtual reality. Addictive Behaviors Reports, 2024, 19, pp.100549.*" srcset="
/post/24-06-24-retours-mobilites/flavien1_hu6a0621bc777fb7a9da9ff6d21ac20822_66069_a45d3433a171ede714a77230e2f0d486.webp 400w,
/post/24-06-24-retours-mobilites/flavien1_hu6a0621bc777fb7a9da9ff6d21ac20822_66069_6659d451b3092652cb9e7d0b65791aef.webp 760w,
/post/24-06-24-retours-mobilites/flavien1_hu6a0621bc777fb7a9da9ff6d21ac20822_66069_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/flavien1_hu6a0621bc777fb7a9da9ff6d21ac20822_66069_a45d3433a171ede714a77230e2f0d486.webp"
width="760"
height="323"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Environnement virtuel pour une thérapie en Réalité Virtuelle &lt;br>&lt;em>Thomas Lehoux, Christelle Nithart Porche, Antonio Capobianco, Miguel Gervilla, Flavien Lecuyer, et al.. Towards virtual reality exposure therapy for cocaine use disorder: A feasibility study of inducing cocaine craving through virtual reality. Addictive Behaviors Reports, 2024, 19, pp.100549.&lt;/em>
&lt;/figcaption>&lt;/figure>
&lt;p>Dans le cadre de leurs travaux sur l&amp;rsquo;influence des émotions sur le sentiment d&amp;rsquo;incarnation en réalité virtuelle, les chercheurs de Strasbourg ont initié une collaboration avec l&amp;rsquo;équipe Hybrid de l&amp;rsquo;INRIA Rennes. Cette mission a impliqué Flavien Lécuyer, jeune maître de conférences, et Benjamin Freeling, doctorant, dans le but de définir les contours d&amp;rsquo;une étude conjointe.&lt;/p>
&lt;p>Pendant leur visite à Rennes, les chercheurs ont rencontré Ferran Argelaguet et discuté des recherches complémentaires menées au laboratoire IRISA/Inria Rennes. Ensemble, ils ont exploré les facteurs permettant l&amp;rsquo;incarnation des avatars virtuels et ont envisagé des solutions innovantes pour améliorer les simulations de réalité virtuelle. Cette collaboration vise à comparer le sentiment d&amp;rsquo;incarnation dans des contextes applicatifs similaires, en utilisant des casques de réalité virtuelle standard et un environnement de type CAVE, tel que celui de la plateforme Immersia.&lt;/p>
&lt;p>Les discussions ont mis en lumière le potentiel de l&amp;rsquo;analyse en temps réel de l&amp;rsquo;implication émotionnelle des utilisateurs, offrant ainsi de nouvelles perspectives pour évaluer l&amp;rsquo;incarnation virtuelle. Cette approche pourrait surmonter les limites des questionnaires post-expérience actuellement utilisés pour mesurer l&amp;rsquo;incarnation virtuelle.&lt;/p>
&lt;h3 id="clément-poull---lib-dijon--xlim-poitiers---décembre-2023">Clément Poull - LIB (Dijon) / XLIM (Poitiers) - Décembre 2023&lt;/h3>
&lt;figure id="figure-rendu-de-sphères-en-verre-gravé-globe-en-métal-milieu-et-en-verre-droite-scintillants-walter-b-marschner-sr-li-h-torrance-ke-microfacet-models-for-refraction-through-rough-surfaces-egsr-2007-pp-195206-and-chermain-x-sauvage-b-dischler-j-m-dachsbacher-c-importance-sampling-of-glittering-bsdfs-based-on-finite-mixture-distributions-egsr-2021">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Rendu de sphères en verre gravé (globe), en métal (milieu) et en verre (droite) scintillants. *Walter B., Marschner S.R., Li H., Torrance K.E.: Microfacet models for refraction through rough surfaces (EGSR 2007, pp. 195–206)* and *Chermain X., Sauvage B., Dischler J.-M., Dachsbacher C.: Importance sampling of glittering BSDFs based on finite mixture distributions. (EGSR 2021)*" srcset="
/post/24-06-24-retours-mobilites/clement1_huf9a5e1308a8a8fed9144796e965c919d_558143_ecb363e3142dccb22a28a87b11a7e340.webp 400w,
/post/24-06-24-retours-mobilites/clement1_huf9a5e1308a8a8fed9144796e965c919d_558143_b11df375001e27658177c2bc6fa599ed.webp 760w,
/post/24-06-24-retours-mobilites/clement1_huf9a5e1308a8a8fed9144796e965c919d_558143_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/clement1_huf9a5e1308a8a8fed9144796e965c919d_558143_ecb363e3142dccb22a28a87b11a7e340.webp"
width="760"
height="259"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Rendu de sphères en verre gravé (globe), en métal (milieu) et en verre (droite) scintillants. &lt;br>&lt;em>Walter B., Marschner S.R., Li H., Torrance K.E.: Microfacet models for refraction through rough surfaces (EGSR 2007, pp. 195–206)&lt;/em> and &lt;em>Chermain X., Sauvage B., Dischler J.-M., Dachsbacher C.: Importance sampling of glittering BSDFs based on finite mixture distributions. (EGSR 2021)&lt;/em>
&lt;/figcaption>&lt;/figure>
&lt;p>Clément Poull, doctorant au sein de l&amp;rsquo;équipe Modélisation Géométrique (MG) du Laboratoire d&amp;rsquo;Informatique de Bourgogne (LIB), a effectué une mobilité d&amp;rsquo;une semaine en décembre 2023 à l&amp;rsquo;équipe Informatique Graphique (IG) du laboratoire XLIM à Poitiers. Cette mobilité s&amp;rsquo;inscrit dans le cadre du projet ANR JCJC FRACLETTES, dont l&amp;rsquo;objectif est la représentation, l&amp;rsquo;analyse et la caractérisation de surfaces rugueuses pour la simulation numérique.&lt;/p>
&lt;p>Les objectifs de cette mobilité étaient de formaliser les discussions entre les équipes MG et IG sur l&amp;rsquo;utilisation de modèles fractals pour la simulation d&amp;rsquo;éclairage et de préparer un travail de fond sur le contrôle de la distribution des normales aux microfacettes pour la plausibilité physique des calculs de simulation d’éclairage.&lt;/p>
&lt;p>Clément Poull travaille sur la définition d&amp;rsquo;un modèle mathématique fractal déterministe pour le contrôle géométrique de la rugosité. L&amp;rsquo;équipe IG du XLIM s&amp;rsquo;intéresse à la représentation, la synthèse et l&amp;rsquo;animation de structures géométriques complexes, ainsi qu&amp;rsquo;à la gestion de leur apparence en simulation d’éclairage. Les modèles fractals développés par Clément Poull pourraient être utilisés pour contrôler la distribution des normales aux microfacettes, améliorant ainsi le réalisme des simulations d&amp;rsquo;éclairage.&lt;/p>
&lt;h3 id="julien-mendes-forte---greyc-caen--ligm-champs-sur-marne---20-24-novembre-2023">Julien Mendes Forte - GREYC (Caen) / LIGM (Champs-sur-Marne) - 20-24 novembre 2023&lt;/h3>
&lt;figure id="figure-analyse-topologique-dune-image-f-et-ses-ensembles-de-seuils-où-les-arbres-des-formes-et-les-arbres-topologiques-des-formes-représentent-les-relations-dinclusion-et-dimbrication-des-composantes-connexes-des-seuils-de-f">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Analyse topologique d&amp;#39;une image F et ses ensembles de seuils, où les arbres des formes et les arbres topologiques des formes représentent les relations d&amp;#39;inclusion et d&amp;#39;imbrication des composantes connexes des seuils de F" srcset="
/post/24-06-24-retours-mobilites/julien1_hua2bb820b2a25709951d08af30cb1c715_61928_209c210ea143c9c671a354abf859b106.webp 400w,
/post/24-06-24-retours-mobilites/julien1_hua2bb820b2a25709951d08af30cb1c715_61928_e2bf4ab7e5d0b11b90410022b20d33e3.webp 760w,
/post/24-06-24-retours-mobilites/julien1_hua2bb820b2a25709951d08af30cb1c715_61928_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/24-06-24-retours-mobilites/julien1_hua2bb820b2a25709951d08af30cb1c715_61928_209c210ea143c9c671a354abf859b106.webp"
width="760"
height="393"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Analyse topologique d&amp;rsquo;une image F et ses ensembles de seuils, où les arbres des formes et les arbres topologiques des formes représentent les relations d&amp;rsquo;inclusion et d&amp;rsquo;imbrication des composantes connexes des seuils de F
&lt;/figcaption>&lt;/figure>
&lt;p>Julien Mendes Forte, doctorant au sein de l&amp;rsquo;équipe Image du laboratoire GREYC à Caen, a effectué une mobilité au Laboratoire d’Informatique Gaspard Monge (LIGM) à Champs-sur-Marne du 20 au 24 novembre 2023. Il a été accueilli par l&amp;rsquo;équipe A3SI pour travailler sur le sujet de l&amp;rsquo;Arbre Topologique des Formes (ATdF).&lt;/p>
&lt;p>Les objectifs de cette mobilité étaient de discuter avec Benjamin Perret, développeur de la bibliothèque Higra, de l&amp;rsquo;intégration de l&amp;rsquo;ATdF dans la bibliothèque et d&amp;rsquo;explorer l&amp;rsquo;utilisation de l&amp;rsquo;ATdF comme moyen de guider l&amp;rsquo;apprentissage des réseaux de neurones grâce à la définition d’une fonction de perte basée sur la structure.&lt;/p>
&lt;p>Julien Mendes Forte travaille sur l&amp;rsquo;analyse structurelle d&amp;rsquo;images pour l&amp;rsquo;extraction et la mesure de l&amp;rsquo;information topologique. Il a notamment développé un nouveau descripteur topologique d&amp;rsquo;images basé sur l&amp;rsquo;ATdF. L&amp;rsquo;intégration de l&amp;rsquo;ATdF dans la bibliothèque Higra permettrait de diffuser cet outil et de faciliter son utilisation. L&amp;rsquo;utilisation de l&amp;rsquo;ATdF pour guider l&amp;rsquo;apprentissage des réseaux de neurones est une piste prometteuse pour améliorer la précision des segmentations d&amp;rsquo;images.&lt;/p></description></item><item><title>26èmes journées du Groupe de Travail Animation et Simulation</title><link>https://gdr-igrv.fr/event/journee_gtas2024/</link><pubDate>Thu, 11 Jul 2024 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtas2024/</guid><description>&lt;p>Les prochaines journées du Groupe de Travail Animation et Simulation du GDR IGRV auront lieu les 11 et 12 juillet 2024, à Limoges (Laboratoire XLIM).&lt;/p>
&lt;p>L’objet des Journées du GT AS est triple. Il s’agit :&lt;/p>
&lt;ul>
&lt;li>de partager les avancées de la recherche en animation et simulation,&lt;/li>
&lt;li>de dresser le paysage du domaine en France, et&lt;/li>
&lt;li>d’en préciser les perspectives et les thématiques émergentes.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Le thème focus cette année sera: Animation et simulation de phénomènes naturels.&lt;/strong>&lt;/p>
&lt;p>Les inscriptions sont ouvertes. A faire en remplissant &lt;a href="https://forms.gle/XJPmmHccMw79JiwS7" target="_blank" rel="noopener">ce formulaire&lt;/a>.&lt;/p>
&lt;h2 id="infos-pratiques">Infos pratiques&lt;/h2>
&lt;h3 id="lieu">Lieu&lt;/h3>
&lt;blockquote>
&lt;p>Salle de conférences, Laboratoire XLIM&lt;/p>
&lt;p>123 Av. Albert Thomas, 87000 Limoges&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a href="https://maps.app.goo.gl/THQKxM9HY9E63crq6" target="_blank" rel="noopener">Emplacement sur Google Maps&lt;/a>&lt;/p>
&lt;p>Accès depuis le centre-ville (bus n°8 dir &amp;ldquo;Mal Joffre&amp;rdquo; - arrêt &amp;ldquo;Campus La Borie&amp;rdquo;)&lt;/p>
&lt;p>Accès en bus par la ligne 8 (dir “Mal Joffre”, arrêt “Campus La Borie”) :&lt;/p>
&lt;ul>
&lt;li>Site TCL : &lt;a href="https://www.stcl.fr" target="_blank" rel="noopener">https://www.stcl.fr&lt;/a>&lt;/li>
&lt;li>App MyBus (achat de billet en ligne): &lt;a href="https://www.mybus.io/" target="_blank" rel="noopener">https://www.mybus.io/&lt;/a>&lt;/li>
&lt;li>Depuis la gare des Bénédictins, prendre d’abord la ligne 6 (dir “Mal Juin”) puis rejoindre la ligne 8 à partir des arrêts “Pl. W. Churchill” ou “Mauvendière”&lt;/li>
&lt;/ul>
&lt;p>Depuis l’arrêt de bus ou le parking principal du campus de la Faculté des Sciences :&lt;br>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Acces" srcset="
/event/journee_gtas2024/acces_hu3d80a8d2602b7b986ff22f378a99dc74_200939_5a6344efdd128c10327711ce12d82d2f.webp 400w,
/event/journee_gtas2024/acces_hu3d80a8d2602b7b986ff22f378a99dc74_200939_b36c7f39983c2ff6361c6316cfc69537.webp 760w,
/event/journee_gtas2024/acces_hu3d80a8d2602b7b986ff22f378a99dc74_200939_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/event/journee_gtas2024/acces_hu3d80a8d2602b7b986ff22f378a99dc74_200939_5a6344efdd128c10327711ce12d82d2f.webp"
width="760"
height="376"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="sélection-hôtels">Sélection Hôtels&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://maps.app.goo.gl/1ZNepm5CYuUpamkr6" target="_blank" rel="noopener">ENZO HOTELS LIMOGES CENTRE JOURDAN By KYRIAD DIRECT&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://maps.app.goo.gl/R8emehZgkj4kRDQm9" target="_blank" rel="noopener">ibis Limoges Centre&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://maps.app.goo.gl/a7qLdDysTBZT8XKp8" target="_blank" rel="noopener">MERCURE LIMOGES CENTRE&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://maps.app.goo.gl/5baFd9r3fmUVeBnR7" target="_blank" rel="noopener">Hôtel Campanile Limoges Centre Gare&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://maps.app.goo.gl/EbrEDwoThP42U7t79" target="_blank" rel="noopener">Contact Hôtel Des Deux Moulins&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="programme">Programme&lt;/h1>
&lt;p>&lt;strong>Jeudi 11 juillet&lt;/strong>&lt;/p>
&lt;p>12h30-13h55 : buffet végétarien (salle XR201)&lt;/p>
&lt;p>13h55-14h00 : ouverture du GTAS&lt;/p>
&lt;p>14h-15h30 : session 1&lt;/p>
&lt;ul>
&lt;li>14h-14h20 : &lt;strong>SMEAR: Stylized Motion Exaggeration with ARt-direction&lt;/strong>, &lt;em>Jean Basset, Pierre Bénard, Pascal Barla&lt;/em>, Inria Bordeaux Sud-Ouest, Équipe Manao.&lt;/li>
&lt;li>14h25-14h45 : &lt;strong>Fixed-radius Nearest Neighbour Search using Delaunay Triangulations&lt;/strong>, &lt;em>Heinich Porro.&lt;/em>&lt;/li>
&lt;li>14h45-15h30 : démarrage de l’atelier &lt;strong>Systèmes de particules avec Shadertoy&lt;/strong>, &lt;em>C. Plateau&amp;ndash;Holleville&lt;/em>, XLIM Limoges - Venez avec votre ordinateur portable !!!&lt;/li>
&lt;/ul>
&lt;p>15h30-15h45 : pause café&lt;/p>
&lt;ul>
&lt;li>15h45-16h30 : suite de l’atelier&lt;/li>
&lt;li>16h30-17h : enseignement de l’AS et avec l’AS
&lt;ul>
&lt;li>Intervention à distance “&lt;strong>Apprentissage Enactif : Réalité Virtuelle et Systèmes Haptiques au service du « learning by doing » en Nanosciences et en STIC à l’université Grenoble Alpes&lt;/strong>”, Nicolas Castagné, MCF en Informatique, Florence Marchi, MCF en Physique&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>18h-19h : moment artistique&lt;/p>
&lt;ul>
&lt;li>Guillaume Demaison, graphiste et motion designer, &lt;a href="https://kailis-design.net/" target="_blank" rel="noopener">Studio Kailis&lt;/a>&lt;/li>
&lt;li>Lieu : &lt;a href="https://maps.app.goo.gl/WBWS22cUhWqgW5hF9" target="_blank" rel="noopener">Orge et Houblon&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>19h30 : rdv &lt;a href="https://maps.app.goo.gl/rGFTgf9zVAyjtKFYA" target="_blank" rel="noopener">Chez Alphonse&lt;/a> (à confirmer)&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Vendredi 12 juillet&lt;/strong>&lt;/p>
&lt;p>9h : accueil&lt;/p>
&lt;p>9h-10h30 - session 2 “Animation et simulation de phénomènes naturels” ****+ discussions&lt;/p>
&lt;ul>
&lt;li>9h-9h20 : &lt;strong>Windblown Sand Around Obstacles - Simulation and Validation of Deposition Patterns&lt;/strong>, &lt;em>Nicolas Rosset, Régis Duvigneau, Adrien Bousseau, Guillaume Cordonnier,&lt;/em> Inria Université Côte d’Azur, Équipes GraphDeco &amp;amp; Acumes. (Lien HAL: &lt;a href="https://hal.science/INRIA2/hal-04566241v1" target="_blank" rel="noopener">https://hal.science/INRIA2/hal-04566241v1&lt;/a>)&lt;/li>
&lt;li>9h25-9h45 : &lt;strong>Simulation de pluie&lt;/strong>, &lt;em>Gabriel Cadilhac&lt;/em>, XLIM Limoges.&lt;/li>
&lt;li>9h50-10h10 : &lt;strong>Un framework de simulation d&amp;rsquo;océan temps réel,&lt;/strong> &lt;em>David Algis, Emmanuelle Darles, Bérenger Bramas, Lilian Aveneau,&lt;/em> Université de Poitiers, Laboratoire XLIM &amp;amp; Studio Nyx &amp;amp; Inria de Nancy.&lt;/li>
&lt;/ul>
&lt;p>10h10-10h30 : discussions&lt;/p>
&lt;p>10h30-10h45 : pause café&lt;/p>
&lt;p>10h45-11h35 : atelier &lt;strong>Simulation de fluide avec &lt;a href="https://github.com/ProjectPhysX/FluidX3D" target="_blank" rel="noopener">FluidX3D&lt;/a>,&lt;/strong> &lt;em>Louis Forestier&lt;/em>, XLIM Poitiers (salle de TP I213 - à confirmer)&lt;/p>
&lt;p>11h35-12h30 : prospectives, session en ligne sur :&lt;/p>
&lt;p>&lt;a href="https://grenoble-inp.zoom.us/j/95742816391" target="_blank" rel="noopener">https://grenoble-inp.zoom.us/j/95742816391&lt;/a>&lt;/p>
&lt;p>Code secret: gtas&lt;/p>
&lt;p>12h30-13h55 : buffet végétarien (salle XR202)&lt;/p>
&lt;p>&lt;strong>Sponsors&lt;/strong>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="France2030" srcset="
/event/journee_gtas2024/france2030_hu11475e296047db8e2b9c564d3059c20c_12649_628d3b1bcb4a7ced1ea0401b6c643fd6.webp 400w,
/event/journee_gtas2024/france2030_hu11475e296047db8e2b9c564d3059c20c_12649_8f889f682b3950f58afe7babdd8c2d4c.webp 760w,
/event/journee_gtas2024/france2030_hu11475e296047db8e2b9c564d3059c20c_12649_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/event/journee_gtas2024/france2030_hu11475e296047db8e2b9c564d3059c20c_12649_628d3b1bcb4a7ced1ea0401b6c643fd6.webp"
width="151"
height="151"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Ceramics" srcset="
/event/journee_gtas2024/ceramicsICT_hud57044b1d90a81390c5b3bdc3b0ea2e8_16723_9df349babb17569b2d504e951365fd89.webp 400w,
/event/journee_gtas2024/ceramicsICT_hud57044b1d90a81390c5b3bdc3b0ea2e8_16723_4ecca2e18e16e8bde7be1ea5b9d8630e.webp 760w,
/event/journee_gtas2024/ceramicsICT_hud57044b1d90a81390c5b3bdc3b0ea2e8_16723_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/event/journee_gtas2024/ceramicsICT_hud57044b1d90a81390c5b3bdc3b0ea2e8_16723_9df349babb17569b2d504e951365fd89.webp"
width="500"
height="250"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Journée GT Rendu 2024</title><link>https://gdr-igrv.fr/event/journee_gtrendu2024/</link><pubDate>Wed, 26 Jun 2024 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrendu2024/</guid><description>&lt;p>Bonjour à toutes et à tous,&lt;/p>
&lt;p>Nous n&amp;rsquo;avons pas recu beaucoup de propositions de contribution (ni d&amp;rsquo;inscriptions par ailleurs). Dans le passé ces journées ont été très riches et une très bonne opportunité de discuter et rencontrer d&amp;rsquo;autres chercheurs en rendu. Vu le regain d&amp;rsquo;intérêt pour le rendu d&amp;rsquo;une manière générale, j&amp;rsquo;incite fortement tout le monde à venir et participer!&lt;/p>
&lt;p>La prochaine journée du Groupe de Travail Rendu du GDR IGRV aura lieu dans les locaux d&amp;rsquo;Adobe le 26 juin 2024.&lt;/p>
&lt;p>Venez faire vivre ces journées en contribuant ou simplement pour rencontrer et discuter avec la communauté graphique française !
Les thèmes abordés peuvent être variés pour aggrémenter les discussions et avoir un aperçu des activités françaises dans le domaine du rendu :&lt;/p>
&lt;ul>
&lt;li>travaux actuels, aboutis ou non, publiés ou non&lt;/li>
&lt;li>tours d&amp;rsquo;horizons sur des thèmes/approches/outils émergents&lt;/li>
&lt;li>travaux d&amp;rsquo;une équipe de recherche sur les dernières années&lt;/li>
&lt;li>etc.&lt;/li>
&lt;/ul>
&lt;p>** INSCRIPTIONS **
Pour assister aux présentations, merci d&amp;rsquo;ajouter votre prénom/nom/organisme dans ce framapad :
&lt;a href="https://mypads2.framapad.org/p/gt-rendu-2024-lvk849hn" target="_blank" rel="noopener">https://mypads2.framapad.org/p/gt-rendu-2024-lvk849hn&lt;/a>&lt;/p>
&lt;p>La liste des participants sera transmise à Adobe 3 jours avant le début du GT et une pièce d&amp;rsquo;identité vous sera demandée à l&amp;rsquo;entrée.&lt;/p>
&lt;p>** CONTRIBUTIONS **
Pour présenter, envoyez un email à George et moi même contenant [GT Rendu] dans le sujet, avec les informations suivantes :&lt;/p>
&lt;ul>
&lt;li>Prénom, nom, organisme de l&amp;rsquo;orateur&lt;/li>
&lt;li>Titre de la présentation&lt;/li>
&lt;li>Eventuellement un lien vers une page web s&amp;rsquo;il s&amp;rsquo;agit d&amp;rsquo;un travail déjà publié/diffusé.&lt;/li>
&lt;/ul>
&lt;p>** ADRESSE **
Adobe, 94-96 Rue Lauriston, 75016 Paris
Salle « Moulin Rouge », au Rez-de-Chaussée, accessible depuis l’atrium&lt;/p>
&lt;p>Retrouvez les présentations des années précédentes sur le blog du GT : &lt;a href="http://gtrendu.blogspot.com/" target="_blank" rel="noopener">http://gtrendu.blogspot.com/&lt;/a>&lt;/p>
&lt;p>A très bientôt et en espérant vous voir nombreux pour cette occasion,
George Drettakis &amp;amp; Romain Vergne&lt;/p></description></item><item><title>Journées Scientifiques GT-RV 2024 et EQUIPEX CONTINUUM</title><link>https://gdr-igrv.fr/event/journees_gtrv2024/</link><pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journees_gtrv2024/</guid><description>&lt;p>Les pages suivantes regroupent les informations relatives aux journées scientifiques du GT-RV qui auront lieu du &lt;strong>24 et 25 Juin 2024&lt;/strong> au Centre Inria de l&amp;rsquo;Université de Rennes/IRISA et qui seront communes cette année avec des journées scientifiques de l&amp;rsquo;EQUIPEX CONTINUUM (&lt;a href="https://equipexcontinuum.github.io" target="_blank" rel="noopener">https://equipexcontinuum.github.io&lt;/a>).&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/event/journees_gtrv2024/logo-500-white_hu35d071d27e1ad6d5a4833ab3adadc5ea_37028_723275fb0821ca0719a23358b1f339e1.webp 400w,
/event/journees_gtrv2024/logo-500-white_hu35d071d27e1ad6d5a4833ab3adadc5ea_37028_544b26610624c934043cd28acd72f92c.webp 760w,
/event/journees_gtrv2024/logo-500-white_hu35d071d27e1ad6d5a4833ab3adadc5ea_37028_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/event/journees_gtrv2024/logo-500-white_hu35d071d27e1ad6d5a4833ab3adadc5ea_37028_723275fb0821ca0719a23358b1f339e1.webp"
width="500"
height="169"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Le matin du 25 Juin, la journée est partagée avec les Journées CONTINUUM 2024.&lt;/p>
&lt;p>La journée est gratuite, mais sur inscription avant le 17 Juin 2024 -&amp;gt; &lt;a href="https://evento.renater.fr/survey/journee-scientifique-continuum-et-gt-rv-2024-du-24-au-25-juin-rennes-aa7r1ytu" target="_blank" rel="noopener">(lien d&amp;rsquo;inscription)&lt;/a>.
Si vous assistez aussi aux Journées CONTINUUM, utilisez ce lien -&amp;gt; &lt;a href="https://evento.renater.fr/survey/journees-continuum-2024-du-24-au-26-juin-rennes-y7hlpzv6" target="_blank" rel="noopener">(lien d&amp;rsquo;inscription)&lt;/a>.&lt;/p>
&lt;p>Pour information, les déjeuneurs sont pris en charge par les organisateurs, les dîners ne les sont pas.&lt;/p>
&lt;h1 id="informations-générales">Informations générales&lt;/h1>
&lt;p>Les activités proposées durant ces journées seront les suivantes :&lt;/p>
&lt;ul>
&lt;li>Présentations scientifiques animées par le GT RV et CONTINUUM.&lt;/li>
&lt;li>Séminaire de prospective scientifique sur les thématiques du GT-RV&lt;/li>
&lt;li>Présentations d&amp;rsquo;activités Rennaises (équipes MimeTIC, Hybrid, Virtus, Rainbow) et de CONTINUUM.&lt;/li>
&lt;li>Présentation de Anne-Laure GUINET, qui a reçu un accessit au prix de thèse du GdR IG-RV en 2023 pour sa thèse intitulée &amp;ldquo;Retours sensoriels multimodaux en réalité augmentée pour la rééducation de la marche des enfants atteints de paralysie cérébrale&amp;rdquo;&lt;/li>
&lt;li>Visites de la plateforme Immersia&lt;/li>
&lt;/ul>
&lt;h1 id="programme-détaillé">Programme détaillé&lt;/h1>
&lt;h2 id="lundi-24-juin">Lundi 24 Juin&lt;/h2>
&lt;ul>
&lt;li>12h00-13h30 - Accueil Journée Scientifique CONTINUUM/GT RV&lt;/li>
&lt;li>13h30-14h00 - Introduction Journée Scientifique&lt;/li>
&lt;li>14h00-15h30 - Présentations Scientifiques&lt;/li>
&lt;li>15h30-16h00 - Pause café&lt;/li>
&lt;li>16h00-17h00 - Présentations Scientifiques&lt;/li>
&lt;li>17h00-18h00 - Séminaire sur les Prospectives Scientifiques de nos thématiques de recherche (Réalité Virtuelle, Réalité Augmentée, Réalité Mixte)&lt;/li>
&lt;/ul>
&lt;h4 id="soirée">Soirée&lt;/h4>
&lt;ul>
&lt;li>Repas dans un restaurant (à vos frais malheureusement)&lt;/li>
&lt;/ul>
&lt;h2 id="mardi-25-juin">Mardi 25 Juin&lt;/h2>
&lt;ul>
&lt;li>08h30-09h30 - Présentations Scientifiques / Accueil Journées CONTINUUM&lt;/li>
&lt;li>09h30-10h00 - Pause café&lt;/li>
&lt;li>10h00-10h30 - Introduction Journées CONTINUUM&lt;/li>
&lt;li>10h30-11h30 - Présentation des équipes de recherche du site Rennais (MimeTIC, Hybrid, Virtus, Rainbow).&lt;/li>
&lt;li>11h30-12-00 - Présentation d&amp;rsquo;Anne-Laure GUINET, Accessit au prix de thèse du GdR IG-RV 2023 pour sa thèse doctorat intitulée &amp;ldquo;Retours sensoriels multimodaux en réalité augmentée pour la rééducation de la marche des enfants atteints de paralysie cérébrale&amp;rdquo;&lt;/li>
&lt;li>12h00-13h30 - Buffet repas&lt;/li>
&lt;li>13h30-15h30 - Visite plateforme Immersia et démos équipes&lt;/li>
&lt;li>15h30-16h00 - Cloture Journée Scientifiques (Pause Café)&lt;/li>
&lt;/ul>
&lt;h1 id="comment-venir">Comment venir&lt;/h1>
&lt;p>Les sessions plénières se dérouleront au Centre Inria de l&amp;rsquo;Université de Rennes/IRISA. Vous trouverez ici les informations pour nous joindre :&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.irisa.fr/localisez-nous-rennes" target="_blank" rel="noopener">https://www.irisa.fr/localisez-nous-rennes&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.inria.fr/fr/comment-venir-au-centre-inria-de-luniversite-de-rennes" target="_blank" rel="noopener">https://www.inria.fr/fr/comment-venir-au-centre-inria-de-luniversite-de-rennes&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Les tickets de métro et de bus rechargeables peuvent être achetés à la gare ou dans n&amp;rsquo;importe quelle station de métro. Possibilité de valider son titre de transport à la montée des bus avec la carte bancaire.&lt;/p>
&lt;h3 id="plateforme-immersia">Plateforme Immersia&lt;/h3>
&lt;p>La plateforme Immersia est située sur le Campus Universitaire de Beaulieu à côté de l&amp;rsquo;Inria Rennes/IRISA.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.irisa.fr/immersia/localisation/" target="_blank" rel="noopener">https://www.irisa.fr/immersia/localisation/&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Journée Visu 2024</title><link>https://gdr-igrv.fr/event/journee_visu2024/</link><pubDate>Tue, 18 Jun 2024 13:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_visu2024/</guid><description>&lt;p>Nous aurons le plaisir d’accueillir Ingrid Hotz, de l’université de Linköping, comme oratrice invitée.&lt;/p>
&lt;h2 id="soumissions">Soumissions&lt;/h2>
&lt;p>Les dépôts de soumissions seront ouverts à la mi-mars et s&amp;rsquo;effectueront sur le site &lt;a href="https://visu-24.sciencesconf.org/" target="_blank" rel="noopener">https://visu-24.sciencesconf.org/&lt;/a>.
Nous sollicitons des soumissions sur résumé qui présentent des travaux originaux.&lt;/p>
&lt;h2 id="inscriptions">Inscriptions&lt;/h2>
&lt;p>La journée Visu 2024 est gratuite et ouverte à tous dans la limite des capacités d&amp;rsquo;accueil. L’inscription est obligatoire.
Les inscriptions seront ouvertes à la mi-mars et s&amp;rsquo;effectueront sur le site &lt;a href="https://visu-24.sciencesconf.org/" target="_blank" rel="noopener">https://visu-24.sciencesconf.org/&lt;/a>.&lt;/p>
&lt;h2 id="organisation">Organisation&lt;/h2>
&lt;p>Jules Vidal (IRIT, Université Toulouse III)
Romain Vuillemot (LIRIS, Ecole Centrale Lyon)
Jonathan Sarton (ICube, Université de Strasbourg)&lt;/p>
&lt;p>Plus d&amp;rsquo;informations : &lt;a href="https://visu-24.sciencesconf.org/" target="_blank" rel="noopener">https://visu-24.sciencesconf.org/&lt;/a>
Pour toute question : &lt;a href="mailto:jules.vidal@irit.fr">jules.vidal@irit.fr&lt;/a>&lt;/p></description></item><item><title>Résultats du prix de thèse du GdR et des associations AFIG et EGFR 2024</title><link>https://gdr-igrv.fr/post/24-06-14-prixthese/</link><pubDate>Fri, 14 Jun 2024 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/24-06-14-prixthese/</guid><description>&lt;p>&lt;strong>Résultats du prix de thèse du GDR IG-RV 2024
en collaboration avec l’Association Française d’Informatique Graphique et le Chapitre Français d’Eurographics.&lt;/strong>&lt;/p>
&lt;p>&lt;a href="http://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">Page des prix de thèse pour plus de détails sur les lauréats&lt;/a>&lt;/p>
&lt;p>Pour cette huitième édition, la participation au concours était ouverte aux docteurs ayant soutenu leur thèse entre le 01/01/2023 et le 31/12/2023. Il y a eu 12 soumissions, toutes d’un excellent niveau scientifique et couvrant largement les thématiques du GDR IG-RV. Cette année, le jury 2024 a été animé par Georges-Pierre Bonneau et Guillaume Cordonnier. Il était composé de Yvonne Jansen, Jean-Michel Dischler, Bruno Levy, Damien Rohmer, Eric Gali et Daniel Mestre.&lt;/p>
&lt;p>Le prix de thèse du GDR IG-RV 2024 est décerné à :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Emilie Yu&lt;/strong> (Inria, Université Côte d’Azur) pour sa thèse intitulée « Conception d’outils de création de contenu 3D basés sur le dessin 3D » effectuée sous la direction de Adrien Bousseau.&lt;/li>
&lt;/ul>
&lt;p>Avec deux accessits :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Loann Giovannangeli&lt;/strong> (Université de Bordeaux) pour sa thèse intitulée « Génération et Évaluation de Visualisations avec des techniques d’Apprentissage Automatique » effectuée sous la direction de Romain Bourqui.&lt;/li>
&lt;li>&lt;strong>Axel Paris&lt;/strong> (Université de Lyon) pour sa thèse intitulée « Modeling and simulating virtual terrains » effectuée sous la direction de Eric Galin et Eric Guérin.&lt;/li>
&lt;/ul>
&lt;p>Nous tenons à remercier l’ensemble des candidats pour leur participation,&lt;/p>
&lt;p>Bien cordialement&lt;/p>
&lt;p>Les animateurs du prix de thèse 2024,
Guillaume Cordonnier et Georges-Pierre Bonneau&lt;/p></description></item><item><title>Résultats du prix 2024</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2024/</link><pubDate>Thu, 13 Jun 2024 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2024/</guid><description>&lt;h2 id="lauréat">Lauréat&lt;/h2>
&lt;p>&lt;strong>Emilie Yu&lt;/strong> (Inria, Université Côte d&amp;rsquo;Azur) pour sa thèse intitulée « &lt;em>Conception d&amp;rsquo;outils de création de contenu 3D basés sur le dessin 3D&lt;/em> » effectuée sous la direction de Adrien Bousseau&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2024/emilie-yu-phd-video.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://theses.hal.science/tel-04484971" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;h2 id="accessits">Accessits&lt;/h2>
&lt;p>&lt;strong>Loann Giovannangeli&lt;/strong> (Université de Bordeaux) pour sa thèse intitulée « &lt;em>Génération et Évaluation de Visualisations avec des techniques d&amp;rsquo;Apprentissage Automatique&lt;/em> » effectuée sous la direction de Romain Bourqui&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2024/LoannGio_igrv_jfig_v3.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://theses.hal.science/tel-04312123" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>&lt;strong>Axel Paris&lt;/strong> (Université de Lyon) pour sa thèse intitulée « &lt;em>Modeling and simulating virtual terrains&lt;/em> » effectuée sous la direction de Eric Galin et Eric Guérin.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2024/AxelParisJFIGVideo.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://theses.hal.science/tel-04502530v1" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>&lt;em>Le jury 2024 a été animé par Georges-Pierre Bonneau et Guillaume Cordonnier. Il était composé de Yvonne Jansen, Jean-Michel Dischler, Bruno Levy, Damien Rohmer, Eric Galin, Daniel Mestre.&lt;/em>&lt;/p></description></item><item><title>Journées Géométrie dans l'industrie et Jeunes Chercheurs en Géométrie</title><link>https://gdr-igrv.fr/event/journees_geomindus24/</link><pubDate>Thu, 06 Jun 2024 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journees_geomindus24/</guid><description>&lt;p>&lt;em>(English version, French below)&lt;/em>&lt;/p>
&lt;p>As part of the thematic year on &amp;ldquo;Geometry&amp;rdquo; spearheaded by the GdRs IFM and IG-RV, you are invited to a workshop on Geometry in Industry, to be held on June 6th 2024 at Université Gustave Eiffel (20min from Paris using RER A). Several researchers working in industry (or closely linked to it) will present their activity involving various aspects of geometry (including, but not limited to, computational geometry, geometric modeling, and digital geometry). This event will be a great opportunity for the members of the GdRs IFM and IG-RV to learn more about the current trends and challenges faced by the industrial world and consider new collaborations.&lt;/p>
&lt;p>Confirmed presentations from &lt;strong>Tamy Boubekeur&lt;/strong> (Adobe Research), &lt;strong>David Bonner&lt;/strong> (Dassault Systèmes), &lt;strong>Tong Fu&lt;/strong> (Kitware), and &lt;strong>Pierre Alliez&lt;/strong> (Inria, CGAL). More presentations TBA soon.&lt;/p>
&lt;p>Attendance to this event is free. A platform to register will be provided soon, but you can already save the date!&lt;/p>
&lt;p>Note also that travel and accommodation expenses for PhD students and postdocs belonging to the GdR IFM or IG-RV can be covered by the &lt;a href="https://jcgeo24.sciencesconf.org" target="_blank" rel="noopener">Young researcher in Geometry&lt;/a> event held the day after (June 7th 2024) in the same campus. Check out their webpages for the exact procedure.&lt;/p>
&lt;p>++++++++++++++++&lt;/p>
&lt;p>&lt;em>(French version)&lt;/em>&lt;/p>
&lt;p>Dans le cadre de l&amp;rsquo;année thématique « Géométrie » soutenue par les GdRs IGM et IG-RV, vous êtes invités à un colloque sur la Géométrie dans l&amp;rsquo;industrie, qui aura lieu le 6 juin 2024 à l&amp;rsquo;Université Gustave Eiffel (20 minutes depuis le centre de Paris via le RER A). Plusieurs chercheur·se·s travaillant dans l&amp;rsquo;industrie (ou très proche) viendront présenter leur activité impliquant différents aspects de la géométrie (y compris, mais sans s&amp;rsquo;y limiter, la géométrie algorithmique, la modélisation géométrique et la géométrie discrète). Cet événement est une belle opportunité pour les membres des GdR IFM et IG-RV d&amp;rsquo;en apprendre plus sur les tendances actuelles et les défis rencontrés par le monde industriel et d&amp;rsquo;envisager de nouvelles collaborations.&lt;/p>
&lt;p>Présentations confirmées : &lt;strong>Tamy Boubeker&lt;/strong> (Adobe Research), &lt;strong>David Bonner&lt;/strong> (Dassault Systèmes), &lt;strong>Tong Fu&lt;/strong> (Kitware), et &lt;strong>Pierre Alliez&lt;/strong> (Inria, CGAL). D&amp;rsquo;autres présentations seront annoncées prochainement.&lt;/p>
&lt;p>La participation à l&amp;rsquo;événement est gratuite. Une plateforme pour s&amp;rsquo;inscrire vous sera prochainement communiquée, mais vous pouvez d&amp;rsquo;ores et déjà noter la date !&lt;/p>
&lt;p>À noter également que les transports et logement des doctorants et post-doctorants appartenant aux GdRs IFM et IG-RV peuvent être pris en charge dans le cadre de l&amp;rsquo;événement &lt;a href="https://jcgeo24.sciencesconf.org" target="_blank" rel="noopener">Jeunes Chercheurs en Géométrie&lt;/a> qui se tiendra le lendemain (le 7 juin 2024) sur le même campus. De plus amples informations sont disponibles sur leur page.&lt;/p></description></item><item><title>Journées IHM - GdR IG-RV</title><link>https://gdr-igrv.fr/event/journees_ihm2024/</link><pubDate>Thu, 30 May 2024 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journees_ihm2024/</guid><description>&lt;p>Nous vous invitons à participer à la deuxième édition des journées IHM IG RV le 30 et 31 mai 2024 à Lille. Ces journées sont communes au GdR IG-RV (&lt;a href="https://gdr-igrv.fr/" target="_blank" rel="noopener">https://gdr-igrv.fr/&lt;/a>) et à l&amp;rsquo;AFIHM (&lt;a href="https://www.afihm.org/%29" target="_blank" rel="noopener">https://www.afihm.org/)&lt;/a>.&lt;/p>
&lt;p>L&amp;rsquo;objectif de ces journées est d&amp;rsquo;offrir une vision élargie des recherches menées autour des communautés scientifiques de l&amp;rsquo;Informatique Graphique, la Réalité Virtuelle et l&amp;rsquo;Interaction Humain-Machine. Les journées IHM IG RV sont ainsi une belle opportunité pour avoir des échanges scientifiques riches avec des spécialistes des différentes communautés, rencontrer et recruter de jeunes talents, faire connaitre vos activités et nouer des partenariats, effectuer des réunions de projet ou/et initier de nouveaux projets!&lt;/p>
&lt;p>Cette deuxième édition sera placée sous le thème de la créativité! Nous aurons deux présentations invitées passionnantes données par Adrien Bousseau (DR Inria Sophia-Antipolis) et Marcelo Wanderley (Pr. McGill University).
Vous avez la possibilité de proposer une contribution scientifique qui pourra être présentée sous forme de communication sans actes. Deux modalités de contributions scientifiques sont proposées: soumission de travaux en cours ou bien présentation de travaux déjà publiés.
N&amp;rsquo;hésitez pas à parcourir le site web dédié aux journées pour plus de détails : &lt;a href="https://ihmigrv.afihm.org" target="_blank" rel="noopener">https://ihmigrv.afihm.org&lt;/a>.&lt;/p>
&lt;p>L&amp;rsquo;inscription à la journée est gratuite mais obligatoire. Afin de faciliter l&amp;rsquo;organisation, nous vous invitons à vous inscrire dès maintenant et avant le 2 avril 2024.
Nous espérons vous voir nombreux à Lille !&lt;/p>
&lt;p>Bonnes fêtes de fin d&amp;rsquo;année,&lt;/p>
&lt;p>Maud Marchal et Thomas Pietrzak&lt;/p></description></item><item><title>Rencontres des Jeunes Chercheurs du GTMG</title><link>https://gdr-igrv.fr/event/journees_rgtmg2024/</link><pubDate>Wed, 27 Mar 2024 12:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journees_rgtmg2024/</guid><description/></item><item><title>Résultats du prix de thèse du GdR et des associations AFIG et EGFR 2023</title><link>https://gdr-igrv.fr/post/08-11-2023-prixthese/</link><pubDate>Tue, 07 Nov 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/08-11-2023-prixthese/</guid><description>&lt;p>&lt;strong>Résultats du prix de thèse du GDR IG-RV 2023
en collaboration avec l’Association Française d’Informatique Graphique et le Chapitre Français d’Eurographics.&lt;/strong>&lt;/p>
&lt;p>&lt;a href="http://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">Page des prix de thèse pour plus de détails sur les lauréats&lt;/a>&lt;/p>
&lt;p>Pour cette septième édition, la participation au concours était ouverte aux docteurs ayant soutenu leur thèse entre le 01/01/2022 et le 31/12/2022. Il y a eu 13 soumissions, toutes d’un excellent niveau scientifique et couvrant largement les thématiques du GDR IG-RV. Cette année, le jury de sélection a été animé par Guillaume Cordonnier et Loïc Barthe et il était composé de Florence Bertails-Descoubes, Bruno Levy, Tamy Boubekeur, Eric Galin, Yvonne Jansen et Daniel Mestre.&lt;/p>
&lt;p>Le prix de thèse du GDR IG-RV 2023 est décerné à :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Thibault Tricard&lt;/strong> (Inria, Université de Lorraine) pour sa thèse intitulée « Procedural noises for the design of small-scale structures in Additive Manufacturing » effectuée sous la direction de Sylvain Lefebvre et Didier Rouxel.&lt;/li>
&lt;/ul>
&lt;p>Deux accessit ont aussi été décernés à :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Anne-Laure Guinet&lt;/strong> (Université Evry-Paris-Saclay) pour sa thèse intitulée « Retours sensoriels multimodaux en réalité augmentée pour la rééducation de la marche des enfants atteints de paralysie cérébrale » effectuée sous la direction de Samir Otmane, Guillaume Bouyer et de Eric Desailly.&lt;/li>
&lt;li>&lt;strong>François Protais&lt;/strong> (Inria, Université de Lorraine) pour sa thèse intitulée « Maillage à dominante Polycube » effectuée sous la direction de Dmitry Sokolov et Franck Ledoux.&lt;/li>
&lt;/ul>
&lt;p>Le prix de thèse sera remis à l&amp;rsquo;occasion des Journées Françaises de l&amp;rsquo;Informatique Graphique, les 8-10 novembre à Montpellier.&lt;/p>
&lt;p>Nous tenons à remercier l’ensemble des candidats pour leur participation,&lt;/p>
&lt;p>Bien cordialement&lt;/p>
&lt;p>Les animateurs du prix de thèse 2023,
Guillaume Cordonnier et Loïc Barthe&lt;/p></description></item><item><title>Des contributions françaises à SIGGRAPH 2023</title><link>https://gdr-igrv.fr/post/23-07-31-siggraph2023/</link><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/23-07-31-siggraph2023/</guid><description>&lt;p>N&amp;rsquo;hésitez pas à nous signaler tout oubli.&lt;/p>
&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table des matières&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#building-a-virtual-weakly-compressible-wind-tunnel-testing-facility">Building a Virtual Weakly-compressible Wind Tunnel Testing Facility&lt;/a>&lt;/li>
&lt;li>&lt;a href="#patternshop-editing-point-patterns-by-image-manipulation">Patternshop: Editing Point Patterns by Image Manipulation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#a-sparse-non-parametric-brdf-model">A Sparse Non-parametric BRDF Model&lt;/a>&lt;/li>
&lt;li>&lt;a href="#videodoodles-hand-drawn-animations-on-videos-with-scene-aware-canvases">VideoDoodles: Hand-drawn Animations on Videos With Scene-aware Canvases&lt;/a>&lt;/li>
&lt;li>&lt;a href="#large-scale-terrain-authoring-through-interactive-erosion-simulation">Large-scale Terrain Authoring Through Interactive Erosion Simulation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#forming-terrains-by-glacial-erosion">Forming Terrains by Glacial Erosion&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contesse-accurate-occluding-contours-for-subdivision-surfaces">ConTesse: Accurate Occluding Contours for Subdivision Surfaces&lt;/a>&lt;/li>
&lt;li>&lt;a href="#polynomial-2d-green-coordinates-for-polygonal-cages">Polynomial 2D Green Coordinates for Polygonal Cages&lt;/a>&lt;/li>
&lt;li>&lt;a href="#orientable-dense-cyclic-infill-for-anisotropic-appearance-fabrication">Orientable Dense Cyclic Infill for Anisotropic Appearance Fabrication&lt;/a>&lt;/li>
&lt;li>&lt;a href="#complex-wrinkle-field-evolution">Complex Wrinkle Field Evolution&lt;/a>&lt;/li>
&lt;li>&lt;a href="#coupling-conduction-convection-and-radiative-transfer-in-a-single-path-space-application-to-infrared-rendering">Coupling Conduction, Convection and Radiative Transfer in a Single Path-Space: Application to Infrared Rendering&lt;/a>&lt;/li>
&lt;li>&lt;a href="#textured-mesh-quality-assessment-large-scale-dataset-and-deep-learning-based-quality-metric">Textured Mesh Quality Assessment: Large-scale Dataset and Deep Learning-based Quality Metric&lt;/a>&lt;/li>
&lt;li>&lt;a href="#variational-shape-reconstruction-via-quadric-error-metrics">Variational Shape Reconstruction via Quadric Error Metrics&lt;/a>&lt;/li>
&lt;li>&lt;a href="#somigliana-coordinates-an-elasticity-derived-approach-for-cage-deformation">Somigliana Coordinates: An Elasticity-derived Approach for Cage Deformation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#constraint-based-simulation-of-passive-suction-cups">Constraint-based Simulation of Passive Suction Cups&lt;/a>&lt;/li>
&lt;li>&lt;a href="#mesogen-designing-procedural-on-surface-stranded-mesostructures">MesoGen: Designing Procedural On-surface Stranded Mesostructures&lt;/a>&lt;/li>
&lt;li>&lt;a href="#fluid-solid-coupling-in-kinetic-two-phase-flow-simulation">Fluid-solid Coupling in Kinetic Two-phase Flow Simulation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#greil-crowds-crowd-simulation-with-deep-reinforcement-learning-and-examples">GREIL-Crowds: Crowd Simulation With Deep Reinforcement Learning and Examples&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3d-gaussian-splatting-for-real-time-radiance-field-rendering">3D Gaussian Splatting for Real-Time Radiance Field Rendering&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pcbend-light-up-your-3d-shapes-with-foldable-circuit-boards">PCBend: Light Up Your 3D Shapes With Foldable Circuit Boards&lt;/a>&lt;/li>
&lt;li>&lt;a href="#fast-gpu-based-two-way-continuous-collision-handling">Fast GPU-based Two-way Continuous Collision Handling&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;h2 id="building-a-virtual-weakly-compressible-wind-tunnel-testing-facility">Building a Virtual Weakly-compressible Wind Tunnel Testing Facility&lt;/h2>
&lt;p>&lt;em>Chaoyang Lyu (ShanghaiTech University / SIMIT / UCAS), Kai Bai (ShanghaiTech University / AEROCAE Digital Ltd.), Yiheng Wu (ShanghaiTech University), Mathieu Desbrun (Inria and Ecole Polytechnique), Changxi Zheng (Tencent Pixel Lab and Columbia University), Xiaopei Liu (ShanghaiTech University)&lt;/em>&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-07-31-siggraph2023/windTunnel2023_hu2d9686d9240c9a987dd2062745f588e6_62179_8fff236cd3acb2de842d10cbcb75af86.webp 400w,
/post/23-07-31-siggraph2023/windTunnel2023_hu2d9686d9240c9a987dd2062745f588e6_62179_65ae865b18131d2f96d1cd959b0983d4.webp 760w,
/post/23-07-31-siggraph2023/windTunnel2023_hu2d9686d9240c9a987dd2062745f588e6_62179_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/windTunnel2023_hu2d9686d9240c9a987dd2062745f588e6_62179_8fff236cd3acb2de842d10cbcb75af86.webp"
width="313"
height="195"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Virtual wind tunnel testing is a key ingredient in the engineering design process for the automotive and aeronautical industries as well as for urban planning: through visualization and analysis of the simulation data, it helps optimize lift and drag coefficients, increase peak speed, detect high pressure zones, and reduce wind noise at low cost prior to manufacturing. In this paper, we develop an efficient and accurate virtual wind tunnel system based on recent contributions from both computer graphics and computational fluid dynamics in high-performance kinetic solvers. Running on one or multiple GPUs, our massively-parallel lattice Boltzmann model meets industry standards for accuracy and consistency while exceeding current mainstream industrial solutions in terms of efficiency Ð especially for unsteady turbulent flow simulation at very high Reynolds number (on the order of 10^7) &amp;ndash; due to key contributions in improved collision modeling and boundary treatment, automatic construction of multiresolution grids for complex models, as well as performance optimization. We demonstrate the efficacy and reliability of our virtual wind tunnel testing facility through comparisons of our results to multiple benchmark tests, showing an increase in both accuracy and efficiency compared to state-of-the-art industrial solutions. We also illustrate the fine turbulence structures that our system can capture, indicating the relevance of our solver for both VFX and industrial product design.&lt;/p>
&lt;video controls >
&lt;source src="http://www.geometry.caltech.edu/Movies/LBWD&amp;#43;23.mp4" type="video/mp4">
&lt;/video>
&lt;h2 id="patternshop-editing-point-patterns-by-image-manipulation">Patternshop: Editing Point Patterns by Image Manipulation&lt;/h2>
&lt;p>&lt;em>Xingchang Huang (Max Planck Institute for Informatics), Tobias Ritschel (University College London), Hans-Peter Seidel (Max Planck Institute for Informatics), Pooran Memari (LIX-Inria), Gurprit Singh (Max Planck Institute for Informatics)&lt;/em>&lt;/p>
&lt;figure id="figure-our-framework-facilitate-point-pattern-design-by-representing-both-density-and-correlation-as-a-three-channel-raster-image-a-these-images-can-be-edited-c-in-terms-of-their-density-or-correlation-using-off-the-shelf-image-manipulation-software-the-resulting-point-patterns-are-shown-before-b-and-after-the-edits-d-please-see-the-accompanied-supplemental-material-for-vector-graphic-images">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Our framework facilitate point pattern design by representing both density and correlation as a three-channel raster image (a). These images can be edited (c) in terms of their density or correlation using off-the-shelf image manipulation software. The resulting point patterns are shown before (b) and after the edits (d). Please see the accompanied supplemental material for vector graphic images." srcset="
/post/23-07-31-siggraph2023/Huang2023_hub913d5f797897cd9e2b8611f3f4630bc_441127_e6f2b232f3683b0f9b166032b45a887b.webp 400w,
/post/23-07-31-siggraph2023/Huang2023_hub913d5f797897cd9e2b8611f3f4630bc_441127_19bb6c8269387816e94a57c4a55291f0.webp 760w,
/post/23-07-31-siggraph2023/Huang2023_hub913d5f797897cd9e2b8611f3f4630bc_441127_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Huang2023_hub913d5f797897cd9e2b8611f3f4630bc_441127_e6f2b232f3683b0f9b166032b45a887b.webp"
width="760"
height="207"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Our framework facilitate point pattern design by representing both density and correlation as a three-channel raster image (a). These images can be edited (c) in terms of their density or correlation using off-the-shelf image manipulation software. The resulting point patterns are shown before (b) and after the edits (d). Please see the accompanied supplemental material for vector graphic images.
&lt;/figcaption>&lt;/figure>
&lt;p>Point patterns are characterized by their density and correlation. While spatial variation of density is well-understood, analysis and synthesis of spatially-varying correlation is an open challenge. No tools are available to intuitively edit such point patterns, primarily due to the lack of a compact representation for spatially varying correlation. We propose a low-dimensional perceptual embedding for point correlations. This embedding can map point patterns to common three-channel raster images, enabling manipulation with off-the-shelf image editing software. To synthesize back point patterns, we propose a novel edge-aware objective that carefully handles sharp variations in density and correlation. The resulting framework allows intuitive and backward-compatible manipulation of point patterns, such as recoloring, relighting to even texture synthesis that have not been available to 2D point pattern design before. Effectiveness of our approach is tested in several user experiments. Code is available at &lt;a href="https://github.com/xchhuang/patternshop" target="_blank" rel="noopener">https://github.com/xchhuang/patternshop&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://xchhuang.github.io/patternshop/" target="_blank" rel="noopener">&lt;em>Page projet&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="a-sparse-non-parametric-brdf-model">A Sparse Non-parametric BRDF Model&lt;/h2>
&lt;p>&lt;em>Tanaboon Tongbuasirilai, Jonas Unger (Linkoping University), Christine Guillemot (INRIA), Ehsan Miandji (Linkoping University)&lt;/em>&lt;/p>
&lt;figure id="figure-an-overview-of-the-proposed-framework-for-learning-accurate-representations-and-sparse-data-driven-brdf-models-through-analysis-of-the-space-of-brdfs-the-brdf-dictionary-ensemble-is-trained-once-and-can-accurately-represent-a-wide-range-of-previously-unseen-materials">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="An overview of the proposed framework for learning accurate representations and sparse data-driven BRDF models through analysis of the space of BRDFs. The BRDF dictionary ensemble is trained once and can accurately represent a wide range of previously unseen materials." srcset="
/post/23-07-31-siggraph2023/Tongbuasirilai2023_hua36147e27d19343525cc8ffe3f476577_106446_dcd635af33beb48d29efc6cca2115be8.webp 400w,
/post/23-07-31-siggraph2023/Tongbuasirilai2023_hua36147e27d19343525cc8ffe3f476577_106446_a7a2990d988acf85350ef90e89ad92f3.webp 760w,
/post/23-07-31-siggraph2023/Tongbuasirilai2023_hua36147e27d19343525cc8ffe3f476577_106446_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Tongbuasirilai2023_hua36147e27d19343525cc8ffe3f476577_106446_dcd635af33beb48d29efc6cca2115be8.webp"
width="760"
height="200"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
An overview of the proposed framework for learning accurate representations and sparse data-driven BRDF models through analysis of the space of BRDFs. The BRDF dictionary ensemble is trained once and can accurately represent a wide range of previously unseen materials.
&lt;/figcaption>&lt;/figure>
&lt;p>This paper presents a novel sparse non-parametric BRDF model derived using a machine learning approach to represent the space of possible BRDFs using a set of multidimensional sub-spaces, or dictionaries. By training the dictionaries under a sparsity constraint, the model guarantees high quality representations with minimal storage requirements and an inherent clustering of the BDRF-space. The model can be trained once and then reused to represent a wide variety of measured BRDFs. Moreover, the proposed method is flexible to incorporate new unobserved data sets, parameterizations, and transformations. In addition, we show that any two, or more, BRDFs can be smoothly interpolated in the coefficient space of the model rather than the significantly higher-dimensional BRDF space. The proposed sparse BRDF model is evaluated using the MERL, DTU and RGL-EPFL BRDF databases. Experimental results show that the proposed approach results in about 9.75dB higher SNR on average for rendered images as compared to current state-of-the-art models.&lt;/p>
&lt;p>&lt;a href="https://hal.science/hal-03654734/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="videodoodles-hand-drawn-animations-on-videos-with-scene-aware-canvases">VideoDoodles: Hand-drawn Animations on Videos With Scene-aware Canvases&lt;/h2>
&lt;p>&lt;em>Emilie Yu (Centre Inria d&amp;rsquo;Universite Cote d&amp;rsquo;Azur), Kevin Matzen, Cuong Nguyen, Oliver Wang, Rubaiat Habib Kazi (Adobe), Adrien Bousseau (Centre Inria d&amp;rsquo;Universite Cote d&amp;rsquo;Azur and TU Delft)&lt;/em>&lt;/p>
&lt;figure id="figure-video-doodles-combine-hand-drawn-animations-with-video-footage-our-interactive-system-eases-the-creation-of-this-mixed-media-art-by-letting-users-place-planar-canvases-in-the-scene-which-are-then-tracked-in-3d-in-this-example-the-inserted-rainbow-bridge-exhibits-correct-perspective-and-occlusions-and-the-characters-face-and-arms-follow-the-tram-as-it-runs-towards-the-camera">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Video doodles combine hand-drawn animations with video footage. Our interactive system eases the creation of this mixed media art by letting users place planar canvases in the scene which are then tracked in 3D. In this example, the inserted rainbow bridge exhibits correct perspective and occlusions, and the character’s face and arms follow the tram as it runs towards the camera." srcset="
/post/23-07-31-siggraph2023/Yu2023_hue8dae0495c45bedbccd3c7a8dc80448c_1188849_505a82327c9e5f44bedcd333f1ca82b4.webp 400w,
/post/23-07-31-siggraph2023/Yu2023_hue8dae0495c45bedbccd3c7a8dc80448c_1188849_28cbdf70130e3e95c8f68f7c7da0a145.webp 760w,
/post/23-07-31-siggraph2023/Yu2023_hue8dae0495c45bedbccd3c7a8dc80448c_1188849_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Yu2023_hue8dae0495c45bedbccd3c7a8dc80448c_1188849_505a82327c9e5f44bedcd333f1ca82b4.webp"
width="760"
height="141"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Video doodles combine hand-drawn animations with video footage. Our interactive system eases the creation of this mixed media art by letting users place planar canvases in the scene which are then tracked in 3D. In this example, the inserted rainbow bridge exhibits correct perspective and occlusions, and the character’s face and arms follow the tram as it runs towards the camera.
&lt;/figcaption>&lt;/figure>
&lt;p>We present an interactive system to ease the creation of so-called video doodles – videos on which artists insert hand-drawn animations for entertainment or educational purposes. Video doodles are challenging to create because to be convincing, the inserted drawings must appear as if they were part of the captured scene. In particular, the drawings should undergo tracking, perspective deformations and occlusions as they move with respect to the camera and to other objects in the scene – visual effects that are difficult to reproduce with existing 2D video editing software. Our system supports these effects by relying on planar canvases that users position in a 3D scene reconstructed from the video. Furthermore, we present a custom tracking algorithm that allows users to anchor canvases to static or dynamic objects in the scene, such that the canvases move and rotate to follow the position and direction of these objects. When testing our system, novices could create a variety of short animated clips in a dozen of minutes, while professionals praised its speed and ease of use compared to existing tools.&lt;/p>
&lt;video controls >
&lt;source src="https://em-yu.github.io/media/figures/VideoDoodles/RESULTS_ours.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://em-yu.github.io/research/videodoodles/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="large-scale-terrain-authoring-through-interactive-erosion-simulation">Large-scale Terrain Authoring Through Interactive Erosion Simulation&lt;/h2>
&lt;p>&lt;em>Hugo Schott, Axel Paris, Lucie Fournier, Eric Guerin, Eric Galin (Univ Lyon / INSA Lyon / CNRS / UCBL / LIRIS / UMR5205)&lt;/em>&lt;/p>
&lt;figure id="figure-given-an-input-uplift-field-we-automatically-generate-the-large-scale-terrain-elevation-by-simulating-stream-power-erosion-using-a-parallel-drainage-area-algorithm-inlined-in-the-simulation-the-user-may-define-the-uplift-field-providing-ridge-and-river-networks-or-using-inverse-procedural-modeling-by-computing-the-uplift-from-an-input-digital-elevation-model">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Given an input uplift field, we automatically generate the large-scale terrain elevation by simulating stream power erosion using a parallel drainage area algorithm inlined in the simulation. The user may define the uplift field, providing ridge and river networks, or using inverse procedural modeling by computing the uplift from an input digital elevation model." srcset="
/post/23-07-31-siggraph2023/Schott2023_hu42c68a5fabc66b4348f4f85244181c2e_387504_b89d7b0a5cd66d972f088d7668fbf4b6.webp 400w,
/post/23-07-31-siggraph2023/Schott2023_hu42c68a5fabc66b4348f4f85244181c2e_387504_adee5beb6d3ae8da36b781d57687d5c6.webp 760w,
/post/23-07-31-siggraph2023/Schott2023_hu42c68a5fabc66b4348f4f85244181c2e_387504_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Schott2023_hu42c68a5fabc66b4348f4f85244181c2e_387504_b89d7b0a5cd66d972f088d7668fbf4b6.webp"
width="760"
height="151"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Given an input uplift field, we automatically generate the large-scale terrain elevation by simulating stream power erosion using a parallel drainage area algorithm inlined in the simulation. The user may define the uplift field, providing ridge and river networks, or using inverse procedural modeling by computing the uplift from an input digital elevation model.
&lt;/figcaption>&lt;/figure>
&lt;p>Large-scale terrains are essential in the definition of virtual worlds. Given the diversity of landforms and the geomorphological complexity, there is a need for authoring techniques offering hydrological consistency without sacrificing user control. In this paper, we bridge the gap between large-scale erosion simulation and authoring into an efficient framework. We set aside modeling in the elevation domain in favour of the uplift domain, and compute emerging reliefs by simulating the stream power erosion. Our simulation relies on a fast yet accurate approximation of drainage area and flow routing to compute the erosion interactively, which allows for incremental authoring. Our model provides landscape artists with tools for shaping mountain ranges and valleys, such as copy-and-paste operations; warping for imitating folds and faults; point and curve elevation constraints to precisely sculpt ridges or carve river networks. It also lends itself to inverse procedural modeling by reconstructing the uplift from an input digital elevation model and allows hydrologically consistent blending between terrain patches.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/gCP7jzcPLyQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://hal.archives-ouvertes.fr/hal-04049125/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="forming-terrains-by-glacial-erosion">Forming Terrains by Glacial Erosion&lt;/h2>
&lt;p>&lt;em>Guillaume Cordonnier (Inria and Universite Cote d&amp;rsquo;Azur), Guillaume Jouvet (University of Lausanne), Adrien Peytavie (Univ Lyon / INSA Lyon / CNRS / UCBL / LIRIS / UMR5205), Jean Braun (Helmholtz Centre Potsdam and University of Potsdam), Marie-Paule Cani (Ecole Polytechnique), Bedrich Benes (Purdue University), Eric Galin, Eric Guerin (Univ Lyon / INSA Lyon / CNRS / UCBL / LIRIS / UMR5205), James Gain (University of Cape Town)&lt;/em>&lt;/p>
&lt;figure id="figure-a-landscape-carved-by-our-simulated-glacier-specific-landforms-are-1-u-shaped-valleys-2-hanging-valleys-3-a-glacial-cirque-overhung-by-arêtes-and-horns-4-a-pass-and-5-highaltitude-lakes">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="A landscape carved by our simulated glacier. Specific landforms are (1) U-shaped valleys, (2) hanging valleys, (3) a glacial cirque overhung by arêtes and horns, (4) a pass, and (5) high–altitude lakes." srcset="
/post/23-07-31-siggraph2023/Cordonnier2023_hu0e9c5b3ce4c6577c3de3b8d979210db0_152763_1780becfd13c6b355004cd47d9e08edb.webp 400w,
/post/23-07-31-siggraph2023/Cordonnier2023_hu0e9c5b3ce4c6577c3de3b8d979210db0_152763_0dffbd41210d5e45a516ebc6706fb8c8.webp 760w,
/post/23-07-31-siggraph2023/Cordonnier2023_hu0e9c5b3ce4c6577c3de3b8d979210db0_152763_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Cordonnier2023_hu0e9c5b3ce4c6577c3de3b8d979210db0_152763_1780becfd13c6b355004cd47d9e08edb.webp"
width="412"
height="314"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
A landscape carved by our simulated glacier. Specific landforms are (1) U-shaped valleys, (2) hanging valleys, (3) a glacial cirque overhung by arêtes and horns, (4) a pass, and (5) high–altitude lakes.
&lt;/figcaption>&lt;/figure>
&lt;p>We introduce the first solution for simulating the formation and evolution of glaciers, together with their attendant erosive effects, for periods covering the combination of glacial and inter-glacial cycles. Our efficient solution includes both a fast yet accurate deep learning-based estimation of high-order ice flows and a new, multi-scale advection scheme enabling us to account for the distinct time scales at which glaciers reach equilibrium compared to eroding the terrain. We combine the resulting glacial erosion model with finer-scale erosive phenomena to account for the transport of debris flowing from cliffs. This enables us to model the formation of terrain shapes not previously adequately modeled in Computer Graphics, ranging from U-shaped and hanging valleys to fjords and glacial lakes.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/xfk_J4VhdWA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://hal.archives-ouvertes.fr/hal-04090644/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="contesse-accurate-occluding-contours-for-subdivision-surfaces">ConTesse: Accurate Occluding Contours for Subdivision Surfaces&lt;/h2>
&lt;p>&lt;em>Chenxi Liu (University of British Columbia), Pierre Benard (University of Bordeaux / CNRS / Bordeaux INP / INRIA / LaBRI), Aaron Hertzmann (Adobe Research), Shayan Hoshyari (Adobe)&lt;/em>&lt;/p>
&lt;figure id="figure-given-a-a-smooth-3d-surface-and-a-camera-viewpoint-our-method-produces-b-a-triangle-mesh-where-the-occluding-contour-of-the-mesh-accurately-approximates-the-occluding-contour-of-the-smooth-surface-standard-algorithms-may-then-be-used-to-extract-c-the-view-map-of-occluding-contours-and-to-d-stylize-them-fertility-courtesy-uu-from-aimshape-visionair-shape-repository">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Given (a) a smooth 3D surface and a camera viewpoint, our method produces (b) a triangle mesh where the occluding contour of the mesh accurately approximates the occluding contour of the smooth surface. Standard algorithms may then be used to extract (c) the view map of occluding contours, and to (d) stylize them. (Fertility courtesy UU from AIM@SHAPE-VISIONAIR Shape Repository). " srcset="
/post/23-07-31-siggraph2023/Liu2023_hu8cd5e87749f2520bba733f76166d2fcb_237901_ff05ff1039096b189a946f19311ebc07.webp 400w,
/post/23-07-31-siggraph2023/Liu2023_hu8cd5e87749f2520bba733f76166d2fcb_237901_8765f93cb0a8c9ca08cf8757545148fd.webp 760w,
/post/23-07-31-siggraph2023/Liu2023_hu8cd5e87749f2520bba733f76166d2fcb_237901_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Liu2023_hu8cd5e87749f2520bba733f76166d2fcb_237901_ff05ff1039096b189a946f19311ebc07.webp"
width="760"
height="183"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Given (a) a smooth 3D surface and a camera viewpoint, our method produces (b) a triangle mesh where the occluding contour of the mesh accurately approximates the occluding contour of the smooth surface. Standard algorithms may then be used to extract (c) the view map of occluding contours, and to (d) stylize them. (Fertility courtesy UU from AIM@SHAPE-VISIONAIR Shape Repository).
&lt;/figcaption>&lt;/figure>
&lt;p>This paper proposes a method for computing the visible occluding contours of subdivision surfaces. The paper first introduces new theory for contour visibility of smooth surfaces. Necessary and sufficient conditions are introduced for when a sampled occluding contour is valid, that is, when it may be assigned consistent visibility. Previous methods do not guarantee these conditions, which helps explain why smooth contour visibility has been such a challenging problem in the past. The paper then proposes an algorithm that, given a subdivision surface, finds sampled contours satisfying these conditions, and then generates a new triangle mesh matching the given occluding contours. The contours of the output triangle mesh may then be rendered with standard non-photorealistic rendering algorithms, using the mesh for visibility computation. The method can be applied to any triangle mesh, by treating it as the base mesh of a subdivision surface.&lt;/p>
&lt;p>&lt;a href="https://dgp.toronto.edu/~hertzman/contesse/contesse_arxiv.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="polynomial-2d-green-coordinates-for-polygonal-cages">Polynomial 2D Green Coordinates for Polygonal Cages&lt;/h2>
&lt;p>&lt;em>Elie Michel, Jean-Marc Thiery (Adobe Research)&lt;/em>&lt;/p>
&lt;figure id="figure-top-row-a-input-image-and-an-embedding-polygonal-cage-b-d-deformations-obtained-using-mean-value-coordinates-cubic-mean-value-coordinates-and-green-coordinates-e-our-conformal-deformations-obtained-with-cubic-curves-bottom-row-more-resuls-of-our-approach-using-polynomial-curves-of-various-orders-from-1-to-7">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Top row: (a) input image and an embedding polygonal cage; (b-d) deformations obtained using Mean-Value coordinates, Cubic Mean-Value coordinates, and Green coordinates; (e) our conformal deformations obtained with cubic curves. Bottom row: more resuls of our approach, using polynomial curves of various orders (from 1 to 7)." srcset="
/post/23-07-31-siggraph2023/Michel2023_huc959bab4be803eed9e21ba0ee506a8ec_189161_ef86e0c3f951e6738d9ef7afb90eea9d.webp 400w,
/post/23-07-31-siggraph2023/Michel2023_huc959bab4be803eed9e21ba0ee506a8ec_189161_4919a178f9e4a2d872e6b45012955a26.webp 760w,
/post/23-07-31-siggraph2023/Michel2023_huc959bab4be803eed9e21ba0ee506a8ec_189161_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Michel2023_huc959bab4be803eed9e21ba0ee506a8ec_189161_ef86e0c3f951e6738d9ef7afb90eea9d.webp"
width="760"
height="288"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Top row: (a) input image and an embedding polygonal cage; (b-d) deformations obtained using Mean-Value coordinates, Cubic Mean-Value coordinates, and Green coordinates; (e) our conformal deformations obtained with cubic curves. Bottom row: more resuls of our approach, using polynomial curves of various orders (from 1 to 7).
&lt;/figcaption>&lt;/figure>
&lt;p>Cage coordinates are a powerful means to define 2D deformation fields from sparse control points. We introduce Conformal polynomial Coordinates for closed polyhedral cages, enabling segments to be transformed into polynomial curves of any order. Extending classical 2D Green coordinates, our coordinates result in conformal harmonic deformations that are cage-aware. We demonstrate the usefulness of our technique on a variety of 2D deformation scenarios where curves allow artists to perform intuitive deformations with few input parameters. Our method combines the texture preservation property of conformal deformations together with the expressiveness offered by Bezier controls.&lt;/p>
&lt;p>&lt;a href="https://portfolio.exppad.com/documents/2023__Michel__PolynomialGreenCoords.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="orientable-dense-cyclic-infill-for-anisotropic-appearance-fabrication">Orientable Dense Cyclic Infill for Anisotropic Appearance Fabrication&lt;/h2>
&lt;p>&lt;em>Xavier Chermain, Cedric Zanni, Jonas MartÃ­nez, Pierre-Alexandre Hugron, Sylvain Lefebvre (Universite de Lorraine / CNRS / Inria)&lt;/em>&lt;/p>
&lt;figure id="figure-we-develop-an-efficient-algorithm-that-produces-an-orientable-dense-cyclic-infill-by-aligning-a-field-of-periodic-functions-contouring-it-to-obtain-cycles-and-connecting-all-cycles-into-one-we-leverage-this-algorithm-to-print-anisotropic-appearances-using-fused-filament-fabrication-left-the-shape-with-purple-boundaries-is-infilled-with-a-cycle-the-cycles-directions-have-four-modes-parallel-to-the-boundary-red-area-orthogonal-to-the-boundary-blue-area-smoothest-lines-yellow-area-and-constrained-lines-color-gradient-area-our-algorithm-is-very-flexible-allowing-directions-to-be-constrained-everywhere-areas-with-a-color-gradient-in-the-logo-or-only-within-the-vicinity-of-the-boundary-blue-red-and-yellow-areas-alignment-with-boundaries-can-also-be-constrained-as-in-this-example-the-grey-cycle-is-the-output-of-our-algorithm-curve-interspace-objective-25-mm-right-printed-cycle-with-interspace-set-to-04-mm-the-trajectorys-directions-determine-the-appearance-as-extruded-filaments-exhibit-anisotropic-roughness">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="We develop an efficient algorithm that produces an orientable dense cyclic infill by aligning a field of periodic functions, contouring it to obtain cycles, and connecting all cycles into one. We leverage this algorithm to print anisotropic appearances using fused filament fabrication. Left: the shape with purple boundaries is infilled with a cycle. The cycle’s directions have four modes: parallel to the boundary (red area), orthogonal to the boundary (blue area), smoothest lines (yellow area), and constrained lines (color gradient area). Our algorithm is very flexible, allowing directions to be constrained everywhere (areas with a color gradient in the logo) or only within the vicinity of the boundary (blue, red, and yellow areas). Alignment with boundaries can also be constrained, as in this example. The grey cycle is the output of our algorithm (curve interspace objective: 2.5 mm). Right: Printed cycle with interspace set to 0.4 mm. The trajectory’s directions determine the appearance, as extruded filaments exhibit anisotropic roughness." srcset="
/post/23-07-31-siggraph2023/Chermain2023_hue373d50df52cd9152bf212acc56125b2_855072_4c0a4b50beb7eee86837a2bbf5954390.webp 400w,
/post/23-07-31-siggraph2023/Chermain2023_hue373d50df52cd9152bf212acc56125b2_855072_8169254fd2858771158ad0bc89a78528.webp 760w,
/post/23-07-31-siggraph2023/Chermain2023_hue373d50df52cd9152bf212acc56125b2_855072_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Chermain2023_hue373d50df52cd9152bf212acc56125b2_855072_4c0a4b50beb7eee86837a2bbf5954390.webp"
width="760"
height="208"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
We develop an efficient algorithm that produces an orientable dense cyclic infill by aligning a field of periodic functions, contouring it to obtain cycles, and connecting all cycles into one. We leverage this algorithm to print anisotropic appearances using fused filament fabrication. Left: the shape with purple boundaries is infilled with a cycle. The cycle’s directions have four modes: parallel to the boundary (red area), orthogonal to the boundary (blue area), smoothest lines (yellow area), and constrained lines (color gradient area). Our algorithm is very flexible, allowing directions to be constrained everywhere (areas with a color gradient in the logo) or only within the vicinity of the boundary (blue, red, and yellow areas). Alignment with boundaries can also be constrained, as in this example. The grey cycle is the output of our algorithm (curve interspace objective: 2.5 mm). Right: Printed cycle with interspace set to 0.4 mm. The trajectory’s directions determine the appearance, as extruded filaments exhibit anisotropic roughness.
&lt;/figcaption>&lt;/figure>
&lt;p>We present a method to 3D print surfaces exhibiting a prescribed varying field of anisotropic appearance using only standard fused filament fabrication printers. This enables the fabrication of patterns triggering reflections similar to that of brushed metal with direct control over the directionality of the reflections. Our key insight, on which we ground the method, is that the direction of the deposition paths leads to a certain degree of surface roughness, which yields a visual anisotropic appearance. Therefore, generating dense cyclic infills aligned with a line field allows us to grade the anisotropic appearance of the printed surface. To achieve this, we introduce a highly parallelizable algorithm for optimizing oriented, cyclic paths. Our algorithm outperforms existing approaches regarding efficiency, robustness, and result quality. We demonstrate the effectiveness of our technique in conveying an anisotropic appearance on several challenging test cases, ranging from patterns to photographs reinterpreted as anisotropic appearances.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/aUDzZrlRnNU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://xavierchermain.github.io/data/pdf/Chermain2023Orientable.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="complex-wrinkle-field-evolution">Complex Wrinkle Field Evolution&lt;/h2>
&lt;p>&lt;em>Zhen Chen (The University of Texas at Austin), Danny Kaufman (Adobe Research), Melina Skouras (Univ. Grenoble Alpes / Inria / CNRS), Etienne Vouga (The University of Texas at Austin)&lt;/em>&lt;/p>
&lt;figure id="figure-we-propose-complex-wrinkle-fields-cwf-s-a-new-discrete-wrinkle-model-that-enables-the-resolution-of-highly-detailed-wrinkle-patterns-on-coarse-base-mesh-geometry-the-cwf-representation-consists-of-a-positive-number-a-per-vertex-encoding-the-wrinkle-amplitude-a-one-form-ω-per-edge-to-model-wrinkle-frequency-and-a-complex-number-z-per-vertex-to-represent-wrinkle-phase-coupled-via-a-weak-variational-consistency-condition-ensuring-that-z-can-capture-singularities-while-also-being-as-compatible-with-ω-as-possible--31-we-equip-the-cwf-representation-with-a-novel-temporal-interpolation-algorithm--4-and-a-spatial-upsampling-method--5-that-together-allow-for-smooth-interpolation-between-wrinkle-patterns-represented-on-surfaces-by-cwf-s-leftmost-and-rightmost-column-and-base-mesh-independent-rendering-of-arbitrarily-high-resolution-wrinkle-patterns-together-these-contributions-make-it-possible-to-smoothly-evolve-wrinkle-patterns-between-two-prescribed-keyframes-middle-columns-with-automatic-merging-splitting-and-reconnection-of-wrinkles-as-necessary-via-smooth-sliding-of-singularities-across-the-surface-zoomed-in-figures-in-middle-columns">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="We propose Complex Wrinkle Fields (CWF s), a new discrete wrinkle model that enables the resolution of highly detailed wrinkle patterns on coarse base-mesh geometry. The CWF representation consists of a positive number a per vertex encoding the wrinkle amplitude, a one-form ω per edge to model wrinkle frequency, and a complex number ˜z per vertex to represent wrinkle phase, coupled via a weak variational consistency condition ensuring that ˜z can capture singularities while also being as compatible with ω as possible (§ 3.1). We equip the CWF representation with a novel temporal interpolation algorithm (§ 4) and a spatial upsampling method (§ 5) that together allow for smooth interpolation between wrinkle patterns represented on surfaces by CWF s (leftmost and rightmost column), and base-mesh-independent rendering of arbitrarily high-resolution wrinkle patterns. Together these contributions make it possible to smoothly evolve wrinkle patterns between two prescribed keyframes (middle columns) with automatic merging, splitting, and reconnection of wrinkles as necessary via smooth sliding of singularities across the surface (zoomed-in figures in middle columns). " srcset="
/post/23-07-31-siggraph2023/Chen2023_hu99dd2c25e008671c2d5a5f4a3f46a512_30874_8976b6c9414acc86a60084e3c1fd782c.webp 400w,
/post/23-07-31-siggraph2023/Chen2023_hu99dd2c25e008671c2d5a5f4a3f46a512_30874_23dacdd406eebdb9fc5e9d5216779463.webp 760w,
/post/23-07-31-siggraph2023/Chen2023_hu99dd2c25e008671c2d5a5f4a3f46a512_30874_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Chen2023_hu99dd2c25e008671c2d5a5f4a3f46a512_30874_8976b6c9414acc86a60084e3c1fd782c.webp"
width="720"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
We propose Complex Wrinkle Fields (CWF s), a new discrete wrinkle model that enables the resolution of highly detailed wrinkle patterns on coarse base-mesh geometry. The CWF representation consists of a positive number a per vertex encoding the wrinkle amplitude, a one-form ω per edge to model wrinkle frequency, and a complex number ˜z per vertex to represent wrinkle phase, coupled via a weak variational consistency condition ensuring that ˜z can capture singularities while also being as compatible with ω as possible (§ 3.1). We equip the CWF representation with a novel temporal interpolation algorithm (§ 4) and a spatial upsampling method (§ 5) that together allow for smooth interpolation between wrinkle patterns represented on surfaces by CWF s (leftmost and rightmost column), and base-mesh-independent rendering of arbitrarily high-resolution wrinkle patterns. Together these contributions make it possible to smoothly evolve wrinkle patterns between two prescribed keyframes (middle columns) with automatic merging, splitting, and reconnection of wrinkles as necessary via smooth sliding of singularities across the surface (zoomed-in figures in middle columns).
&lt;/figcaption>&lt;/figure>
&lt;p>We propose a new approach for representing wrinkles, designed to capture complex and detailed wrinkle behavior on coarse triangle meshes, called Complex Wrinkle Fields. Complex Wrinkle Fields consist of an almost-everywhere-unit complex-valued phase function over the surface; a frequency one-form; and an amplitude scalar, with a soft compatibility condition coupling the frequency and phase. We develop algorithms for interpolating between two such wrinkle fields, for visualizing them as displacements of a Loop-subdivided refinement of the base mesh, and for making smooth local edits to the wrinkle amplitude, frequency, and/or orientation. These algorithms make it possible, for the first time, to create and edit animations of wrinkles on triangle meshes that are smooth in space, evolve smoothly through time, include singularities along with their complex interactions, and that represent frequencies far finer than the surface resolution.&lt;/p>
&lt;p>&lt;a href="https://zhenchen-jay.github.io/uploads/CWF.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="coupling-conduction-convection-and-radiative-transfer-in-a-single-path-space-application-to-infrared-rendering">Coupling Conduction, Convection and Radiative Transfer in a Single Path-Space: Application to Infrared Rendering&lt;/h2>
&lt;p>&lt;em>Megane Bati, Stephane Blanco (Univ. Toulouse), Christophe Coustet, Vincent Eymet, Vincent Forest (Meso-Star), Richard Fournier (Univ. Toulouse), Jacques Gautrais (Univ. Toulouse and CNRS), Nicolas Mellado, Mathias Paulin (Univ. Toulouse), Benjamin Piaud (Meso-Star)&lt;/em>&lt;/p>
&lt;figure id="figure-we-propose-a-monte-carlo-approach-to-tackle-multiple-physics-with-a-single-algorithm-translating-their-coupling-into-a-single-path-space-composed-of-randomly-chained-sub-paths-for-each-physics-application-is-exemplified-with-heat-transfer-a-an-infrared-image-of-a-steady-state-thermal-exchanger-with-temperature-imposed-on-the-left-and-right-walls-b-monte-carlo-paths-alternate-between-heat-transfer-modes-here-conduction-and-radiation-c-a-huge-benefit-is-the-fast-production-of-transient-simulations-at-any-time-using-the-information-gathered-in-a-ie-from-only-one-monte-carlo-run-at-steady-state">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="We propose a Monte Carlo approach to tackle multiple physics with a single algorithm, translating their coupling into a single path-space composed of randomly chained sub-paths for each physics. Application is exemplified with heat transfer. (a) An infrared image of a steady state thermal exchanger, with temperature imposed on the left and right walls. (b) Monte Carlo paths alternate between heat-transfer modes (here conduction and radiation). (c) A huge benefit is the fast production of transient simulations, at any time, using the information gathered in (a), i.e. from only one Monte Carlo run at steady state. " srcset="
/post/23-07-31-siggraph2023/Bati2023_hu84965310d0506e2d17a54baf42b38b68_243366_e08d4c4b6c16bacfcae2a09910b4af2e.webp 400w,
/post/23-07-31-siggraph2023/Bati2023_hu84965310d0506e2d17a54baf42b38b68_243366_be96c724bf2390c9521759a5b504ac12.webp 760w,
/post/23-07-31-siggraph2023/Bati2023_hu84965310d0506e2d17a54baf42b38b68_243366_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Bati2023_hu84965310d0506e2d17a54baf42b38b68_243366_e08d4c4b6c16bacfcae2a09910b4af2e.webp"
width="760"
height="211"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
We propose a Monte Carlo approach to tackle multiple physics with a single algorithm, translating their coupling into a single path-space composed of randomly chained sub-paths for each physics. Application is exemplified with heat transfer. (a) An infrared image of a steady state thermal exchanger, with temperature imposed on the left and right walls. (b) Monte Carlo paths alternate between heat-transfer modes (here conduction and radiation). (c) A huge benefit is the fast production of transient simulations, at any time, using the information gathered in (a), i.e. from only one Monte Carlo run at steady state.
&lt;/figcaption>&lt;/figure>
&lt;p>In the past decades, Monte Carlo methods have shown their ability to solve PDEs, independently of the dimensionality of the integration domain and for different use-cases (e.g. light transport, geometry processing, physics simulation). Specifically, the path-space formulation of transport equations is a key ingredient to define tractable and scalable solvers, and we observe nowadays a strong interest in the definition of simulation systems based on Monte Carlo algorithms. We also observe that, when simulating combined physics (e.g. thermal rendering from a heat transfer simulation), there is a lack of coupled Monte Carlo algorithms allowing to solve all the physics at once, in the same path space, rather than combining several independent MC estimators, a combination that would make the global solver critically sensitive to the complexity of each simulation space. This brings to our proposal: a coupled, single path-space, Monte Carlo algorithm for efficient multi-physics problems solving. In this work, we combine our understanding and knowledge of Physics and Computer Graphics to demonstrate how to formulate and arrange different simulation spaces into a single path space. We define a tractable formalism for coupled heat transfer simulation using Monte Carlo, and we leverage the path-space construction to interactively compute multiple simulations with different conditions in the same scene, in terms of boundary conditions and observation time. We validate our proposal in the context of infrared rendering with different thermal simulation scenarios: e.g., room temperature simulation, visualization of heat paths within materials (detection of thermal bridges), heat diffusion capacity of thermal exchanger. We expect that our theoretical framework will foster collaboration and multidisciplinary studies. The perspectives this framework opens are detailed and we suggest a research agenda towards the resolution of coupled PDEs at the interface of Physics and Computer Graphics.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/UIjgiNymjyw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://hal.science/hal-04090428" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="textured-mesh-quality-assessment-large-scale-dataset-and-deep-learning-based-quality-metric">Textured Mesh Quality Assessment: Large-scale Dataset and Deep Learning-based Quality Metric&lt;/h2>
&lt;p>&lt;em>Yana Nehme, Johanna Delanoy, Florent Dupont, Jean-Philippe Farrugia (Univ Lyon, UCBL, CNRS, INSA Lyon, LIRIS, UMR5205), Patrick Le Callet (Nantes Universite, Ecole Centrale Nantes, CNRS, LS2N, UMR 6004), Guillaume Lavoue (Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE)&lt;/em>&lt;/p>
&lt;figure id="figure-a-geometry-and-color-spatial-information-and-b-visual-attention-complexity-for-the-selected-source-models">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="(a) Geometry and color spatial information and (b) visual attention complexity for the selected source models. " srcset="
/post/23-07-31-siggraph2023/Nehme2023_hub855d19a346a83ffc1b6f6e9abe80016_324891_7bc39a1ff4f61a485311b010e1c8ee12.webp 400w,
/post/23-07-31-siggraph2023/Nehme2023_hub855d19a346a83ffc1b6f6e9abe80016_324891_4f9ef59a8df25bf3dddd11c0d5c08b9e.webp 760w,
/post/23-07-31-siggraph2023/Nehme2023_hub855d19a346a83ffc1b6f6e9abe80016_324891_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Nehme2023_hub855d19a346a83ffc1b6f6e9abe80016_324891_7bc39a1ff4f61a485311b010e1c8ee12.webp"
width="760"
height="357"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
(a) Geometry and color spatial information and (b) visual attention complexity for the selected source models.
&lt;/figcaption>&lt;/figure>
&lt;p>Over the past decade, 3D graphics have become highly detailed to mimic the real world, exploding their size and complexity. Certain applications and device constraints necessitate their simplification and/or lossy compression, which can degrade their visual quality. Thus, to ensure the best Quality of Experience (QoE), it is important to evaluate the visual quality to accurately drive the compression and find the right compromise between visual quality and data size. In this work, we focus on subjective and objective quality assessment of textured 3D meshes. We first establish a large-scale dataset, which includes 55 source models quantitatively characterized in terms of geometric, color, and semantic complexity, and corrupted by combinations of 5 types of compression-based distortions applied on the geometry, texture mapping and texture image of the meshes. This dataset contains over 343k distorted stimuli. We propose an approach to select a challenging subset of 3000 stimuli for which we collected 148929 quality judgments from over 4500 participants in a large-scale crowdsourced subjective experiment. Leveraging our subject-rated dataset, a learning-based quality metric for 3D graphics was proposed. Our metric demonstrates state-of-the-art results on our dataset of textured meshes and on a dataset of distorted meshes with vertex colors. Finally, we present an application of our metric and dataset to explore the influence of distortion interactions and content characteristics on the perceived quality of compressed textured meshes.&lt;/p>
&lt;p>&lt;a href="https://arxiv.org/abs/2202.02397" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="variational-shape-reconstruction-via-quadric-error-metrics">Variational Shape Reconstruction via Quadric Error Metrics&lt;/h2>
&lt;p>&lt;em>Tong Zhao (Inria Sophia-Antipolis / Universite Cote d&amp;rsquo;Azur / LTCI, Telecom Paris), Laurent Buse, David Cohen-Steiner (Inria Sophia-Antipolis and Universite Cote d&amp;rsquo;Azur), Tamy Boubekeur, Jean-Marc Thiery (Adobe Research), Pierre Alliez (Inria Sophia-Antipolis and Universite Cote d&amp;rsquo;Azur)&lt;/em>&lt;/p>
&lt;figure id="figure-variational-shape-reconstruction-the-clustering-of-the-points-is-randomly-initialized-then-alternates-partitioning-and-generator-updating-some-generators-relocate-to-sharp-features-after-one-iteration-new-generators-are-then-added-the-clustering-converges-after-five-iterations-a-set-of-candidate-edges-is-derived-from-the-adjacency-between-clusters-and-candidate-facets-red-are-generated-the-output-mesh-is-reconstructed-via-a-constrained-binary-solver-that-selects-a-subset-of-the-red-facets">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Variational shape reconstruction. The clustering of the points is randomly initialized, then alternates partitioning and generator updating. Some generators relocate to sharp features after one iteration. New generators are then added. The clustering converges after five iterations. A set of candidate edges is derived from the adjacency between clusters, and candidate facets (red) are generated. The output mesh is reconstructed via a constrained binary solver that selects a subset of the red facets." srcset="
/post/23-07-31-siggraph2023/Zhao2023_hu42af5ecf5f79dbe7dfdad4aa9dd341cb_168617_e4a9ba29ac1bf8ebc6e22e86840c41b5.webp 400w,
/post/23-07-31-siggraph2023/Zhao2023_hu42af5ecf5f79dbe7dfdad4aa9dd341cb_168617_c15cb938484df3342f21a08cd5673d28.webp 760w,
/post/23-07-31-siggraph2023/Zhao2023_hu42af5ecf5f79dbe7dfdad4aa9dd341cb_168617_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Zhao2023_hu42af5ecf5f79dbe7dfdad4aa9dd341cb_168617_e4a9ba29ac1bf8ebc6e22e86840c41b5.webp"
width="530"
height="442"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Variational shape reconstruction. The clustering of the points is randomly initialized, then alternates partitioning and generator updating. Some generators relocate to sharp features after one iteration. New generators are then added. The clustering converges after five iterations. A set of candidate edges is derived from the adjacency between clusters, and candidate facets (red) are generated. The output mesh is reconstructed via a constrained binary solver that selects a subset of the red facets.
&lt;/figcaption>&lt;/figure>
&lt;p>Inspired by the strengths of quadric error metrics initially designed for mesh decimation, we propose a concise mesh reconstruction approach for 3D point clouds. Our approach proceeds by clustering the input points enriched with quadric error metrics, where the generator of each cluster is the optimal 3D point for the sum of its quadric error metrics. This approach favors the placement of generators on sharp features, and tends to equidistribute the error among clusters. We reconstruct the output surface mesh from the adjacency between clusters and a constrained binary solver. We combine our clustering process with an adaptive refinement driven by the error. Compared to prior art, our method avoids dense reconstruction prior to simplification and produces immediately an optimized mesh.&lt;/p>
&lt;p>&lt;a href="https://hal.science/3IA-COTEDAZUR/hal-04131765v1" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="somigliana-coordinates-an-elasticity-derived-approach-for-cage-deformation">Somigliana Coordinates: An Elasticity-derived Approach for Cage Deformation&lt;/h2>
&lt;p>&lt;em>Jiong Chen (Ecole Polytechnique), Fernando de Goes (Pixar Animation Studios), Mathieu Desbrun (Inria and Ecole Polytechnique)&lt;/em>&lt;/p>
&lt;figure id="figure-somigliana-coordinates-given-an-initial-cage-top-inset-and-its-deformed-pose-our-novel-cage-deformer-promotes-a-more-elastic-behavior-of-the-cage-deformation-than-previous-works-by-leveraging-an-elasticity-derived-matrix-weighted-combination-of-both-vertex-positions-and-face-normals-of-the-cage-a-poisson-ratio-𝜈-and-bulging-scale-𝛾-can-be-adjusted-to-offer-control-over-local-and-global-volume-change">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Somigliana coordinates. Given an initial cage (top inset) and its deformed pose, our novel cage deformer promotes a more elastic behavior of the cage deformation than previous works by leveraging an elasticity-derived matrix-weighted combination of both vertex positions and face normals of the cage. A Poisson ratio 𝜈 and bulging scale 𝛾 can be adjusted to offer control over local and global volume change." srcset="
/post/23-07-31-siggraph2023/Chen2023_hu0adf2dcb2860ad037672cb1a8b05efab_195171_23a0a4e89e3c5b74157bd83b6823ae2b.webp 400w,
/post/23-07-31-siggraph2023/Chen2023_hu0adf2dcb2860ad037672cb1a8b05efab_195171_5d59cb19498097398a7b0c91193e1311.webp 760w,
/post/23-07-31-siggraph2023/Chen2023_hu0adf2dcb2860ad037672cb1a8b05efab_195171_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Chen2023_hu0adf2dcb2860ad037672cb1a8b05efab_195171_23a0a4e89e3c5b74157bd83b6823ae2b.webp"
width="520"
height="537"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Somigliana coordinates. Given an initial cage (top inset) and its deformed pose, our novel cage deformer promotes a more elastic behavior of the cage deformation than previous works by leveraging an elasticity-derived matrix-weighted combination of both vertex positions and face normals of the cage. A Poisson ratio 𝜈 and bulging scale 𝛾 can be adjusted to offer control over local and global volume change.
&lt;/figcaption>&lt;/figure>
&lt;p>In this paper, we present a novel cage deformer based on elasticity-derived matrix-valued coordinates. In order to bypass the typical shearing artifacts and lack of volume control of existing cage deformers, we promote a more elastic behavior of the cage deformation by deriving our coordinates from the Somigliana identity, a boundary integral formulation based on the fundamental solution of linear elasticity. Given an initial cage and its deformed pose, the deformation of the cage interior is deduced from these Somigliana coordinates via a corotational scheme, resulting in a matrix-weighted combination of both vertex positions and face normals of the cage. Our deformer thus generalizes Green coordinates, while producing physically-plausible spatial deformations that are invariant under similarity transformations and with interactive bulging control. We demonstrate the efficiency and versatility of our method through a series of examples in 2D and 3D.&lt;/p>
&lt;video controls >
&lt;source src="https://jiongchen.github.io/files/somi-video.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://jiongchen.github.io/files/somi-paper.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="constraint-based-simulation-of-passive-suction-cups">Constraint-based Simulation of Passive Suction Cups&lt;/h2>
&lt;p>&lt;em>Antonin Bernardin, Univ. Rennes / INSA / IRISA / Inria), Paul Kry (McGill University), Sheldon Andrews (Ecole de technologie superieure), Christian Duriez (Inria / Univ. Lille / CNRS), Maud Marchal (Univ. Rennes / INSA / IRISA / Inria)&lt;/em>&lt;/p>
&lt;figure id="figure-the-monster-pop-up-toy-sticks-to-its-base-until-the-spring-forces-release-it-due-to-air-leakage-making-the-whole-structure-to-jump">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="The Monster pop-up toy sticks to its base until the spring forces release it due to air leakage, making the whole structure to jump." srcset="
/post/23-07-31-siggraph2023/Bernardin2023_hu1ef156b0be57381ad4a03fb9d01dabfd_172949_6848ed7477bd4084947563a4ba38779b.webp 400w,
/post/23-07-31-siggraph2023/Bernardin2023_hu1ef156b0be57381ad4a03fb9d01dabfd_172949_65e9441b98ce3af2f21d81153548e4ae.webp 760w,
/post/23-07-31-siggraph2023/Bernardin2023_hu1ef156b0be57381ad4a03fb9d01dabfd_172949_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Bernardin2023_hu1ef156b0be57381ad4a03fb9d01dabfd_172949_6848ed7477bd4084947563a4ba38779b.webp"
width="760"
height="244"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
The Monster pop-up toy sticks to its base until the spring forces release it due to air leakage, making the whole structure to jump.
&lt;/figcaption>&lt;/figure>
&lt;p>In this paper, we propose a physics-based model of suction phenomenon to achieve simulation of deformable objects like suction cups. Our model uses a constraint-based formulation to simulate the variations of pressure inside suction cups. The respective internal pressures are represented as pressure constraints which are coupled with anti-interpenetration and friction constraints. Furthermore, our method is able to detect multiple air cavities using information from collision detection. We solve the pressure constraints based on the ideal gas law while considering several cavity states. We test our model with a number of scenarios reflecting a variety of uses, for instance, a spring loaded jumping toy, a manipulator performing a pick and place task, and an octopus tentacle grasping a soda can. We also evaluate the ability of our model to reproduce the physics of suction cups of varying shapes, lifting objects of different masses, and sliding on a slippery surface. The results show promise for various applications such as the simulation in soft robotics and computer animation.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/PSKXglvD77I" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://inria.hal.science/hal-03869711/" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="mesogen-designing-procedural-on-surface-stranded-mesostructures">MesoGen: Designing Procedural On-surface Stranded Mesostructures&lt;/h2>
&lt;p>&lt;em>Elie Michel, Tamy Boubekeur (Adobe Research)&lt;/em>&lt;/p>
&lt;figure id="figure-we-propose-a-workflow-for-designing-rich-mesostructures-with-self-similarity-but-no-repetition-artifacts-our-method-is-based-on-wang-tiling-to-enable-fast-authoring-and-efficient-real-time-rendering">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="We propose a workflow for designing rich mesostructures, with self-similarity but no repetition artifacts. Our method is based on Wang tiling to enable fast authoring and efficient real-time rendering." srcset="
/post/23-07-31-siggraph2023/Michel2023_hu234445fd5bf9117d38de5295c8b1e7af_184189_2ada78d3e31abf0ce485db0b2562436e.webp 400w,
/post/23-07-31-siggraph2023/Michel2023_hu234445fd5bf9117d38de5295c8b1e7af_184189_b3d5cb25393d734eb4a2b16ebd2a8b09.webp 760w,
/post/23-07-31-siggraph2023/Michel2023_hu234445fd5bf9117d38de5295c8b1e7af_184189_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Michel2023_hu234445fd5bf9117d38de5295c8b1e7af_184189_2ada78d3e31abf0ce485db0b2562436e.webp"
width="760"
height="191"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
We propose a workflow for designing rich mesostructures, with self-similarity but no repetition artifacts. Our method is based on Wang tiling to enable fast authoring and efficient real-time rendering.
&lt;/figcaption>&lt;/figure>
&lt;p>Three-dimensional mesostructures enrich coarse macrosurfaces with complex features, which are 3D geometry with arbitrary topology in essence, but are expected to be self-similar with no tiling artifacts, just like texture-based material models. This is a challenging task, as no existing modeling tool provides the right constraints in the design phase to ensure such properties while maintaining real-time editing capabilities. In this paper, we propose MesoGen, a novel tile-centric authoring approach for the design of procedural mesostructures featuring non-periodic self-similarity while being represented as a compact and GPU-friendly model. We ensure by construction the continuity of the mesostructure: the user designs a set of atomic tiles by drawing 2D cross-sections on the interfaces between tiles, and selecting pairs of cross-sections to be connected as strands, i.e., 3D sweep surfaces. In parallel, a tiling engine continuously fills the shell space of the macrosurface with the so-defined tile set while ensuring that only matching interfaces are in contact. Moreover, the engine suggests to the user the addition of new tiles whenever the problem happens to be over-constrained. As a result, our method allows for the rapid creation of complex, seamless procedural mesostructure and is particularly adapted for wicker-like ones, often impossible to achieve with scattering-based mesostructure synthesis methods.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/AXDTo-JkECc" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://eliemichel.github.io/MesoGen/documents/michel23mesogen.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="fluid-solid-coupling-in-kinetic-two-phase-flow-simulation">Fluid-solid Coupling in Kinetic Two-phase Flow Simulation&lt;/h2>
&lt;p>&lt;em>Wei Li (Inria and Tencent Lightspeed Studios), Mathieu Desbrun (Inria and Ecole Polytechnique)&lt;/em>&lt;/p>
&lt;figure id="figure-key-drop-in-this-paper-we-propose-a-stable-and-efficient-kinetic-two-phase-flow-simulator-which-can-handle-complex-fluid-solid-coupling-like-a-skeleton-key-being-dropped-in-water-the-dynamics-of-the-bubbles-entrapped-by-the-fall-is-well-captured-as-the-insets-of-a-real-experiment-demonstrate">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Key Drop. In this paper, we propose a stable and efficient kinetic two-phase flow simulator which can handle complex fluid-solid coupling, like a skeleton key being dropped in water. The dynamics of the bubbles entrapped by the fall is well captured as the insets of a real experiment demonstrate." srcset="
/post/23-07-31-siggraph2023/Li2023_hu884feca0fdeb785fdf0a7749cd3e433f_151433_8d3af0a36c1f61c865dab29e1467dc82.webp 400w,
/post/23-07-31-siggraph2023/Li2023_hu884feca0fdeb785fdf0a7749cd3e433f_151433_51446ddf5702eb2350a7b169c4ddf10e.webp 760w,
/post/23-07-31-siggraph2023/Li2023_hu884feca0fdeb785fdf0a7749cd3e433f_151433_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Li2023_hu884feca0fdeb785fdf0a7749cd3e433f_151433_8d3af0a36c1f61c865dab29e1467dc82.webp"
width="760"
height="145"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Key Drop. In this paper, we propose a stable and efficient kinetic two-phase flow simulator which can handle complex fluid-solid coupling, like a skeleton key being dropped in water. The dynamics of the bubbles entrapped by the fall is well captured as the insets of a real experiment demonstrate.
&lt;/figcaption>&lt;/figure>
&lt;p>Real-life flows exhibit complex and visually appealing behaviors such as bubbling, splashing, glugging and wetting that simulation techniques in graphics have attempted to capture for years. While early approaches were not capable of reproducing multiphase flow phenomena due to their excessive numerical viscosity and low accuracy, kinetic solvers based on the lattice Boltzmann method have recently demonstrated the ability to simulate water-air interaction at high Reynolds numbers in a massively-parallel fashion. However, robust and accurate handling of fluid-solid coupling has remained elusive: be it for CG or CFD solvers, as soon as the motion of immersed objects is too fast or too sudden, pressures near boundaries and interfacial forces exhibit spurious oscillations leading to blowups. Built upon a phase-field and velocity-distribution based lattice-Boltzmann solver for multiphase flows, this paper spells out a series of numerical improvements in momentum exchange, interfacial forces, and two-way coupling to drastically reduce these typical artifacts, thus significantly expanding the types of fluid-solid coupling that we can efficiently simulate. We highlight the numerical benefits of our solver through various challenging simulation results, including comparisons to previous work and real footage.&lt;/p>
&lt;video controls >
&lt;source src="https://pages.saclay.inria.fr/mathieu.desbrun/Movies/LD23.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://pages.saclay.inria.fr/mathieu.desbrun/pubs/LD23.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="greil-crowds-crowd-simulation-with-deep-reinforcement-learning-and-examples">GREIL-Crowds: Crowd Simulation With Deep Reinforcement Learning and Examples&lt;/h2>
&lt;p>&lt;em>Panayiotis Charalambous (CYENS - Centre of Excellence), Julien Pettre (Univ Rennes, Inria, CNRS, IRISA), Vassilis Vassiliades (University of Cyprus), Yiorgos Chrysanthou (CYENS - Centre of Excellence and University of Cyprus), Nuria Pelechano (Universitat Politecnica de Catalunya)&lt;/em>&lt;/p>
&lt;figure id="figure-results-from-the-same-simulation---all-agents-use-the-pedestrian-controller-the-policy-is-able-to-capture-and-simulate-simultaneously-a-d-social-groups-flocks-individuals-mixed-behaviours-e-f-and-various-behaviors-such-as-agents-suddenly-standing-still-joiningleaving-groups-etc">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Results from the same simulation - all agents use the pedestrian controller. The policy is able to capture and simulate simultaneously (a-d) social groups, flocks, individuals, mixed behaviours; (e-f) and various behaviors such as agents suddenly standing still, joining/leaving groups, etc. " srcset="
/post/23-07-31-siggraph2023/Charalambous2023_hu79748757eaefa5accd1610b59ba6b2df_3266474_2ceab80dd7366ef663b8e2151a161813.webp 400w,
/post/23-07-31-siggraph2023/Charalambous2023_hu79748757eaefa5accd1610b59ba6b2df_3266474_564c60c79c2a7a2b6d633a14241d80e1.webp 760w,
/post/23-07-31-siggraph2023/Charalambous2023_hu79748757eaefa5accd1610b59ba6b2df_3266474_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Charalambous2023_hu79748757eaefa5accd1610b59ba6b2df_3266474_2ceab80dd7366ef663b8e2151a161813.webp"
width="760"
height="470"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Results from the same simulation - all agents use the pedestrian controller. The policy is able to capture and simulate simultaneously (a-d) social groups, flocks, individuals, mixed behaviours; (e-f) and various behaviors such as agents suddenly standing still, joining/leaving groups, etc.
&lt;/figcaption>&lt;/figure>
&lt;p>Simulating crowds with realistic behaviors is a difficult but very important task for a variety of applications. Quantifying how a person balances between different conflicting criteria such as goal seeking,collision avoidance and moving within a group is not intuitive, especially if we consider that behaviors differ largely between people. Inspired by recent advances in Deep Reinforcement Learning, we propose Guided REinforcement Learning (GREIL) Crowds, a method that learns a model for pedestrian behaviors which is guided by reference crowd data. The model successfully captures behaviors such as goal seeking, being part of consistent groups without the need to define explicit relationships and wandering around seemingly without a specific purpose. Two fundamental concepts are important in achieving these results: (a) the per agent state representation and (b) the reward function. The agent state is a temporal representation of the situation around each agent. The reward function is based on the idea that people try to move in situations/states in which they feel comfortable in. Therefore, in order for agents to stay in a comfortable state space, we first obtain a distribution of states extracted from real crowd data; then we evaluate states based on how much of an outlier they are compared to such a distribution. We demonstrate that our system can capture and simulate many complex and subtle crowd interactions in varied scenarios. Additionally, the proposed method generalizes to unseen situations, generates consistent behaviors and does not suffer from the limitations of other data-driven and reinforcement learning approaches.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/VNPUJJW4crM" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://veupnea.github.io/publication_pages/siggraph23-greil.html" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="3d-gaussian-splatting-for-real-time-radiance-field-rendering">3D Gaussian Splatting for Real-Time Radiance Field Rendering&lt;/h2>
&lt;p>&lt;em>Bernhard Kerbl, Georgios Kopanas (Inria and Universite Cote d&amp;rsquo;Azur), Thomas Leimkuhler (MPI Informatik), George Drettakis (Inria and Universite Cote d&amp;rsquo;Azur)&lt;/em>&lt;/p>
&lt;figure id="figure-our-method-achieves-real-time-rendering-of-radiance-fields-with-quality-that-equals-the-previous-method-with-the-best-quality-barron-et-al--2022-while-only-requiring-optimization-times-competitive-with-the-fastest-previous-methods-fridovich-keil-and-yu-et-al--2022-müller-et-al-2022-key-to-this-performance-is-a-novel-3d-gaussian-scene-representation-coupled-with-a-real-time-differentiable-renderer-which-offers-significant-speedup-to-both-scene-optimization-and-novel-view-synthesis-note-that-for-comparable-training-times-to-instantngp-müller-et-al-2022-we-achieve-similar-quality-to-theirs-while-this-is-the-maximum-quality-they-reach-by-training-for-51min-we-achieve-state-of-the-art-quality-even-slightly-better-than-mip-nerf360-barron-et-al--2022">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Our method achieves real-time rendering of radiance fields with quality that equals the previous method with the best quality [Barron et al . 2022], while only requiring optimization times competitive with the fastest previous methods [Fridovich-Keil and Yu et al . 2022; Müller et al. 2022]. Key to this performance is a novel 3D Gaussian scene representation coupled with a real-time differentiable renderer, which offers significant speedup to both scene optimization and novel view synthesis. Note that for comparable training times to InstantNGP [Müller et al. 2022], we achieve similar quality to theirs; while this is the maximum quality they reach, by training for 51min we achieve state-of-the-art quality, even slightly better than Mip-NeRF360 [Barron et al . 2022]." srcset="
/post/23-07-31-siggraph2023/Kerbl2023_huc22b53f1cf87cbeb04c2739cff4b3c3d_504750_c4fbd3e130d994b2dec9cae0b4a54099.webp 400w,
/post/23-07-31-siggraph2023/Kerbl2023_huc22b53f1cf87cbeb04c2739cff4b3c3d_504750_dda269068874c0caf8f27acec50b580a.webp 760w,
/post/23-07-31-siggraph2023/Kerbl2023_huc22b53f1cf87cbeb04c2739cff4b3c3d_504750_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Kerbl2023_huc22b53f1cf87cbeb04c2739cff4b3c3d_504750_c4fbd3e130d994b2dec9cae0b4a54099.webp"
width="760"
height="179"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Our method achieves real-time rendering of radiance fields with quality that equals the previous method with the best quality [Barron et al . 2022], while only requiring optimization times competitive with the fastest previous methods [Fridovich-Keil and Yu et al . 2022; Müller et al. 2022]. Key to this performance is a novel 3D Gaussian scene representation coupled with a real-time differentiable renderer, which offers significant speedup to both scene optimization and novel view synthesis. Note that for comparable training times to InstantNGP [Müller et al. 2022], we achieve similar quality to theirs; while this is the maximum quality they reach, by training for 51min we achieve state-of-the-art quality, even slightly better than Mip-NeRF360 [Barron et al . 2022].
&lt;/figcaption>&lt;/figure>
&lt;p>Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates.&lt;/p>
&lt;p>We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (≥ 100 fps) novel-view synthesis at 1080p resolution.&lt;/p>
&lt;p>First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/T_kXY43VZnk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/3d_gaussian_splatting_high.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank" rel="noopener">&lt;em>Project page&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="pcbend-light-up-your-3d-shapes-with-foldable-circuit-boards">PCBend: Light Up Your 3D Shapes With Foldable Circuit Boards&lt;/h2>
&lt;p>&lt;em>Marco Freire* (Universite de Lorraine / CNRS / Inria), Manas Bhargava* (ISTA), Camille Schreck, Pierre-Alexandre Hugron (Universite de Lorraine / CNRS / Inria), Bernd Bickel (ISTA), Sylvain Lefebvre (Universite de Lorraine / CNRS / Inria) (* Joint first authors)&lt;/em>&lt;/p>
&lt;figure id="figure-starting-from-a-3d-mesh-our-method-automatically-generates-design-files-to-produce-an-on-surface-display-composed-of-individually-addressable-rgb-leds-the-circuit-board-is-manufactured-through-standard-pcb-production-services-including-component-soldering-the-user-then-folds-the-fabricated-board-back-onto-a-3d-printed-support-the-final-model-becomes-a-curved-display-onto-which-intricate-light-patterns-can-be-programmed-in-a-shader-like-manner">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Starting from a 3D mesh our method automatically generates design files to produce an on-surface display composed of individually addressable RGB LEDs. The circuit board is manufactured through standard PCB production services, including component soldering. The user then folds the fabricated board back onto a 3D printed support. The final model becomes a curved display, onto which intricate light patterns can be programmed in a shader-like manner." srcset="
/post/23-07-31-siggraph2023/Freire2023_hu607ffb6b7b8d3832e4c4abdd43f7c096_1579071_72bd301b3ef90bf013071be9ddf286c2.webp 400w,
/post/23-07-31-siggraph2023/Freire2023_hu607ffb6b7b8d3832e4c4abdd43f7c096_1579071_0841e7f95ef699e33f22341f85bd8147.webp 760w,
/post/23-07-31-siggraph2023/Freire2023_hu607ffb6b7b8d3832e4c4abdd43f7c096_1579071_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Freire2023_hu607ffb6b7b8d3832e4c4abdd43f7c096_1579071_72bd301b3ef90bf013071be9ddf286c2.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Starting from a 3D mesh our method automatically generates design files to produce an on-surface display composed of individually addressable RGB LEDs. The circuit board is manufactured through standard PCB production services, including component soldering. The user then folds the fabricated board back onto a 3D printed support. The final model becomes a curved display, onto which intricate light patterns can be programmed in a shader-like manner.
&lt;/figcaption>&lt;/figure>
&lt;p>We propose a computational design approach for covering a surface with individually addressable RGB LEDs, effectively forming a low-resolution surface screen. To achieve a low-cost and scalable approach, we propose creating designs from flat PCB panels bent in-place along the surface of a 3D printed core. Working with standard rigid PCBs enables the use of established PCB manufacturing services, allowing the fabrication of designs with several hundred LEDs. Our approach optimizes the PCB geometry for folding, and then jointly optimizes the LED packing, circuit and routing, solving a challenging layout problem under strict manufacturing requirements. Unlike paper, PCBs cannot bend beyond a certain point without breaking. Therefore, we introduce parametric cut patterns acting as hinges, designed to allow bending while remaining compact. To tackle the joint optimization of placement, circuit and routing, we propose a specialized algorithm that splits the global problem into one sub-problem per triangle, which is then individually solved. Our technique generates PCB blueprints in a completely automated way. After being fabricated by a PCB manufacturing service, the boards are bent and glued by the user onto the 3D printed support. We demonstrate our technique on a range of physical models and virtual examples, creating intricate surface light patterns from hundreds of LEDs.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/nJspqdpyWq4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://manas-avi.github.io/publications/2023/PCBend/FoldableElectronics-2023-camera-ready.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://visualcomputing.ist.ac.at/publications/2023/PLUY3SWFCB/" target="_blank" rel="noopener">&lt;em>Project page&lt;/em>&lt;/a>&lt;/p>
&lt;h2 id="fast-gpu-based-two-way-continuous-collision-handling">Fast GPU-based Two-way Continuous Collision Handling&lt;/h2>
&lt;p>&lt;em>Tianyu Wang (FaceUnity), Jiong Chen (Ecole Polytechnique), Dongping Li, Xiaowei Liu (FaceUnity), Huamin Wang (Style3D), Kun Zhou (Zhejiang University)&lt;/em>&lt;/p>
&lt;figure id="figure-knotting-the-bow-knot-example-on-the-top-with-142k-triangles-and-the-reef-knot-example-on-the-bottom-with-71k-triangles-are-presented-in-this-work-we-develop-a-two-way-method-for-safe-and-fast-collision-handling-in-deformable-body-simulation-thanks-to-this-method-our-simulator-can-robustly-handle-complex-collision-contacts-in-these-two-examples-at-4-to-17-fps-and-10-to-21-fps-respectively">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Knotting. The bow knot example (on the top, with 142K triangles) and the reef knot example (on the bottom, with 71K triangles) are presented. In this work, we develop a two-way method for safe and fast collision handling in deformable body simulation. Thanks to this method, our simulator can robustly handle complex collision contacts in these two examples at 4 to 17 FPS and 10 to 21 FPS respectively." srcset="
/post/23-07-31-siggraph2023/Wang2023_hu69823277c1dcb031b5bd621e1a13ecc8_528044_f396f3e5b544b8db768c92875f90fca7.webp 400w,
/post/23-07-31-siggraph2023/Wang2023_hu69823277c1dcb031b5bd621e1a13ecc8_528044_6e919c3166ff63a6527f0b1c9454a3e8.webp 760w,
/post/23-07-31-siggraph2023/Wang2023_hu69823277c1dcb031b5bd621e1a13ecc8_528044_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-07-31-siggraph2023/Wang2023_hu69823277c1dcb031b5bd621e1a13ecc8_528044_f396f3e5b544b8db768c92875f90fca7.webp"
width="760"
height="354"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Knotting. The bow knot example (on the top, with 142K triangles) and the reef knot example (on the bottom, with 71K triangles) are presented. In this work, we develop a two-way method for safe and fast collision handling in deformable body simulation. Thanks to this method, our simulator can robustly handle complex collision contacts in these two examples at 4 to 17 FPS and 10 to 21 FPS respectively.
&lt;/figcaption>&lt;/figure>
&lt;p>Step-and-project is a popular method to simulate non-penetrating deformable bodies in physically-based animation. The strategy is to first integrate the system in time without considering contacts and then resolve potential intersections, striking a good balance between plausibility and efficiency. However, existing methods can be defective and unsafe when using large time steps, taking risks of failure or demanding repetitive collision testing and resolving that severely degrade performance. In this paper, we propose a novel two-way method for fast and reliable continuous collision handling. Our method launches an optimization from both ends of the intermediate time-integrated state and the previous intersection-free state. It progressively generates a piecewise linear path and eventually obtains a feasible solution for the next time step. The algorithm efficiently alternates between a forward step and a backward step until the result is conditionally converged. Thanks to a set of unified volume-based contact constraints, our method offers flexible and reliable handling of various codimensional deformable bodies, including volumetric bodies, cloth, hair and sand. Experimental results demonstrate the safety, robustness, physical fidelity and numerical efficiency of our method, making it particularly suitable for scenarios involving large deformations or large time steps.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/6T52DU2iFu0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;a href="https://wanghmin.github.io/Wang-2023-FGB/Wang-2023-FGB.pdf" target="_blank" rel="noopener">&lt;em>Full paper&lt;/em>&lt;/a>&lt;/p></description></item><item><title>25èmes journées du Groupe de Travail Animation et Simulation</title><link>https://gdr-igrv.fr/event/journee_gtas2023/</link><pubDate>Thu, 06 Jul 2023 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtas2023/</guid><description>&lt;p>Les prochaines journées du Groupe de Travail Animation et Simulation du GDR IGRV auront lieu du jeudi 6 juillet 2023 au vendredi 7 juillet 2023, à Paris, sur le campus Pierre et Marie Curie (Jussieu).&lt;/p>
&lt;p>L’objet des Journées du GT AS est triple. Il s’agit :&lt;/p>
&lt;ul>
&lt;li>de partager les avancées de la recherche en animation et simulation,&lt;/li>
&lt;li>de dresser le paysage du domaine en France, et&lt;/li>
&lt;li>d’en préciser les perspectives et les thématiques émergentes.&lt;/li>
&lt;/ul>
&lt;p>Cette année, plusieurs présentations de &lt;strong>travaux et résultats récents&lt;/strong> aborderont des thèmes diversifiés tels que l&amp;rsquo;analyse, la synthèse et l&amp;rsquo;édition de mouvement, la modélisation et la simulation de phénomènes naturels, la capture de mouvements faciaux et du regard, la modélisation et l&amp;rsquo;animation faciale, la synthèse de gestes liés à la prosodie, les aspects multimodaux et multisensoriels dans l&amp;rsquo;animation, l&amp;rsquo;évolution des techniques de motion capture par vidéo, ou encore la synthèse de mouvements de langue des signes.&lt;/p>
&lt;p>Avec un &lt;strong>spectre plus large&lt;/strong>, plusieurs équipes présenteront un panorama pluriannuel de leur thématiques de recherche et de leurs évolutions, ainsi que des avancées de projets collaboratifs auxquelles elles contribuent.&lt;/p>
&lt;p>Les Journées sont également bien sûr l’occasion d’&lt;strong>échanges et de débats scientifiques&lt;/strong>. Deux thèmes focus ont été retenus pour cette année :&lt;/p>
&lt;ul>
&lt;li>les problématiques liées à l&amp;rsquo;animation et la simulation de personnages, incluant par exemple, les agents conversationnels ou les questions de style ou d’expression dans le mouvement humain,&lt;/li>
&lt;li>les questions relatives à l’enseignement de l’animation et de la simulation et l’usage de l’AS pour la pédagogie d’autres disciplines.&lt;/li>
&lt;/ul>
&lt;p>Enfin, l’ensemble des participants s’attacheront à mettre à jour les éléments prospectifs du domaine : nouveaux sujets, thèmes émergents, perspectives, points clés.&lt;/p>
&lt;p>L’inscription aux Journées est gratuite mais obligatoire – merci de prendre contact avec les coordinateurs du GT pour obtenir le lien d&amp;rsquo;inscription.&lt;/p>
&lt;h2 id="lieu">Lieu&lt;/h2>
&lt;blockquote>
&lt;p>Salle 304, acces par la tour 65&lt;br>
Sorbonne Université - campus Marie et Pierre CURIE&lt;br>
4 Pl. Jussieu, 75005 Paris&lt;/p>
&lt;/blockquote>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/event/journee_gtas2023/acces_huf85e0e203c1f5be2efbe9b4c84f8dea6_191411_097433a0aa645aa6eafd24086a019832.webp 400w,
/event/journee_gtas2023/acces_huf85e0e203c1f5be2efbe9b4c84f8dea6_191411_1372c5627c32c7998e8a0dc620a9cd00.webp 760w,
/event/journee_gtas2023/acces_huf85e0e203c1f5be2efbe9b4c84f8dea6_191411_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/event/journee_gtas2023/acces_huf85e0e203c1f5be2efbe9b4c84f8dea6_191411_097433a0aa645aa6eafd24086a019832.webp"
width="100%"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h2 id="programme-prévisionnel">Programme Prévisionnel&lt;/h2>
&lt;h3 id="jeudi-6-juillet-2023">Jeudi 6 juillet 2023&lt;/h3>
&lt;ul>
&lt;li>10h : Accueil, salle 304&lt;/li>
&lt;li>10h - 12h30 : Atelier GRETA, animé par l&amp;rsquo;équipe PIRoS&lt;/li>
&lt;li>12h30 - 13h30 : Repas au CROUS, offert par le GDR aux 15 premiers inscrits&lt;/li>
&lt;li>13h30 : Accueil salle 304 avec café, rafraichissements et macarons&lt;/li>
&lt;li>13h55 - 14h00 : Ouverture des Journées&lt;/li>
&lt;li>14h - 15h30 : Présentations - Session 1
&lt;ul>
&lt;li>Maintaining 2D Delaunay triangulations on the GPU for proximity queries of moving points, B. Crespin, H. Porro, N. Hitschfeld-Kahler, C. Navarro, F. Carter, U. de Limoges, U. de Chile, U. Austral de Chile.&lt;/li>
&lt;li>Inferring the routes of prehistoric humans, Adrien RAMANANA RAHARY, École polytechnique, Mylène LORRE, Université de Perpignan Via Domitia, UMR HNHP, Sophie GRÉGOIRE, Université de Perpignan Via Domitia, UMR HNH, Marie-Paule CANI, École polytechnique.&lt;/li>
&lt;li>A validated efficient membrane model for peannaceous bird feathers, Jean Jouve (&lt;a href="http://www.jeanjouve.lautre.net/%29" target="_blank" rel="noopener">http://www.jeanjouve.lautre.net/)&lt;/a>, Victor Romero (&lt;a href="http://elan.inrialpes.fr/people/vromerog/%29" target="_blank" rel="noopener">http://elan.inrialpes.fr/people/vromerog/)&lt;/a>, Rahul Narain (&lt;a href="https://www.cse.iitd.ac.in/~narain/%29" target="_blank" rel="noopener">https://www.cse.iitd.ac.in/~narain/)&lt;/a>, Theodore Kim (&lt;a href="http://www.tkim.graphics/" target="_blank" rel="noopener">http://www.tkim.graphics/&lt;/a>) et Florence Bertails-Descoubes (&lt;a href="http://elan.inrialpes.fr/people/bertails/%29" target="_blank" rel="noopener">http://elan.inrialpes.fr/people/bertails/)&lt;/a>, University Grenoble Alpes Inria, CNRS, Grenoble INP, LJK.&lt;/li>
&lt;li>Interactions virtuelles main/objet basées simulation physique, Mohammed-Bashir Mahdi, Erwan Guillou, Alexandre Meyer, Saida Bouakaz, équipe SAARA, LIRIS.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>15h30 - 15h45 : Pause café&lt;/li>
&lt;li>15h45 - 17h : Présentations et discussions sur l&amp;rsquo;“Enseignement de l’AS et avec l’AS” - Session 2
&lt;ul>
&lt;li>Usage de l’AS en enseignement et enseignement de l’AS dans le contexte du projet pédagogique &amp;ldquo;apprentissage enactif&amp;rdquo; de l’IDEX Université Grenoble Alpes, Nicolas Castagné, Florence Marchi.&lt;/li>
&lt;li>Utilisation de Processing pour l’enseignement, Benoit Crespin.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>16h30 - 16h55 : Présentations - Session 3
&lt;ul>
&lt;li>Who said GPU and water do not mix? (plus other excerpts from SIG 23) Wei Li and Mathieu Desbrun - Inria Saclay and LIX.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>17h - 19h : Moment artistique et démonstrations
&lt;ul>
&lt;li>Introduction&lt;/li>
&lt;li>Motion In Style, Caroline Larboulette (Université Bretagne Sud, équipe EXPRESSION de l&amp;rsquo;IRISA) et Laura Pouppeville (Artiste Visuelle).&lt;/li>
&lt;li>VR interaction with deep RL characters through a physics simulation : A Demo, Paul Boursin°, James Burness*, Marie-Paule Cani°, James Gain* - °Labo LIX, Ecole Polytechnique et CNRS, et *Cape Town University.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>19h: Social event offert par le GDR / CNRS&lt;/li>
&lt;/ul>
&lt;h3 id="vendredi-7-juillet-2023">Vendredi 7 juillet 2023&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>9h : Accueil, salle 304&lt;/p>
&lt;/li>
&lt;li>
&lt;p>9h -10h30 : Présentations et discussions - Session 4 - focus “avatars”&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Agents Sociaux Interactifs, modélisation et interaction, Catherine Pelachaud, équipe PIRoS de l&amp;rsquo;ISIR.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MAAIP: Multi-Agent Adversarial Interaction Priors for imitation from fighting demonstrations for physics-based characters, Mohamed Younes, Ewa Kijak, Simon Malinowski, Richard Kulpa, Franck Multon. MimeTIC &amp;amp; LinkMedia, IRISA/Inria Rennes.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Virtual agents, perception and social interactions: human behaviour studies in virtual reality, Pierre Raimbaud, Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, France.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>10h30 - 10h45 - Pause café&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10h45-11h35 : Présentations - Session 5&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Randomly stacked open cylindrical shells as functional mechanical energy absorber, Emile Hohnadel 1, Tomohiko Sano 2, Toshiyuki Kawata 2, Thibaut Métivet 1, Florence Bertails-Descoubes 1, 1 INRIA, CNRS, UGA, INP, LJK, France, 2 Department of Mechanical Engineering, Keio University, Yokohama, 2230061, Kanagawa, Japan.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Supporting Perception of Spatiality in Dance in Augmented Reality. Manon Vialle, Sarah Fdili Alaoui, Mélina Skouras, Elisabeth Schwartz.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>11h35 - 12h30 : Discussions “Prospectives”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>12h30 - 13h30 : Repas au CROUS, offert par le GDR aux 15 premiers inscrits&lt;/p>
&lt;/li>
&lt;li>
&lt;p>13h30 : Fin des journées&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Journées du GT GDMM 2023</title><link>https://gdr-igrv.fr/event/journee_gtgdmm2023/</link><pubDate>Thu, 06 Jul 2023 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtgdmm2023/</guid><description>&lt;h2 id="dates-importantes">DATES IMPORTANTES&lt;/h2>
&lt;p>Proposition d&amp;rsquo;exposé (titre et résumé) : 15/06/2023&lt;/p>
&lt;p>Inscription : 20/06/2023&lt;/p>
&lt;p>Journée du GT-GDMM : les 6 et 7 Juillet 2023&lt;/p>
&lt;h2 id="gdmm">GDMM&lt;/h2>
&lt;h3 id="la-géométrie-discrète">La géométrie discrète&lt;/h3>
&lt;p>Le contexte de la géométrie discrète s’intègre dans le cadre général de la modélisation et l’analyse géométrique et topologique d’objets définis sur des structures régulières (ex. des grilles de pixels ou de voxels) ou combinatoires (graphes, cartes, etc.). Généralement, les axiomes et propriétés de la géométrie euclidienne classique ne sont plus valides lorsque l’on considère des ensembles de pixels. La définition de concepts et notions adaptés à des structures discrètes, mais néanmoins compatibles avec les concepts et notions continus, est alors requise. L’originalité de cette approche réside dans le fait qu’en exploitant les propriétés du support sur lequel sont décrits les objets, nous pouvons obtenir des algorithmes efficaces, certifiés et précis pour répondre à des problèmes de caractérisation géométrique ou topologique d’objets discrets (2D, 3D, nD, etc.). Le caractère discret des données à traiter, et donc l’utilité de l’approche discrète, se retrouvent dans de nombreux contextes applicatifs (analyse et traitements d’images, imagerie médicale, ingénierie des matériaux, etc.).&lt;/p>
&lt;h3 id="la-morphologie-mathématique">La morphologie mathématique&lt;/h3>
&lt;p>La morphologie mathématique est une théorie essentiellement non-linéaire, utilisée en particulier en analyse d’images, dont le but est l&amp;rsquo;étude des objets en fonction de leur forme, de leur taille, des relations avec leur voisinage (en particulier topologiques), de leur texture, et de leurs niveaux de gris ou de leur couleur. Par les transformations qu’elle propose, elle se situe à différents niveaux du traitement d’images (filtrage, segmentation, mesures, analyse de texture) et fournit ainsi des outils pour la reconnaissance des formes. La morphologie mathématique, développée à l’origine pour l&amp;rsquo;étude des matériaux poreux, trouve maintenant ses applications dans de nombreux domaines du traitement d’images, aussi bien 2D que 3D, en biologie et cytologie quantitative, en imagerie médicale, en imagerie aérienne et satellitaire, en robotique et vision par ordinateur, en contrôle industriel non destructif, dans les études sur les documents et les œuvres d’art. Hors du domaine du traitement des images, on trouve des applications par exemple en analyse de données, ou encore en théorie des jeux.&lt;/p>
&lt;h2 id="comité-dorganisation">COMITÉ D&amp;rsquo;ORGANISATION&lt;/h2>
&lt;p>Yukiko Kenmochi (CNRS), Caroline Petitjean (Université de Rouen Normandie), Luc Brun (ENSICAEN), Sébastien Fourey (ENSICAEN), Olivier Lézoray (Université de Caen Normandie)&lt;/p></description></item><item><title>Journée GT Rendu 2023</title><link>https://gdr-igrv.fr/event/journee_gtrendu2023/</link><pubDate>Fri, 23 Jun 2023 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrendu2023/</guid><description>&lt;p>Bonjour à tous,&lt;/p>
&lt;p>La date du GT rendu sera finalement le 23 juin dans les locaux d&amp;rsquo;Adobe à Paris.&lt;/p>
&lt;p>Je vous remets toutes les informations nécessaires ci-dessous.&lt;br>
Encore désolé pour le report. On espère vous voir nombreux et nombreuses.&lt;/p>
&lt;p>George &amp;amp; Romain&lt;/p>
&lt;p>La liste des participants sera transmise à Adobe 3 jours avant le début du GT et une pièce d&amp;rsquo;identité vous sera demandée à l&amp;rsquo;entrée.&lt;/p>
&lt;p>Venez faire vivre ces journées en contribuant ou simplement pour rencontrer et discuter avec la communauté graphique française !
Les thèmes abordés peuvent être variés pour aggrémenter les discussions et avoir un aperçu des activités françaises dans le domaine du rendu :&lt;/p>
&lt;ul>
&lt;li>travaux actuels, aboutis ou non, publiés ou non&lt;/li>
&lt;li>tours d&amp;rsquo;horizons sur des thèmes/approches/outils émergents&lt;/li>
&lt;li>travaux d&amp;rsquo;une équipe de recherche sur les dernières années&lt;/li>
&lt;li>etc.&lt;/li>
&lt;/ul>
&lt;p>** INSCRIPTIONS **
Pour assister aux présentations, merci d&amp;rsquo;ajouter votre prénom/nom/organisme dans ce framapad :
&lt;a href="https://mypads2.framapad.org/p/gt-rendu-xyvob9ol" target="_blank" rel="noopener">https://mypads2.framapad.org/p/gt-rendu-xyvob9ol&lt;/a>
La liste des participants sera transmise à Adobe 3 jours avant le début du GT et une pièce d&amp;rsquo;identité vous sera demandée à l&amp;rsquo;entrée.&lt;/p>
&lt;p>** CONTRIBUTIONS **
Pour présenter, envoyez un email à George et moi même contenant [GT Rendu] dans le sujet, avec les informations suivantes :&lt;/p>
&lt;ul>
&lt;li>Prénom, nom, organisme de l&amp;rsquo;orateur&lt;/li>
&lt;li>Titre de la présentation&lt;/li>
&lt;li>Eventuellement un lien vers une page web s&amp;rsquo;il s&amp;rsquo;agit d&amp;rsquo;un travail déjà publié/diffusé.&lt;/li>
&lt;/ul>
&lt;p>** ADRESSE **
Adobe, 94-96 Rue Lauriston, 75016 Paris
Salle « Moulin Rouge », au Rez-de-Chaussée, accessible depuis l’atrium&lt;/p></description></item><item><title>Journée Visu 2023</title><link>https://gdr-igrv.fr/event/journee_visu2023/</link><pubDate>Thu, 22 Jun 2023 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_visu2023/</guid><description>&lt;p>Benjamin Bach, chercheur à l&amp;rsquo;Université d&amp;rsquo;Edimbourg, introduira la journée par un exposé sur ses recherches portant sur la conception de visualisations interactives pour faciliter l&amp;rsquo;exploration, la communication et la compréhension des données.&lt;/p>
&lt;h2 id="soumissions">Soumissions&lt;/h2>
&lt;p>Nous sollicitons des soumissions sur résumé qui présentent des travaux originaux. Merci de nous faire parvenir votre résumé par e-mail à &lt;a href="mailto:visu2023@inria.fr">visu2023@inria.fr&lt;/a>. La date limite de soumission est fixée au vendredi 12 mai 2023. Les notifications d’acceptation seront envoyées le vendredi 26 mai 2023.&lt;/p>
&lt;p>Les modalités de soumission sont indiquées sur le site &lt;a href="https://journee-visu.github.io/2023/#cfp" target="_blank" rel="noopener">https://journee-visu.github.io/2023/#cfp&lt;/a>.&lt;/p>
&lt;h2 id="inscriptions">Inscriptions&lt;/h2>
&lt;p>La journée Visu 2023 est gratuite et ouverte à tous dans la limite des capacités d&amp;rsquo;accueil. L’inscription est obligatoire.&lt;/p>
&lt;p>Inscriptions jusqu&amp;rsquo;au samedi 27 mai 2023 sur: &lt;a href="https://journee-visu.github.io/2023/#inscription" target="_blank" rel="noopener">https://journee-visu.github.io/2023/#inscription&lt;/a>&lt;/p>
&lt;h2 id="organisateur-et-organisatrice">Organisateur et organisatrice&lt;/h2>
&lt;p>Florent Cabric (AVIZ team, INRIA)
Vanessa Peña-Araya (ILDA team, INRIA)&lt;/p>
&lt;p>Cette journée est financée par l&amp;rsquo;INRIA, le LISN, Kitware et le CNRS via le GDR IG-RV.&lt;/p>
&lt;p>Plus d&amp;rsquo;informations : &lt;a href="https://journee-visu.github.io/2023" target="_blank" rel="noopener">https://journee-visu.github.io/2023&lt;/a>
Pour toute question : &lt;a href="mailto:visu2023@inria.fr">visu2023@inria.fr&lt;/a>&lt;/p></description></item><item><title>Hommage à Jean-Marc Chassery</title><link>https://gdr-igrv.fr/post/23-06-17-hommage-jm-chassery/</link><pubDate>Sat, 17 Jun 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/23-06-17-hommage-jm-chassery/</guid><description>&lt;p>C’est avec une immense tristesse que nous avons appris le décès soudain de Jean-Marc Chassery le 17 juin 2023.&lt;/p>
&lt;p>Jean-Marc a été non seulement un des pionniers de la géométrie discrète dans les années 90, et un des maîtres d’oeuvre de la création du groupe de travail GDMM via le rapprochement entre les communautés de géométrie discrète et morphologie mathématique.&lt;/p>
&lt;p>Très impliqué dans l&amp;rsquo;animation et la structuration de la recherche, il a assuré de nombreuses responsabilités tout au long de sa carrière : fondateur et premier directeur du GIPSA-Lab, directeur du GdR ISIS de 1992 à 2001 après avoir eu des responsabilités dans le GdR TDSI ; membre du Comité National du CNRS (CoNRS) en section 07 en 2001 ; Directeur-Adjoint Scientifique (DAS) à la création de l’INSIS de 2009 à 2012 ; délégué scientifique à l’HCERES de 2012 à 2017.&lt;/p>
&lt;p>Même à la retraite depuis plusieurs années, Jean-Marc restait très proche de ses anciens collègues pour qui sa disparition est une très grande perte.&lt;/p>
&lt;p>&lt;a href="https://www.gdr-isis.fr/index.php/hommage-a-jean-marc-chassery/" target="_blank" rel="noopener">Hommage à Jean-Marc Chassery sur le site du GdR ISIS&lt;/a>&lt;/p></description></item><item><title>Retour sur les pleinières 2023</title><link>https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/</guid><description>&lt;h1 id="lancement">Lancement&lt;/h1>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/pl%c3%a9ni%c3%a8res2023_lancement.pdf"> Accéder à la présentation &lt;/a>&lt;/p>
&lt;h1 id="session-ia-et-animation">Session &amp;ldquo;IA et Animation&amp;rdquo;&lt;/h1>
&lt;h2 id="alexandre-meyer---ia-et-animation">Alexandre Meyer - IA et Animation&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_IA_hu9c8879c4c5db3e353099dc518ed8460d_132337_1c8d139b532166c6aad267c88e4667c1.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_IA_hu9c8879c4c5db3e353099dc518ed8460d_132337_0047e2b8bf705773fc13470a534e92a4.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_IA_hu9c8879c4c5db3e353099dc518ed8460d_132337_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_IA_hu9c8879c4c5db3e353099dc518ed8460d_132337_1c8d139b532166c6aad267c88e4667c1.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Alexandre Meyer est Maître de conférences (HDR) au département d&amp;rsquo;informatique de l&amp;rsquo;Université Lyon 1 depuis 2004. Il mène ses recherches dans le groupe SAARA du laboratoire LIRIS.
Ses travaux de recherche se situent à l&amp;rsquo;interface entre l&amp;rsquo;infographie et la vision par ordinateur. Dans le domaine de la vision par ordinateur, ses travaux se concentrent sur la reconnaissance des expressions des visages et des mouvements du corps, en établissant souvent un lien avec l&amp;rsquo;animation ou la perception. Du côté de l&amp;rsquo;infographie, ses travaux vont de l&amp;rsquo;animation procédurale (zéro données) à l&amp;rsquo;animation basée sur l&amp;rsquo;apprentissage, avec un intérêt particulier pour l&amp;rsquo;édition ou la création de style dans les animations.&lt;/p>
&lt;p>Il a donné une présentation sur l&amp;rsquo;utilisation de l&amp;rsquo;intelligence artificielle (IA) dans l&amp;rsquo;animation. Sa présentation a discuté des progrès réalisés grâce à l&amp;rsquo;apprentissage profond et a exploré différentes méthodes utilisées dans ce domaine. Différents types de réseaux de neurones ont été abordés, tels que les réseaux de convolution et les autoencodeurs. Des techniques d&amp;rsquo;amélioration de la qualité des animations ont été discutées, ainsi que l&amp;rsquo;utilisation des espaces latents pour la représentation des poses. Des exemples d&amp;rsquo;applications de l&amp;rsquo;IA dans l&amp;rsquo;animation ont été donnés, comme la génération d&amp;rsquo;avatars 3D à partir de textes. Enfin, la présentation a souligné les avancées réalisées et les défis à relever dans ce domaine.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/2023_GDR_AMeyer.pdf"> Accéder à la présentation &lt;/a>&lt;/p>
&lt;figure id="figure-alexandre-meyer-université-lyon1-liris---httpspersoliriscnrsframeyerpublic_htmlwww">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Alexandre Meyer (Université Lyon1, LIRIS) : https://perso.liris.cnrs.fr/ameyer/public_html/www/" srcset="
/post/23-06-06-retour-pleinieres-2023/alexM_hua93c34035ab6236b9d4769d2cad09f7e_26557_b00db74b34e210594f2eac9c3173bb2e.webp 400w,
/post/23-06-06-retour-pleinieres-2023/alexM_hua93c34035ab6236b9d4769d2cad09f7e_26557_2958251a62cc56b99a62120650218d32.webp 760w,
/post/23-06-06-retour-pleinieres-2023/alexM_hua93c34035ab6236b9d4769d2cad09f7e_26557_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/alexM_hua93c34035ab6236b9d4769d2cad09f7e_26557_b00db74b34e210594f2eac9c3173bb2e.webp"
width="118"
height="119"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Alexandre Meyer (Université Lyon1, LIRIS) : &lt;a href="https://perso.liris.cnrs.fr/ameyer/public_html/www/" target="_blank" rel="noopener">https://perso.liris.cnrs.fr/ameyer/public_html/www/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h1 id="session-impact-environnemental--on-en-est-où">Session &amp;ldquo;Impact environnemental : on en est où&amp;rdquo;&lt;/h1>
&lt;h2 id="peter-sturm">Peter Sturm&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_peter_hu9c8879c4c5db3e353099dc518ed8460d_130370_d43289433e96465a1ee6d1c90da1352e.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_peter_hu9c8879c4c5db3e353099dc518ed8460d_130370_7baf54c6edffaf28acc3d112b073ec04.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_peter_hu9c8879c4c5db3e353099dc518ed8460d_130370_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_peter_hu9c8879c4c5db3e353099dc518ed8460d_130370_d43289433e96465a1ee6d1c90da1352e.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Peter Sturm est adjoint au directeur scientifique, en charge du domaine &amp;ldquo;Perception, cognition, interaction&amp;rdquo; à Inria depuis le 9 avril 2015. Il mène ses recherches dans l&amp;rsquo;équipe STEEP à Inria Grenoble Rhône-Alpes.
Ses sujets de recherche, centrés sur la vision par ordinateur, concernent surtout le calibrage de caméras, la reconstruction 3D et l’estimation de mouvement, que ce soit pour des caméras perspectives ou omnidirectionnelles. Depuis 2011, Peter contribue aux travaux de l&amp;rsquo;institut sur le développement durable et, plus particulièrement, sur des modèles intégrés d’usage des sols et de transport.&lt;/p>
&lt;p>Il a donné une présentation abordant les thèmes des effets rebond, de l&amp;rsquo;efficience, de la sobriété et de la résilience. Au dela de la définition des ces notions, Peter a aussi sensibilisé l&amp;rsquo;audience à l&amp;rsquo;importance de se poser les bonnes questions (autour des impacts environnementaux mais pas seulement), de bien nommer les choses et d&amp;rsquo;avoir conscience des possibles impacts des technologies developpées dans les laboratoires.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/2023_05_30_GdR_IG_RV_Peter_Sturm.pdf"> Accéder à la présentation &lt;/a>&lt;/p>
&lt;figure id="figure-peter-sturm-inria-grenoble-ljk--httpssteepinriafrmembres-de-lequipepeter-sturm">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Peter Sturm (INRIA Grenoble, LJK) : https://steep.inria.fr/membres-de-lequipe/peter-sturm/" srcset="
/post/23-06-06-retour-pleinieres-2023/peterS_hudbec3e859f1c8a7103c10d23fa8ef1d6_69529_aad061517f32190af7b33bafdef3d111.webp 400w,
/post/23-06-06-retour-pleinieres-2023/peterS_hudbec3e859f1c8a7103c10d23fa8ef1d6_69529_a80a7e0004cc92dd366970a130259e55.webp 760w,
/post/23-06-06-retour-pleinieres-2023/peterS_hudbec3e859f1c8a7103c10d23fa8ef1d6_69529_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/peterS_hudbec3e859f1c8a7103c10d23fa8ef1d6_69529_aad061517f32190af7b33bafdef3d111.webp"
width="265"
height="195"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Peter Sturm (INRIA Grenoble, LJK) : &lt;a href="https://steep.inria.fr/membres-de-lequipe/peter-sturm/" target="_blank" rel="noopener">https://steep.inria.fr/membres-de-lequipe/peter-sturm/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="laurent-lefevre">Laurent Lefevre&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_laurent_hu9c8879c4c5db3e353099dc518ed8460d_124772_1ca442ff78a80f2ada1c4653908c7690.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_laurent_hu9c8879c4c5db3e353099dc518ed8460d_124772_74a19166b28154bacbbd73a1e39cdf94.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_laurent_hu9c8879c4c5db3e353099dc518ed8460d_124772_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_laurent_hu9c8879c4c5db3e353099dc518ed8460d_124772_1ca442ff78a80f2ada1c4653908c7690.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Laurent Lefèvre est un chercheur permanent en informatique à Inria. Il travaille au sein de l&amp;rsquo;équipe AVALON (Algorithmes et Architectures Logicielles pour les Plates-formes Orientées Service) d&amp;rsquo;Inria et du Laboratoire LIP à l&amp;rsquo;École Normale Supérieure de Lyon.
Ses domaines de recherche comprennent l&amp;rsquo;informatique distribuée et les réseaux, l&amp;rsquo;informatique et les réseaux écoénergétiques, le Green IT, la durabilité en informatique, les réseaux définis par logiciel, les réseaux autonomes, les protocoles et services de réseaux à haute performance, les réseaux actifs et programmables, les réseaux tolérants aux perturbations, le calcul en grappes, les systèmes de mémoire partagée distribuée et la cohérence des données, ainsi que la tolérance aux pannes.&lt;/p>
&lt;p>Il a présenté l&amp;rsquo;impact du numérique, à la fois de son usage (consommation d&amp;rsquo;énergie) mais aussi de son cycle de vie (extraction des ressources et recyclage), sur l&amp;rsquo;environnement, dans un monde où les usages du numériques sont de plus en plus nombreux.
Il a ensuite présenté quelques pistes pour prendre en compte ces enjeux.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/GDR-IG-RV_2023_Laurent_Lefevre_diffuse.pdf"> Accéder à la présentation &lt;/a>&lt;/p>
&lt;figure id="figure-laurent-lefevre-inria-lip--httpspersoens-lyonfrlaurentlefevre">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Laurent Lefevre (INRIA, LIP) : https://perso.ens-lyon.fr/laurent.lefevre/" srcset="
/post/23-06-06-retour-pleinieres-2023/laurentL_huf81403ad945414b1df24ec670126f56e_20248_0adc25409d2129bd67674b33f826a080.webp 400w,
/post/23-06-06-retour-pleinieres-2023/laurentL_huf81403ad945414b1df24ec670126f56e_20248_a1c8aad6b11c2337c207786b562e8e1b.webp 760w,
/post/23-06-06-retour-pleinieres-2023/laurentL_huf81403ad945414b1df24ec670126f56e_20248_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/laurentL_huf81403ad945414b1df24ec670126f56e_20248_0adc25409d2129bd67674b33f826a080.webp"
width="320"
height="240"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Laurent Lefevre (INRIA, LIP) : &lt;a href="https://perso.ens-lyon.fr/laurent.lefevre/" target="_blank" rel="noopener">https://perso.ens-lyon.fr/laurent.lefevre/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h1 id="session-ig-rv-et-jo-2024">Session &amp;ldquo;IG-RV et JO 2024&amp;rdquo;&lt;/h1>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_JO_hu9c8879c4c5db3e353099dc518ed8460d_125334_f743bb1567cfcfb9f4decc50c0561225.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_JO_hu9c8879c4c5db3e353099dc518ed8460d_125334_bb2b6d949688661643884d2e7772c01c.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_JO_hu9c8879c4c5db3e353099dc518ed8460d_125334_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_JO_hu9c8879c4c5db3e353099dc518ed8460d_125334_f743bb1567cfcfb9f4decc50c0561225.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h2 id="lije-yao">Lije Yao&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_lijie_hu7fef5788bd28ca160c0fe5ce76757543_128964_cfc4f4d5497828abaed767f20bf576bc.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_lijie_hu7fef5788bd28ca160c0fe5ce76757543_128964_004bdbcd6e6acf97cf222bd90e491a12.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_lijie_hu7fef5788bd28ca160c0fe5ce76757543_128964_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_lijie_hu7fef5788bd28ca160c0fe5ce76757543_128964_cfc4f4d5497828abaed767f20bf576bc.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Lije Yao prépare actuellement un doctorat à Inria dans l&amp;rsquo;équipe Aviz (Analyse et visualisation) et l&amp;rsquo;Université Paris-Saclay. Ses principaux sujets de recherche comprennent la visualisation de l&amp;rsquo;information et l&amp;rsquo;analyse visuelle, avec un accent sur la visualisation en mouvement.&lt;/p>
&lt;p>Elle a présenté ses recherches sur la visualisation située et en temps réel des informations liées aux compétitions de natations.&lt;/p>
&lt;figure id="figure-lije-yao-inria-saclay">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Lije Yao (INRIA Saclay)" srcset="
/post/23-06-06-retour-pleinieres-2023/LijieYao_huf9d1f7593529e1e0866263f2b932ecbb_38534_3142174961f8f80cd2c848390dfaa53a.webp 400w,
/post/23-06-06-retour-pleinieres-2023/LijieYao_huf9d1f7593529e1e0866263f2b932ecbb_38534_05d1f13daf041649d06456f7c385015a.webp 760w,
/post/23-06-06-retour-pleinieres-2023/LijieYao_huf9d1f7593529e1e0866263f2b932ecbb_38534_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/LijieYao_huf9d1f7593529e1e0866263f2b932ecbb_38534_3142174961f8f80cd2c848390dfaa53a.webp"
width="247"
height="300"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Lije Yao (INRIA Saclay)
&lt;/figcaption>&lt;/figure>
&lt;h2 id="franck-multon">Franck Multon&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_franck_hu9c8879c4c5db3e353099dc518ed8460d_119594_f2596967dcf14a4be4fafa7342c5b45f.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_franck_hu9c8879c4c5db3e353099dc518ed8460d_119594_7b160cf11d15b0908808c2ce95176a78.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_franck_hu9c8879c4c5db3e353099dc518ed8460d_119594_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_franck_hu9c8879c4c5db3e353099dc518ed8460d_119594_f2596967dcf14a4be4fafa7342c5b45f.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Franck Multon est directeur de recherche à Inria et reponsable de l&amp;rsquo;équipe MimeTIC (Analysis-Synthesis Approach for Virtual Human Simulation). Depuis septembre 2018, il s&amp;rsquo;occupe d&amp;rsquo;une mission nationale de coordination des actions du centre dans le domaine du numérique pour le sport, en lien avec les JOP Paris 2024.&lt;/p>
&lt;p>Il a présenté plusieurs travaux autour de l&amp;rsquo;utilisation du numérique et de la réalité virtuelle pour l&amp;rsquo;entrainement des sportifs de haut niveau (autour du rugby ou du football notamment).&lt;/p>
&lt;figure id="figure-franck-multon-univ-rennes-inria--httpspersouniv-rennes2frfranckmulton">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Franck Multon (Univ Rennes, INRIA) : https://perso.univ-rennes2.fr/franck.multon" srcset="
/post/23-06-06-retour-pleinieres-2023/franckM_huc3e2e9df64bacb078d5e2e5db6bde03e_4816_48fea43ec0c6d47c00e1ce0d9cab8d36.webp 400w,
/post/23-06-06-retour-pleinieres-2023/franckM_huc3e2e9df64bacb078d5e2e5db6bde03e_4816_b8c9e7f5c4d8fc276de2d330c4db9007.webp 760w,
/post/23-06-06-retour-pleinieres-2023/franckM_huc3e2e9df64bacb078d5e2e5db6bde03e_4816_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/franckM_huc3e2e9df64bacb078d5e2e5db6bde03e_4816_48fea43ec0c6d47c00e1ce0d9cab8d36.webp"
width="150"
height="150"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Franck Multon (Univ Rennes, INRIA) : &lt;a href="https://perso.univ-rennes2.fr/franck.multon" target="_blank" rel="noopener">https://perso.univ-rennes2.fr/franck.multon&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="thibaut-le-naour-startup-motion-up">Thibaut Le Naour (Startup Motion-Up)&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_motionUp_hu9c8879c4c5db3e353099dc518ed8460d_127687_2f477a174ce30435881c9dc9c4b0067e.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_motionUp_hu9c8879c4c5db3e353099dc518ed8460d_127687_f70b05916290e2a4bd0c3dc125a819c9.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_motionUp_hu9c8879c4c5db3e353099dc518ed8460d_127687_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_motionUp_hu9c8879c4c5db3e353099dc518ed8460d_127687_2f477a174ce30435881c9dc9c4b0067e.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>MotionUp est une entreprise spécialisée dans les services informatiques, axée sur la capture de mouvement et la production de solutions numériques. Elle propose des services de capture de mouvement précis et efficaces, permettant la numérisation des mouvements avec une grande précision et rapidité. En plus de la capture de mouvement, MotionUp propose des solutions numériques personnalisées, de la conception à l&amp;rsquo;hebergement.&lt;/p>
&lt;p>Thibat Le Naour, le fondateur de Motion-Up a discuté des différentes technologies de motion capture et a présenté plusieurs cas d&amp;rsquo;usage des technologies de motion capture pour l&amp;rsquo;apprentissage des gestes.&lt;/p>
&lt;figure id="figure-thibaut-le-naour--httpmotion-upcompersotlenaour">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Thibaut Le Naour : http://motion-up.com/perso/tlenaour/" srcset="
/post/23-06-06-retour-pleinieres-2023/thibautLN_hu2d95b4841be49ae575605f2168e6f15c_35820_612e6cf504afee9bbe9b6c80db0b7a92.webp 400w,
/post/23-06-06-retour-pleinieres-2023/thibautLN_hu2d95b4841be49ae575605f2168e6f15c_35820_a8f800fef2c41b6c84e23aa9677d0b03.webp 760w,
/post/23-06-06-retour-pleinieres-2023/thibautLN_hu2d95b4841be49ae575605f2168e6f15c_35820_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/thibautLN_hu2d95b4841be49ae575605f2168e6f15c_35820_612e6cf504afee9bbe9b6c80db0b7a92.webp"
width="195"
height="195"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Thibaut Le Naour : &lt;a href="http://motion-up.com/perso/tlenaour/" target="_blank" rel="noopener">http://motion-up.com/perso/tlenaour/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;figure id="figure-startup-motion-up--httpswwwmotion-upcom">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Startup Motion-Up : https://www.motion-up.com/" srcset="
/post/23-06-06-retour-pleinieres-2023/motionUp_hu6cd07605589ec653d3a05196a8ac57c6_16926_2a6cee6b9458c3261094b9ea25ae6393.webp 400w,
/post/23-06-06-retour-pleinieres-2023/motionUp_hu6cd07605589ec653d3a05196a8ac57c6_16926_7eca80373bf10bdf049b5cddffa7c16c.webp 760w,
/post/23-06-06-retour-pleinieres-2023/motionUp_hu6cd07605589ec653d3a05196a8ac57c6_16926_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/motionUp_hu6cd07605589ec653d3a05196a8ac57c6_16926_2a6cee6b9458c3261094b9ea25ae6393.webp"
width="300"
height="129"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Startup Motion-Up : &lt;a href="https://www.motion-up.com/" target="_blank" rel="noopener">https://www.motion-up.com/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h1 id="session-art-et-science">Session &amp;ldquo;Art et Science&amp;rdquo;&lt;/h1>
&lt;h2 id="benoit-arbelot-théoriz-">Benoit Arbelot (Théoriz) :&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_theoriz_hu7fef5788bd28ca160c0fe5ce76757543_136186_1a2edc89d3b1ce1f2ec674448f76465b.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_theoriz_hu7fef5788bd28ca160c0fe5ce76757543_136186_44ae3d3d5442529e9be9600d36aa15f7.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_theoriz_hu7fef5788bd28ca160c0fe5ce76757543_136186_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_theoriz_hu7fef5788bd28ca160c0fe5ce76757543_136186_1a2edc89d3b1ce1f2ec674448f76465b.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Theoriz est un studio de création artistique et technologique spécialisé dans la conception d&amp;rsquo;installations immersives et de spectacles audiovisuels innovants. Composé d&amp;rsquo;une équipe d&amp;rsquo;ingénieurs, d&amp;rsquo;artistes et de développeurs créatifs, Theoriz combine recherche artistique et scientifique pour créer de nouvelles expériences uniques. Du mélange entre le réel, le virtuel et la poésie, leurs installations artistiques sont exposées à travers le monde.&lt;/p>
&lt;p>Benoît Arbelot, ingénieur à Theoriz, a présenté différents projets menés par le studio et les technologies developpées pour ces projets.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/Presentation%20THEORIZ%20IG-RV%202023-05-30.pdf"> Accéder à la présentation &lt;/a>&lt;/p>
&lt;p>
&lt;figure id="figure-benoit-arbelot">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Benoit Arbelot" srcset="
/post/23-06-06-retour-pleinieres-2023/benoitA_hu08263980ec618ada007391c65888356b_19067_f1075cea404a52fdb6f860460d515b47.webp 400w,
/post/23-06-06-retour-pleinieres-2023/benoitA_hu08263980ec618ada007391c65888356b_19067_d5e0351ea34d52a2725611f1831a6c16.webp 760w,
/post/23-06-06-retour-pleinieres-2023/benoitA_hu08263980ec618ada007391c65888356b_19067_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/benoitA_hu08263980ec618ada007391c65888356b_19067_f1075cea404a52fdb6f860460d515b47.webp"
width="192"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Benoit Arbelot
&lt;/figcaption>&lt;/figure>
&lt;figure id="figure-théoriz">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Théoriz" srcset="
/post/23-06-06-retour-pleinieres-2023/theoriz_hu080ec4554bb77cb9791d92479736430b_15181_6da81c871544d422287596d0a8140e6d.webp 400w,
/post/23-06-06-retour-pleinieres-2023/theoriz_hu080ec4554bb77cb9791d92479736430b_15181_b3ec9acd9042766eea34f53660aac7bd.webp 760w,
/post/23-06-06-retour-pleinieres-2023/theoriz_hu080ec4554bb77cb9791d92479736430b_15181_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/theoriz_hu080ec4554bb77cb9791d92479736430b_15181_6da81c871544d422287596d0a8140e6d.webp"
width="300"
height="132"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Théoriz
&lt;/figcaption>&lt;/figure>&lt;/p>
&lt;h1 id="session-métavers-enjeux-scientifiques-et-impacts">Session &amp;ldquo;Métavers: enjeux scientifiques et impacts&amp;rdquo;&lt;/h1>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_metavers2_hu9c8879c4c5db3e353099dc518ed8460d_140385_5df032450ebc378a0eb3762453586a42.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_metavers2_hu9c8879c4c5db3e353099dc518ed8460d_140385_60f216673a916922b3f389952b8e2470.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_metavers2_hu9c8879c4c5db3e353099dc518ed8460d_140385_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_metavers2_hu9c8879c4c5db3e353099dc518ed8460d_140385_5df032450ebc378a0eb3762453586a42.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_metavers_hu5acd42242b1b5ce0f9b4a3a2fbdf55e9_152481_e50d15bc8cd9cb038d0211e847475a89.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_metavers_hu5acd42242b1b5ce0f9b4a3a2fbdf55e9_152481_4cccbde10a5f65303548d991beb3e9d2.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_metavers_hu5acd42242b1b5ce0f9b4a3a2fbdf55e9_152481_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_metavers_hu5acd42242b1b5ce0f9b4a3a2fbdf55e9_152481_e50d15bc8cd9cb038d0211e847475a89.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h2 id="pascal-guitton">Pascal Guitton&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_pascal_hu9c8879c4c5db3e353099dc518ed8460d_118090_83595e6df257e15a36320cc603113e32.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_pascal_hu9c8879c4c5db3e353099dc518ed8460d_118090_45842762334c733ecd70d84fcbf6132e.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_pascal_hu9c8879c4c5db3e353099dc518ed8460d_118090_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_pascal_hu9c8879c4c5db3e353099dc518ed8460d_118090_83595e6df257e15a36320cc603113e32.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Pascal Guitton est professeur émérite à l’université de Bordeaux. Ses domaines de recherche sont la réalité virtuelle et l&amp;rsquo;interaction, notamment dans les systèmes numériques d&amp;rsquo;enseignement.&lt;/p>
&lt;p>Cette présentation a abordé divers questionnements relatifs aux métavers, en mettant en évidence leur origine dans des avancées scientifiques, technologiques et culturelles antérieures, ainsi que les implications spécifiques liées à la réalité virtuelle, aux réseaux sociaux, aux jeux vidéo et les blockchains. Elle a soulevé des préoccupations telles que la protection des données personnelles, les vols et détournements, les potentielles addictions et manipulations, les problèmes de harcèlement, ainsi que les impacts environnementaux. En conclusion, la présentation a recommandé de ne pas être passif face aux métavers, mais d&amp;rsquo;engager des réflexions, des recherches et des développements appliqués accompagnés de questionnements éthiques, et de considérer la régulation de leur mise en ligne tout en réfléchissant à leur utilité réelle.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/2023%20M%c3%a9tavers%20GDR%20IGRV.pdf"> Accéder à la présentation &lt;/a>&lt;/p>
&lt;figure id="figure-pascal-guitton-université-de-bordeaux">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Pascal Guitton (Université de Bordeaux)" srcset="
/post/23-06-06-retour-pleinieres-2023/pascalG_hu257b6b91973c7f1feb28ff8993791d90_20319_6b0de9e233947ca3e01e17031ac37e95.webp 400w,
/post/23-06-06-retour-pleinieres-2023/pascalG_hu257b6b91973c7f1feb28ff8993791d90_20319_99c1fc8b985f618b0f4e3645eebe21ec.webp 760w,
/post/23-06-06-retour-pleinieres-2023/pascalG_hu257b6b91973c7f1feb28ff8993791d90_20319_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/pascalG_hu257b6b91973c7f1feb28ff8993791d90_20319_6b0de9e233947ca3e01e17031ac37e95.webp"
width="200"
height="200"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Pascal Guitton (Université de Bordeaux)
&lt;/figcaption>&lt;/figure>
&lt;h2 id="jean-marie-burkhardt">Jean-Marie Burkhardt&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_jmb_hu9c8879c4c5db3e353099dc518ed8460d_144447_d78ae8d6b23979c471398ef1cce62823.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_jmb_hu9c8879c4c5db3e353099dc518ed8460d_144447_45d21e91ff7e640805656ee3a15f48b3.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_jmb_hu9c8879c4c5db3e353099dc518ed8460d_144447_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_jmb_hu9c8879c4c5db3e353099dc518ed8460d_144447_d78ae8d6b23979c471398ef1cce62823.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Jean-Marie Burkhardt est directeur de recherche à l&amp;rsquo;Univ. Gustave Eiffel au laboratoire de psychologie et d&amp;rsquo;ergonomie appliquées (LaPEA). Il développe des recherches en ergonomie et psychologie sur deux axes : d&amp;rsquo;une part des études sur les activités, les facteurs de risques et la prévention d&amp;rsquo;accidents dans le domaine des mobilités et, d&amp;rsquo;autre part, sur la conception-centrée utilité des technologies émergentes telles que la réalité virtuelle, augmentée et mixte.&lt;/p>
&lt;p>Il a présenté la méthodologie ainsi qu&amp;rsquo;un résumé du rapport de l&amp;rsquo;ANSES sur l&amp;rsquo;exposition aux technologies de réalité virtuelle et/ou augmentée.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/BurkhardtVR&amp;amp;ARHealthEffectsGDRIGRV2023.pdf"> Accéder à la présentation &lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.anses.fr/fr/system/files/AP2017SA0076Ra.pdf" target="_blank" rel="noopener">Lien vers le rapport ANSES&lt;/a>&lt;/p>
&lt;figure id="figure-jean-marie-burkhardt-université-gustave-eiffel--httpswwwifsttarfrmenu-hautannuairefiche-personnellepersonneburkhardt-jean-marie">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Jean-Marie Burkhardt (Université Gustave Eiffel) : https://www.ifsttar.fr/menu-haut/annuaire/fiche-personnelle/personne/burkhardt-jean-marie/" srcset="
/post/23-06-06-retour-pleinieres-2023/jeanMarieB_hucfca0eb1b5c0afb5dbb0ceab0dda51c7_113984_e3f4ef1a3a3c9fc8846650baa5a5c851.webp 400w,
/post/23-06-06-retour-pleinieres-2023/jeanMarieB_hucfca0eb1b5c0afb5dbb0ceab0dda51c7_113984_a975f74ef6c1ab3348dc9e833b86f0b0.webp 760w,
/post/23-06-06-retour-pleinieres-2023/jeanMarieB_hucfca0eb1b5c0afb5dbb0ceab0dda51c7_113984_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/jeanMarieB_hucfca0eb1b5c0afb5dbb0ceab0dda51c7_113984_e3f4ef1a3a3c9fc8846650baa5a5c851.webp"
width="203"
height="203"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Jean-Marie Burkhardt (Université Gustave Eiffel) : &lt;a href="https://www.ifsttar.fr/menu-haut/annuaire/fiche-personnelle/personne/burkhardt-jean-marie/" target="_blank" rel="noopener">https://www.ifsttar.fr/menu-haut/annuaire/fiche-personnelle/personne/burkhardt-jean-marie/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="rémi-ronfard">Rémi Ronfard&lt;/h2>
&lt;p>Rémi Ronfard est directeur de recherche à Inria, et dirige l&amp;rsquo;équipe Anima d&amp;rsquo;Inria Grenoble Rhone Alpes. Sa recherche porte sur les modèles informatiques de la narration visuelle et de la réalisation de films, et plus précisement sur le développement d&amp;rsquo;outils informatiques pour la réalisation de films d&amp;rsquo;animation et de jeux interactifs, utilisant des décors virtuels, des acteurs, des caméras et des lumières.&lt;/p>
&lt;p>Il a présenté les résultats d&amp;rsquo;une mission exploratoire sur les métavers, en définissant tout d&amp;rsquo;abord les différents types de metavers puis les principaux axes de reflexion autour d&amp;rsquo;une stratégie metaversique, des questions de socitété soulevées par le metavers aux besoins de régulation.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/Metavers%20-%20Mai%202023_R%c3%a9mi%20Ronfard.pdf"> Accéder à la présentation &lt;/a>&lt;/p>
&lt;figure id="figure-rémi-ronfard-inria--httpsteaminriafranimaremi-ronfard">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Rémi Ronfard (INRIA) : https://team.inria.fr/anima/remi-ronfard/" srcset="
/post/23-06-06-retour-pleinieres-2023/remiR_hu9c16a90acf421e3d00babe2090f04297_44442_637b1b551e835c60df9a41c0ad8baf04.webp 400w,
/post/23-06-06-retour-pleinieres-2023/remiR_hu9c16a90acf421e3d00babe2090f04297_44442_dfb8f655f6e48cd75f46215658a2d5a2.webp 760w,
/post/23-06-06-retour-pleinieres-2023/remiR_hu9c16a90acf421e3d00babe2090f04297_44442_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/remiR_hu9c16a90acf421e3d00babe2090f04297_44442_637b1b551e835c60df9a41c0ad8baf04.webp"
width="234"
height="300"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Rémi Ronfard (INRIA) : &lt;a href="https://team.inria.fr/anima/remi-ronfard/" target="_blank" rel="noopener">https://team.inria.fr/anima/remi-ronfard/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h1 id="session-futur-du">Session &amp;ldquo;futur du&amp;hellip;&amp;rdquo;&lt;/h1>
&lt;h2 id="george-drettakis">George Drettakis&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_george_hu9c8879c4c5db3e353099dc518ed8460d_136296_f587f6a54c6f00212b1e3c549478a415.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_george_hu9c8879c4c5db3e353099dc518ed8460d_136296_0b2ce6c6efb040ede3efba0b81eb1efd.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_george_hu9c8879c4c5db3e353099dc518ed8460d_136296_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_george_hu9c8879c4c5db3e353099dc518ed8460d_136296_f587f6a54c6f00212b1e3c549478a415.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>George Drettakis est Directeur de recherche à Inria et dirige l&amp;rsquo;équipe GraphDeco d&amp;rsquo;Inria Sophia Antipolis Mediterranée. Ses recherches portent sur le rendu et les textures à base d&amp;rsquo;images, l&amp;rsquo;illumination interactive, les ombres, le rééclairage et le rendu interactif en général.&lt;/p>
&lt;p>Il a présenté une perspective personnelle de l&amp;rsquo;évolution du rendu graphique, remontant dans le temps pour retracer l&amp;rsquo;histoire du rendu graphique, en mettant en évidence les problèmes ouverts et les avancées majeures, et abordant également les récentes avancées dans le domaine du rendu neuronal, ainsi que les opportunités identifiées pour l&amp;rsquo;avenir du rendu.&lt;/p>
&lt;p>&lt;a href="https://gdr-igrv.fr/uploads/The%20Future%20of%20RenderingNoVideos.pdf"> Accéder à la présentation (pdf sans vidéo)&lt;/a>&lt;/p>
&lt;figure id="figure-george-drettakis-inria-sophia-antipolis---httpwww-sopinriafrmembersgeorgedrettakis">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="George Drettakis (INRIA, Sophia-Antipolis) : http://www-sop.inria.fr/members/George.Drettakis/" srcset="
/post/23-06-06-retour-pleinieres-2023/georgeG_hu72bbbbec7c0329f3a5c49a314d1884d9_17120_35b59389f50208e366425b87190f0fdb.webp 400w,
/post/23-06-06-retour-pleinieres-2023/georgeG_hu72bbbbec7c0329f3a5c49a314d1884d9_17120_fde72d84b2a811cfc1e06cb35cc069e0.webp 760w,
/post/23-06-06-retour-pleinieres-2023/georgeG_hu72bbbbec7c0329f3a5c49a314d1884d9_17120_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/georgeG_hu72bbbbec7c0329f3a5c49a314d1884d9_17120_35b59389f50208e366425b87190f0fdb.webp"
width="224"
height="300"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
George Drettakis (INRIA, Sophia-Antipolis) : &lt;a href="http://www-sop.inria.fr/members/George.Drettakis/" target="_blank" rel="noopener">http://www-sop.inria.fr/members/George.Drettakis/&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="tamy-boubekeur">Tamy Boubekeur&lt;/h2>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/23-06-06-retour-pleinieres-2023/session_tamy_hu9c8879c4c5db3e353099dc518ed8460d_138717_116cf2393d099063aa08a3a187d3b539.webp 400w,
/post/23-06-06-retour-pleinieres-2023/session_tamy_hu9c8879c4c5db3e353099dc518ed8460d_138717_744ff97b0bc97286aed654d48608148b.webp 760w,
/post/23-06-06-retour-pleinieres-2023/session_tamy_hu9c8879c4c5db3e353099dc518ed8460d_138717_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/session_tamy_hu9c8879c4c5db3e353099dc518ed8460d_138717_116cf2393d099063aa08a3a187d3b539.webp"
width="760"
height="506"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>Tamy Boubekeur est actuellement directeur de laboratoire et chercheur chez Adobe Research, ainsi que professeur au département d&amp;rsquo;informatique de l&amp;rsquo;Ecole Polytechnique, Institut Polytechnique de Paris. Ses domaines de recherche personnels se concentrent sur l&amp;rsquo;infographie 3D, avec un intérêt particulier pour la modélisation, le rendu et l&amp;rsquo;apprentissage efficace des données 3D.&lt;/p>
&lt;p>Il a présenté différents projets autour d&amp;rsquo;outils d&amp;rsquo;édition et de création de contenu 3D (textures, géométrie&amp;hellip;), en insistant sur l&amp;rsquo;aspect multi-scalaire de ces différentes solutions.&lt;/p>
&lt;figure id="figure-tamy-boubekeur-adobe-research-httpsresearchadobecompersontamy-boubekeur">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Tamy Boubekeur (Adobe Research) https://research.adobe.com/person/tamy-boubekeur/" srcset="
/post/23-06-06-retour-pleinieres-2023/tamyB_hub3758cf5bb13ac6ae63ed1850f9b1d9b_30430_9aa187625280cf41b3045cc80a76d935.webp 400w,
/post/23-06-06-retour-pleinieres-2023/tamyB_hub3758cf5bb13ac6ae63ed1850f9b1d9b_30430_8231019291c6feeeaf9e67a1a617b73e.webp 760w,
/post/23-06-06-retour-pleinieres-2023/tamyB_hub3758cf5bb13ac6ae63ed1850f9b1d9b_30430_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/23-06-06-retour-pleinieres-2023/tamyB_hub3758cf5bb13ac6ae63ed1850f9b1d9b_30430_9aa187625280cf41b3045cc80a76d935.webp"
width="300"
height="300"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Tamy Boubekeur (Adobe Research) &lt;a href="https://research.adobe.com/person/tamy-boubekeur/" target="_blank" rel="noopener">https://research.adobe.com/person/tamy-boubekeur/&lt;/a>
&lt;/figcaption>&lt;/figure></description></item><item><title>Résultats du prix 2023</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2023/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2023/</guid><description>&lt;h2 id="lauréat">Lauréat&lt;/h2>
&lt;p>&lt;strong>Thibault Tricard&lt;/strong> (Inria, Université de Lorraine) pour sa thèse intitulée &amp;ldquo;&lt;em>Procedural noises for the design of small-scale structures in Additive Manufacturing&lt;/em>&amp;rdquo; effectuée sous la direction de Sylvain Lefebvre et Didier Rouxel.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2023/Video%20Thibault%20Tricard.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://hal.science/tel-03765259/" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;h2 id="accessits">Accessits&lt;/h2>
&lt;p>&lt;strong>Anne-Laure Guinet&lt;/strong> (Université Evry-Paris-Saclay) pour sa thèse intitulée &amp;ldquo;&lt;em>Retours sensoriels multimodaux en réalité augmentée pour la rééducation de la marche des enfants atteints de paralysie cérébrale&lt;/em>&amp;rdquo; effectuée sous la direction de Samir Otmane, Guillaume Bouyer et de Eric Desailly.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2023/Video%20Anne-Laure%20Guinet.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://projet.liris.cnrs.fr/gdr-igrv-data/misc/AnneLaure-Guinet-PhD.pdf" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>&lt;strong>François Protais&lt;/strong> (Inria, Université de Lorraine) pour sa thèse intitulée &amp;ldquo;&lt;em>Maillage à dominante Polycube&lt;/em>&amp;rdquo; effectuée sous la direction de Dmitry Sokolov et Franck Ledoux.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2023/Video%20Francois%20Protais.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://hal.science/tel-03775686v1" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>&lt;em>Le jury 2023 a été animé par Loïc Barthe et Guillaume Cordonnier. Il était composé de Florence Bertails-Descoubes, Bruno Levy, Tamy Boubekeur, Eric Galin, Yvonne Jansen, Daniel Mestre.&lt;/em>&lt;/p></description></item><item><title>Journée du GT RV</title><link>https://gdr-igrv.fr/event/journee_gtrv2023/</link><pubDate>Wed, 31 May 2023 14:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrv2023/</guid><description>&lt;h1 id="programme">Programme&lt;/h1>
&lt;h2 id="mercredi-31-mai">Mercredi 31 mai&lt;/h2>
&lt;h3 id="14h-accueil">14h Accueil&lt;/h3>
&lt;h3 id="14h10-session-sensorielle">14h10 Session “Sensorielle”&lt;/h3>
&lt;h4 id="14h10--nebula-an-affordable-open-source-and-autonomous-olfactory-display-for-vr-headsets-charles-javerliat--eclenise-liris">14h10 : Nebula: An Affordable Open-Source and Autonomous Olfactory Display for VR Headsets (Charles JAVERLIAT – ECL/ENISE, LIRIS)&lt;/h4>
&lt;p>The impact of olfactory cues on user experience in virtual reality is increasingly studied.
However, results are still heterogeneous and existing studies difficult to replicate, mainly due
to a lack of standardized olfactory displays. In that context, we present Nebula, a low-cost,
open-source, olfactory display capable of diffusing scents at different diffusion rates using a
nebulization process. Nebula can be used with PC VR or autonomous head-mounted
displays, making it easily transportable without the need for an external computer. The
device was calibrated to diffuse at three diffusion rates: no diffusion, low and high. For each
level, the quantity of delivered odor was precisely characterized using a repeated weighting
method. The corresponding perceived olfactory intensities were evaluated by a
psychophysical experiment on sixteen participants. Results demonstrated the device
capability to successfully create three significantly different perceived odor intensities
(Friedman test 𝑝 &amp;lt; 10−6, Wilcoxon tests 𝑝𝑎𝑑 𝑗 &amp;lt; 10−3), without noticeable smell persistence
and with limited noise and discomfort. For reproducibility and to stimulate further research
in the area, 3D printing files, electronic hardware schemes, and firmware/software source
code are made publicly available.&lt;/p>
&lt;h4 id="14h40--influence-of-the-visual-quality-of-food-on-the-ability-to-induce-a-desire-to-eat-in-virtual-reality-florian-ramousse--eclenise-liris">14h40 : Influence of the visual quality of food on the ability to induce a desire to eat in virtual reality (Florian RAMOUSSE – ECL/ENISE, LIRIS)&lt;/h4>
&lt;p>Studies into food-related behaviors and emotions are increasingly being explored with
Virtual Reality (VR). Applications of VR technologies for food science include eating disorder
therapies, eating behavior studies and sensory analyzes. These applications involve 3D
food stimuli intended to elicit cravings, stress, and/or emotions. However, the visual quality
(i.e., the realism) of used food stimuli is heterogeneous, and this factor&amp;rsquo;s influence on the
results has never been isolated and evaluated. In this context, this work aims to study how
the visual quality of food stimuli, exposed in a virtual reality environment, influences the
resulting desire to eat. 28 subjects without eating disorders were included in this protocol,
who evaluated the desire to eat induced by 10 3D food stimuli, each duplicated in 7 quality
levels (for a total of 70 stimuli). Results show that visual quality influences the desire to eat,
and this effect depends on the type of food and users&amp;rsquo; eating habits. We found two significant
thresholds for visual quality: the first provides the minimal quality necessary to elicit a
significant desire to eat, while the second provides the ceiling value above which increasing
the quality does not improve further the desire to eat. These results allow us to provide useful
recommendations for the design of experiments involving food stimuli&lt;/p>
&lt;h4 id="15h10--saisie-de-données-par-écriture-manuelle-pour-les-applications-industrielles-de-la-réalité-virtuelle--influence-de-lorientation-du-tableau-et-des-retours-sensoriels-sur-la-performance-nicolas-fourrier--ecn-aau">15h10 : Saisie de données par écriture manuelle pour les applications industrielles de la réalité virtuelle : influence de l’orientation du tableau et des retours sensoriels sur la performance (Nicolas FOURRIER – ECN, AAU)&lt;/h4>
&lt;p>La saisie de données textuelles en réalité virtuelle (RV) est une tâche critique dont
l’importance ne cesse de grandir. C’est en particulier le cas pour les applications
industrielles de la RV où les situations de saisie de données peuvent être courantes :
communication entre collaborateurs, saisie de données techniques&amp;hellip; Il existe aujourd’hui
un gap de performance entre les outils classiques, comme les claviers physiques, et les
méthodes de saisie virtuelles qui sont utilisées en RV. La saisie de données en RV se doit
d’être efficace et facile à apprendre sans être frustrante. Nous présentons une méthode de
saisie de texte basée sur la reconnaissance d’écriture manuelle qui répond à ces trois
critères. Les utilisateurs peuvent saisir du texte en écrivant manuellement sur un tableau
virtuel. Une étude utilisateur avec 40 participants a été menée pour étudier les meilleurs
conditions d’écriture en terme d’orientation de tableau et de présence de retours sensoriels
(visuel, haptique et audio). La vitesse d’écriture, le taux d’erreur, l’utilisabilité et la charge de
travail sont étudiés. Cette étude montre que l’utilisation d’un tableau penché avec des
retours sensoriels permet de maximiser les vitesses de saisie en minimisant la charge de
travail. L’écriture manuelle en RV fait preuve d’une grande vitesse de saisie et utilisabilité
après un court entrainement en comparaison avec d’autres méthodes de saisie virtuelles.
Après 40 phrases d’entrainement, les participants atteignent en moyenne une vitesse de
saisie de 14.5 mots par minute et un groupe d’utilisateurs expérimentés en RV atteint 16.16
mots par minute. La plus haute vitesse de saisie observée est de 21.11 mots par minute.&lt;/p>
&lt;h3 id="15h40-pause">15h40 Pause&lt;/h3>
&lt;h3 id="16h10-session-comportement">16h10 Session “Comportement”&lt;/h3>
&lt;h4 id="16h10--leffet-proteus-et-la-créativité-avec-lincarnation-de-leonardo-da-vinci-geoffrey-gorisse--ensam-lampa">16H10 : L&amp;rsquo;effet Proteus et la créativité avec l&amp;rsquo;incarnation de Leonardo da Vinci (Geoffrey GORISSE – ENSAM, LAMPA)&lt;/h4>
&lt;p>Virtual reality provides users with the ability to substitute their physical appearance by em-
bodying virtual characters (avatars) using head-mounted displays and motion-capture tech-
nologies. Previous research demonstrated that the sense of embodiment toward an avatar
can impact user behavior and cognition. In this paper, we present an experiment designed
to investigate whether embodying a well-known creative genius could enhance participants'
creative performance. Following a preliminary online survey (N = 157) to select a famous
character suited to the purpose of this study, we developed a VR application allowing parti-
cipants to embody Leonardo da Vinci or a self-avatar. Self-avatars were approximately
matched with participants in terms of skin tone and morphology. 40 participants took part in
three tasks seamlessly integrated in a virtual workshop. The first task was based on a Guil-
ford&amp;rsquo;s Alternate Uses test (GAU) to assess participants&amp;rsquo; divergent abilities in terms of fluency
and originality. The second task was based on a Remote Associates Test (RAT) to evaluate
convergent abilities. Lastly, the third task consisted in designing potential alternative uses
of an object displayed in the virtual environment using a 3D sketching tool. Participants em-
bodying Leonardo da Vinci demonstrated significantly higher divergent thinking abilities, with
a substantial difference in fluency between the groups. Conversely, participants embodying
a self-avatar performed significantly better in the convergent thinking task. Taken together,
these results promote the use of our virtual embodiment approach, especially in applications
where divergent creativity plays an important role, such as design and innovation.&lt;/p>
&lt;h4 id="16h40-influence-of-scenarios-and-player-traits-on-flow-in-virtual-reality-élise-lavoué--université-jean-moulin-lyon-3-liris">16h40 Influence of Scenarios and Player Traits on Flow in Virtual Reality (Élise LAVOUÉ – Université Jean Moulin Lyon 3, LIRIS)&lt;/h4>
&lt;p>Many studies have investigated how interpersonal differences between users influence their
experience in Virtual Reality (VR) and it is now well recognized that user&amp;rsquo;s subjective
experiences and responses to the same VR environment can vary widely. In this study, we
focus on player traits, which correspond to users&amp;rsquo; preferences for game mechanics, arguing
that players react differently when experiencing VR scenarios. We developed three
scenarios in a same VR environment that rely on different game mechanics and evaluate
the influence of player traits on users’ perceived flow in each scenario. Our results show
that 1) the type of scenario has an impact on specific dimensions of flow; 2) the scenarios have
different effects on flow depending on the order they are performed, the flow preconditions
being stronger when performed at last; 3) almost all dimensions of flow are influenced by
the player traits, these influences depending on the scenario, 4) the Aesthetic trait has the
most influences in the three scenarios. We finally discuss the findings and limitations of the
present study that we believe has strong implications for the design of scenarios in VR
experiences.&lt;/p>
&lt;h2 id="jeudi-1er-juin">Jeudi 1er juin&lt;/h2>
&lt;h3 id="9h30-sessions-doctorants-ensam">9h30 Sessions “Doctorants ENSAM”&lt;/h3>
&lt;p>Présentations de 5 projets doctoraux de l’équipe Présence et Innovation du LAMPA
et des Arts et Métiers. Les thématiques abordées sont les agents virtuels, d’incarnation
d’avatars, d’apprentissage en RV et de santé.&lt;/p>
&lt;h3 id="10h20-pause">10h20 Pause&lt;/h3>
&lt;h3 id="10h45-atelier-prospectif">10h45 Atelier Prospectif&lt;/h3>
&lt;h3 id="12h-clôture">12h Clôture&lt;/h3></description></item><item><title>Journées plénières du GdR IG-RV</title><link>https://gdr-igrv.fr/event/pleniere2023/</link><pubDate>Tue, 30 May 2023 12:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/pleniere2023/</guid><description>&lt;p>Programme scientifique en construction.&lt;/p></description></item><item><title>Territoires et immersions</title><link>https://gdr-igrv.fr/event/journee-territoires-immersions-2023/</link><pubDate>Thu, 11 May 2023 10:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee-territoires-immersions-2023/</guid><description>&lt;p>Les progrès technologiques de ces dernières décennies et l’intérêt croissant pour les doubles numériques des espaces construits ont conféré à la 3D une place majeure, avec une production massive de données représentant les territoires à différentes échelles et dont la captation, la manipulation, l’analyse, et la restitution mobilisent diverses techniques à la croisée des domaines des sciences de l’information géographique et de l’informatique graphique. L’introduction de nouvelles modalités d’utilisation de ces données ouvre la voie à une meilleure compréhension des territoires d’étude : il est ainsi possible de faire converger différents états passés, présents, futurs, ou hypothétiques d’un même territoire, de modéliser ou simuler différents processus, d’étudier le ressenti des usagers… En bouleversant la place du sujet face aux données qu’il manipule, la réalité augmentée permet de compléter in situ des représentations de territoires avec des éléments normalement invisibles ou non encore construits et la réalité virtuelle offre d’aller dorénavant « au-delà de la 3D » en révélant des potentialités ou des réalités alternatives. A travers cette journée d’étude centrée sur les modes de visualisation, nous proposons de partager les avancées de la recherche sur ces enjeux, d’en soulever des perspectives et thématiques émergentes, mais aussi d’échanger autour de retours d’expériences sur des objets d’étude particuliers.&lt;/p>
&lt;p>&lt;strong>Liste de thèmes (non exhaustif) :&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Dispositifs techniques d’immersion&lt;/li>
&lt;li>Usages de l’immersion&lt;/li>
&lt;li>Modalités sensorielles&lt;/li>
&lt;li>Modalités d’interaction&lt;/li>
&lt;li>Visualisation multidimensionnelle&lt;/li>
&lt;li>Territoires augmentés&lt;/li>
&lt;li>Immersive/situated analytics&lt;/li>
&lt;li>Visualisation sur site&lt;/li>
&lt;/ul>
&lt;p>Il est prévu une démonstration de l&amp;rsquo;outil d&amp;rsquo;immersion Coraulis&lt;/p>
&lt;p>&lt;strong>Organisateurs :&lt;/strong> Myriam Servières, Vincent Tourre, Violette Abergel, Xavier Granier, Mehdi Chayani&lt;/p>
&lt;p>&lt;strong>Comité d&amp;rsquo;organisation local :&lt;/strong> Véronique Dom&lt;/p>
&lt;p>Le programme est ici : &lt;a href="https://github.com/VCityTeam/MAGIS-AP3D/blob/master/Media/JourneeTerritoires_et_immersions.md" target="_blank" rel="noopener">https://github.com/VCityTeam/MAGIS-AP3D/blob/master/Media/JourneeTerritoires_et_immersions.md&lt;/a>&lt;/p></description></item><item><title>Retour mobilités inter-laboratoires 2022</title><link>https://gdr-igrv.fr/post/23-04-28-retours-mobilites/</link><pubDate>Fri, 28 Apr 2023 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/23-04-28-retours-mobilites/</guid><description>&lt;p>&lt;em>L&amp;rsquo;action de mobilité entre laboratoires français via le financement de court séjour d&amp;rsquo;un doctorant ou d&amp;rsquo;un enseignant-chercheur/chercheur du GdR a permis la réalisation de 5 mobilités en 2022.&lt;/em>&lt;/p>
&lt;h3 id="myriam-servieres--aau-nantes--lab-sticc-brest--8-9-décembre-2022">Myriam Servieres – AAU (Nantes) / Lab-STICC (Brest) – 8-9 décembre 2022&lt;/h3>
&lt;figure id="figure-exemple-de-reprojection-en-réalité-augmentée-dune-maquette-urbaine-25d-sur-site">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Exemple de reprojection en Réalité Augmentée d&amp;#39;une maquette urbaine 2,5D sur site" srcset="
/post/23-04-28-retours-mobilites/myriam1_hu05c4f0a142292c4bbb2ef93a53ddbc36_1023014_24892c166e53527f877492c285508548.webp 400w,
/post/23-04-28-retours-mobilites/myriam1_hu05c4f0a142292c4bbb2ef93a53ddbc36_1023014_ab6706a7ba6d8e31ffe55cd1a74ae705.webp 760w,
/post/23-04-28-retours-mobilites/myriam1_hu05c4f0a142292c4bbb2ef93a53ddbc36_1023014_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/myriam1_hu05c4f0a142292c4bbb2ef93a53ddbc36_1023014_24892c166e53527f877492c285508548.webp"
width="760"
height="528"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Exemple de reprojection en Réalité Augmentée d&amp;rsquo;une maquette urbaine 2,5D sur site
&lt;/figcaption>&lt;/figure>
&lt;p>La visite du jeudi 8 au vendredi 9 décembre sur le site de l’IMT Atlantique de Myriam Servières a permis de renforcer les collaborations entre les équipes AAU - Crénau et Lab-STICC - INUIT. Le groupe de recherche 3V d&amp;rsquo;AAU se concentre sur le triptyque vision-visibilité-visualisation qui articule l&amp;rsquo;utilisation de données urbaines 3D spatiales et temporelles avec la primauté de l&amp;rsquo;aspect visuel et l&amp;rsquo;instrumentation numérique. L&amp;rsquo;équipe INUIT se focalise sur des solutions technologiques immersives et leur évaluation pour améliorer leur naturalité et se concentre sur la proposition ou l’amélioration de ces dispositifs d’interactions. Lors de cette visite, des collaborations portant sur la perception des visibilités et des affordances dans un contexte urbain (perception d&amp;rsquo;ambiances lumineuses, perception des vulnérabilités pour une ville inclusive) ont notamment été initiées.&lt;/p>
&lt;h3 id="charline-grenier--icube-strasbourg--liris-lyon--novembre-2022">Charline Grenier – ICube (Strasbourg) / LIRIS (Lyon) – novembre 2022&lt;/h3>
&lt;p>
&lt;figure id="figure-représentation-dun-terrain-à-deux-étapes-dédition-par-un-artiste">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Représentation d&amp;#39;un terrain à deux étapes d&amp;#39;édition par un artiste" srcset="
/post/23-04-28-retours-mobilites/charline1_hu1843963492ea4dd6523f38cabcb0fb96_1759404_af661668f8333339c78518dc05c31fc1.webp 400w,
/post/23-04-28-retours-mobilites/charline1_hu1843963492ea4dd6523f38cabcb0fb96_1759404_d851018ecd14b8ff16caea81ce902b99.webp 760w,
/post/23-04-28-retours-mobilites/charline1_hu1843963492ea4dd6523f38cabcb0fb96_1759404_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/charline1_hu1843963492ea4dd6523f38cabcb0fb96_1759404_af661668f8333339c78518dc05c31fc1.webp"
width="760"
height="285"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Représentation d&amp;rsquo;un terrain à deux étapes d&amp;rsquo;édition par un artiste
&lt;/figcaption>&lt;/figure>
&lt;figure id="figure-exemples-de-motifs-procéduraux-structurés">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Exemples de motifs procéduraux structurés" srcset="
/post/23-04-28-retours-mobilites/charline2_hu18774e19196f82bf9be7504bf3df1f71_387996_028f5d24e713430d68f36dff028f9d76.webp 400w,
/post/23-04-28-retours-mobilites/charline2_hu18774e19196f82bf9be7504bf3df1f71_387996_b1f651ae26d93a04a9800c973df1dbf6.webp 760w,
/post/23-04-28-retours-mobilites/charline2_hu18774e19196f82bf9be7504bf3df1f71_387996_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/charline2_hu18774e19196f82bf9be7504bf3df1f71_387996_028f5d24e713430d68f36dff028f9d76.webp"
width="760"
height="214"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Exemples de motifs procéduraux structurés
&lt;/figcaption>&lt;/figure>&lt;/p>
&lt;p>Dans le cadre d&amp;rsquo;une thèse menée au laboratoire ICube portant sur la génération et le rendu de textures procédurales, en particulier la synthèse de motifs structurés, une collaboration avec l&amp;rsquo;équipe Origami du LIRIS a été initiée à Lyon. Eric Guérin y travaille sur la création, l&amp;rsquo;édition et le rendu de terrains virtuels. Il a été constaté que des détails structurés présents dans les paysages réels sont difficiles à générer et à contrôler en utilisant les méthodes spécifiques à la génération de terrains. Ainsi, les méthodes de génération de textures structurées ont été explorées en vue de leur utilisation pour la génération de terrains, les algorithmes de synthèse de textures permettant une génération procédurale, à la volée et offrant un bon contrôle du résultat final.&lt;/p>
&lt;h3 id="boris-bordeaux--lib-dijon--imag-montpellier--12-16-décembre-2022">Boris Bordeaux – LIB (Dijon) / IMAG (Montpellier) – 12-16 décembre 2022&lt;/h3>
&lt;figure id="figure-illustration-du-lien-entre-les-empilements-de-sphères-et-le-modèle-bc-ifs-gauche-et-centre-exemple-3d-dempilements-de-sphères-droite">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Illustration du lien entre les empilements de sphères et le modèle BC-IFS (gauche et centre), Exemple 3D d&amp;#39;empilements de sphères (droite)" srcset="
/post/23-04-28-retours-mobilites/boris12_hu036c17802d5fe26f48480c161d879ffc_840337_65ea3045e82dcbf5625ba2b5e7d2f9cb.webp 400w,
/post/23-04-28-retours-mobilites/boris12_hu036c17802d5fe26f48480c161d879ffc_840337_6c685e8397d07f4b4acf1b1742629f9c.webp 760w,
/post/23-04-28-retours-mobilites/boris12_hu036c17802d5fe26f48480c161d879ffc_840337_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/boris12_hu036c17802d5fe26f48480c161d879ffc_840337_65ea3045e82dcbf5625ba2b5e7d2f9cb.webp"
width="760"
height="232"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Illustration du lien entre les empilements de sphères et le modèle BC-IFS (gauche et centre), Exemple 3D d&amp;rsquo;empilements de sphères (droite)
&lt;/figcaption>&lt;/figure>
&lt;p>La mobilité s’inscrit dans le cadre d’un projet visant à concevoir des structures
lacunaires fractales. Le LIB développe des modèles itératifs codant la topologie de structures
fractales. Cependant la conception des structures 3D reste une démarche complexe et manuelle.
D’autre part, l’IMAG développe des méthodes automatiques de construction d’empilements de
sphères, produisant des structures fractales. La complémentarité des approches permet d’envisager
de développer des méthodes de conceptions automatiques et paramétrables de structures lacunaires
3D.&lt;/p>
&lt;h3 id="manon-vialle--ljk-grenoble--ex-situ-paris-saclay--novembre-décembre-2022">Manon Vialle – LJK (Grenoble) / Ex-Situ (Paris-Saclay) – novembre-décembre 2022&lt;/h3>
&lt;figure id="figure-danseur-professionnel-utilisant-le-système-gauche-exemple-de-visualisation-droite">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Danseur professionnel utilisant le système (gauche), Exemple de visualisation (droite)" srcset="
/post/23-04-28-retours-mobilites/manon12_huab49302ee272980f5597d400c47ae82b_2148048_6dea2bdbd120a40ba61f3b250fa07198.webp 400w,
/post/23-04-28-retours-mobilites/manon12_huab49302ee272980f5597d400c47ae82b_2148048_1bc2a56ec8df231b291ae567912482e7.webp 760w,
/post/23-04-28-retours-mobilites/manon12_huab49302ee272980f5597d400c47ae82b_2148048_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/manon12_huab49302ee272980f5597d400c47ae82b_2148048_6dea2bdbd120a40ba61f3b250fa07198.webp"
width="760"
height="282"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Danseur professionnel utilisant le système (gauche), Exemple de visualisation (droite)
&lt;/figcaption>&lt;/figure>
&lt;p>Cette mobilité s&amp;rsquo;inscrit dans le cadre du projet Isadora, une archive vivante élaborée en collaboration avec les équipes Inria Anima et Ex-Situ, le Centre National de la Danse, la danseuse Elisabeth Schwartz et le mocaplab. Le travail de la thèse associée a consisté à élaborer des modèles abstraits du corps des danseurs pour transmettre des qualités intrinsèques de mouvement telles que la fluidité.
Sa thèse a évolué vers un sujet beaucoup plus centré sur l&amp;rsquo;Interaction Humain Machine, notamment dans le cadre de son deuxième projet sur la spatialisation du mouvement. Pour répondre à ces nouveaux défis, cette mobilité de 6 semaines a permis une formation en profondeur dans ce domaine au sein du laboratoire Ex-situ pour profiter de leur expertise et suivre les formations proposées par les membres de l&amp;rsquo;équipe et la faculté de Paris Saclay, ainsi qu’un formation en danse avec la danseuse Elisabeth Schwartz. De plus, un prototype de spatialisation du mouvement en réalité augmentée a été mis au point, en se basant sur une collaboration étroite avec Elisabeth Schwarz et en suivant une méthode de co-design. Ce prototype a été testé et évalué lors d’un workshop avec des danseurs. Tous ces travaux ont mené à une publication à venir dans la conférence Creativity and Cognition 2023.&lt;/p>
&lt;h3 id="florian-beguet--lis-marseille--lib-dijon--décembre-2022">Florian Beguet – LIS (Marseille) / LIB (Dijon) – décembre 2022&lt;/h3>
&lt;figure id="figure-a-morceau-dune-brique-fragmentée-sur-lequel-est-plaqué-la-dimension-de-corrélation-b-graphe-de-reeb-correspondant-à-a-c-segmentation-de-la-brique-à-partir-dun-partitionnement-du-graphe">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="A. Morceau d’une brique fragmentée sur lequel est plaqué la dimension de corrélation. B. Graphe de Reeb correspondant à A. C. Segmentation de la brique à partir d’un partitionnement du graphe" srcset="
/post/23-04-28-retours-mobilites/florian1_huf664376d31a2a3a4cd08d922419f6fe8_520290_624ebd8bb7cdbbe7698c102f4c792c4d.webp 400w,
/post/23-04-28-retours-mobilites/florian1_huf664376d31a2a3a4cd08d922419f6fe8_520290_78fb2a621001e25e6fba4f87ac96a38a.webp 760w,
/post/23-04-28-retours-mobilites/florian1_huf664376d31a2a3a4cd08d922419f6fe8_520290_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/florian1_huf664376d31a2a3a4cd08d922419f6fe8_520290_624ebd8bb7cdbbe7698c102f4c792c4d.webp"
width="760"
height="291"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
A. Morceau d’une brique fragmentée sur lequel est plaqué la dimension de corrélation. B. Graphe de Reeb correspondant à A. C. Segmentation de la brique à partir d’un partitionnement du graphe
&lt;/figcaption>&lt;/figure>
&lt;p>Cette mobilité se place dans le cadre du projet de recherche intitulé &amp;ldquo;Caractérisation de pièces archéologiques&amp;rdquo;, en collaboration entre le laboratoire LIB de l&amp;rsquo;Université de Bourgogne, le laboratoire ArteHis de Dijon et l&amp;rsquo;USTH de Hanoi (Vietnam). L&amp;rsquo;objectif de ce projet est de caractériser les zones de fracture sur des modèles archéologiques numérisés afin de les apparier et les reconstruire. Une méthode basée sur l&amp;rsquo;utilisation d&amp;rsquo;un graphe de Reeb, calculé sur une fonction d&amp;rsquo;indice de forme, a été développée pour extraire des caractéristiques autosimilaires avec des contraintes a priori sur une surface maillée. Cette mobilité a été effectuée dans l&amp;rsquo;optique de présenter ces travaux aux équipes impliquées dans le projet ainsi que les deux hypothèses suivantes. La première hypothèse est que cette approche pourrait être appliquée pour l&amp;rsquo;extraction de zones de fractures en modifiant la fonction d&amp;rsquo;indice de forme avec une fonction basée sur la géométrie mais plus adaptée. Des premiers résultats issus des discussions avec les équipes ont permis d’identifier une fonction de rugosité basée sur la dimension de corrélation. Le graphe de Reeb de cette fonction a ensuite permis d’isoler les régions rugueuses correspondantes aux zones fracturés. La seconde hypothèse abordée a été qu’une approche multi-résolution permettrait d&amp;rsquo;éviter l&amp;rsquo;influence du bruit pour la détection des fractures tout en conservant les informations importantes pour l&amp;rsquo;appariement.&lt;/p>
&lt;h3 id="phuc-ngo--loria-nancy--greyc-caen--décembre-2022">Phuc Ngo – Loria (Nancy) / GREYC (Caen) – décembre 2022&lt;/h3>
&lt;figure id="figure-exemples-de-courbes-tangentielles-adaptatives-sur-des-courbes-numériques-bruitées-en-2d-et-3d">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Exemples de courbes tangentielles adaptatives sur des courbes numériques bruitées en 2D et 3D" srcset="
/post/23-04-28-retours-mobilites/phuc1_hu8213736187bcd5b0f03ce3d45078c0a8_44210_82d20a86fc609d268280bfbab56c07a7.webp 400w,
/post/23-04-28-retours-mobilites/phuc1_hu8213736187bcd5b0f03ce3d45078c0a8_44210_7d75592d6e8c1c6ef2639595b7873694.webp 760w,
/post/23-04-28-retours-mobilites/phuc1_hu8213736187bcd5b0f03ce3d45078c0a8_44210_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/23-04-28-retours-mobilites/phuc1_hu8213736187bcd5b0f03ce3d45078c0a8_44210_82d20a86fc609d268280bfbab56c07a7.webp"
width="760"
height="253"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Exemples de courbes tangentielles adaptatives sur des courbes numériques bruitées en 2D et 3D
&lt;/figcaption>&lt;/figure>
&lt;p>Pendant son séjour, Phuc Ngo a été accueillie par Mme Kenmochi ainsi que les membres de l&amp;rsquo;équipe Image. Les travaux de recherche ont été présentés devant l&amp;rsquo;équipe, se concentrant notamment sur le thème de l&amp;rsquo;&amp;ldquo;Étude géométrique des courbes discrètes bruitées&amp;rdquo;. Des discussions enrichissantes ont eu lieu sur ce sujet, avec des propositions de collaboration pour l&amp;rsquo;exploration d&amp;rsquo;applications liées aux Line-arts.&lt;/p></description></item><item><title>Journées du GTMG</title><link>https://gdr-igrv.fr/event/journee_gtmg2023/</link><pubDate>Wed, 15 Mar 2023 11:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtmg2023/</guid><description/></item><item><title>Remise du prix de thèse du GdR et des associations 2022</title><link>https://gdr-igrv.fr/post/22-11-23-remiseprix/</link><pubDate>Wed, 23 Nov 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-11-23-remiseprix/</guid><description>&lt;p>À l&amp;rsquo;occasion des &lt;a href="https://project.inria.fr/jfig2022/" target="_blank" rel="noopener">Journées Françaises de l&amp;rsquo;Informatique Graphique&lt;/a>, le &lt;a href="https://gdr-igrv.fr/actions/prix-these/" target="_blank" rel="noopener">prix de thèse&lt;/a> du GdR a pu être remis à
&lt;strong>Marie-Julie Rakotosaona&lt;/strong> pour sa thèse intitulée « Learning-based representations and methods for 3D shape analysis, manipulation and reconstruction » effectuée sous la direction de Maks Ovsjanikov (Ecole Polytechnique), ainsi qu&amp;rsquo;a l&amp;rsquo;accessit &lt;strong>Mickael Ly&lt;/strong> pour sa thèse intitulée « Static inverse modelling of cloth » effectuée sous la direction de Florence Bertails-Descoubes et Mélina Skouras (Université Grenoble Alpes).&lt;/p>
&lt;p>Le prix a été remis par les organisateurs du Prix de thèse loic-barthe (Univ Toulouse) et &lt;a href="https://gdr-igrv.fr/author/guillaume-cordonnier/">Guillaume Cordonnier&lt;/a> (INRIA CRISAM), ainsi que les présidents de l&amp;rsquo;AFIG, &lt;strong>Basile Sauvage&lt;/strong> et du Chapitre Français d&amp;rsquo;Eurographics (EGFR), &lt;strong>Eric Guérin&lt;/strong>.&lt;/p>
&lt;p>&lt;em>(photos Adrien Peytavie)&lt;/em>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_172723_hud3ce0b3b38481c0ea27135a835283fab_2805756_60b365b34ce9cb27b1df7769ea051c72.webp 400w,
/post/22-11-23-remiseprix/20221123_172723_hud3ce0b3b38481c0ea27135a835283fab_2805756_29cf4ae4033e9529308c996cd84b1c00.webp 760w,
/post/22-11-23-remiseprix/20221123_172723_hud3ce0b3b38481c0ea27135a835283fab_2805756_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_172723_hud3ce0b3b38481c0ea27135a835283fab_2805756_60b365b34ce9cb27b1df7769ea051c72.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_172743_hua50e7117982b565cc0b0f764b8b3b9d2_2114314_ba3b286d4bea5575349094bd89907b71.webp 400w,
/post/22-11-23-remiseprix/20221123_172743_hua50e7117982b565cc0b0f764b8b3b9d2_2114314_45cfbb7253322098b5a56744af4aa7a0.webp 760w,
/post/22-11-23-remiseprix/20221123_172743_hua50e7117982b565cc0b0f764b8b3b9d2_2114314_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_172743_hua50e7117982b565cc0b0f764b8b3b9d2_2114314_ba3b286d4bea5575349094bd89907b71.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_174320_hu69382911a582d6fbf3859e12ac368478_2303140_8efe182c2c115d143687c91e793400ee.webp 400w,
/post/22-11-23-remiseprix/20221123_174320_hu69382911a582d6fbf3859e12ac368478_2303140_96f2169970216653a294afc252bc33de.webp 760w,
/post/22-11-23-remiseprix/20221123_174320_hu69382911a582d6fbf3859e12ac368478_2303140_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_174320_hu69382911a582d6fbf3859e12ac368478_2303140_8efe182c2c115d143687c91e793400ee.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_173620_hufb48cd73a43893dd483037dc398548de_2050686_fa015a34a99a42d6374f7fd80c354532.webp 400w,
/post/22-11-23-remiseprix/20221123_173620_hufb48cd73a43893dd483037dc398548de_2050686_0622becc3ce7aae721acc505e9d6fc89.webp 760w,
/post/22-11-23-remiseprix/20221123_173620_hufb48cd73a43893dd483037dc398548de_2050686_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_173620_hufb48cd73a43893dd483037dc398548de_2050686_fa015a34a99a42d6374f7fd80c354532.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-11-23-remiseprix/20221123_173654_hu51f8342bdb8708cc4a8c61c715f51df8_2813139_da9e11338f69ae7a0640206fd081b5d6.webp 400w,
/post/22-11-23-remiseprix/20221123_173654_hu51f8342bdb8708cc4a8c61c715f51df8_2813139_f48b5af28d78b8d9f359a668ba2323d2.webp 760w,
/post/22-11-23-remiseprix/20221123_173654_hu51f8342bdb8708cc4a8c61c715f51df8_2813139_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-11-23-remiseprix/20221123_173654_hu51f8342bdb8708cc4a8c61c715f51df8_2813139_da9e11338f69ae7a0640206fd081b5d6.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Journée du GT GDMM</title><link>https://gdr-igrv.fr/event/gdmm2022/</link><pubDate>Tue, 22 Nov 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/gdmm2022/</guid><description>&lt;p>Elle précède les journées françaises de l&amp;rsquo;informatique graphique. Les participants à la journée du GT qui le souhaitent pourront assister sans frais aux sessions du matin le 23 novembre.&lt;/p>
&lt;h1 id="la-géométrie-discrète">La géométrie discrète&lt;/h1>
&lt;p>Le contexte de la géométrie discrète s’intègre dans le cadre général de la modélisation et l’analyse géométrique et topologique d’objets définis sur des structures régulières (ex. des grilles de pixels ou de voxels) ou combinatoires (graphes, cartes, etc.). Généralement, les axiomes et propriétés de la géométrie euclidienne classique ne sont plus valides lorsque l’on considère des ensembles de pixels. La définition de concepts et notions adaptés à des structures discrètes, mais néanmoins compatibles avec les concepts et notions continus, est alors requise. L’originalité de cette approche réside dans le fait qu’en exploitant les propriétés du support sur lequel sont décrits les objets, nous pouvons obtenir des algorithmes efficaces, certifiés et précis pour répondre à des problèmes de caractérisation géométrique ou topologique d’objets discrets (2D, 3D, nD, etc.). Le caractère discret des données à traiter, et donc l’utilité de l’approche discrète, se retrouvent dans de nombreux contextes applicatifs (analyse et traitements d’images, imagerie médicale, ingénierie des matériaux, etc.).&lt;/p>
&lt;h1 id="la-morphologie-mathématique">La morphologie mathématique&lt;/h1>
&lt;p>La morphologie mathématique est une théorie essentiellement non-linéaire, utilisée en particulier en analyse d’images, dont le but est l&amp;rsquo;étude des objets en fonction de leur forme, de leur taille, des relations avec leur voisinage (en particulier topologiques), de leur texture, et de leurs niveaux de gris ou de leur couleur. Par les transformations qu’elle propose, elle se situe à différents niveaux du traitement d’images (filtrage, segmentation, mesures, analyse de texture) et fournit ainsi des outils pour la reconnaissance des formes. La morphologie mathématique, développée à l’origine pour l&amp;rsquo;étude des matériaux poreux, trouve maintenant ses applications dans de nombreux domaines du traitement d’images, aussi bien 2D que 3D, en biologie et cytologie quantitative, en imagerie médicale, en imagerie aérienne et satellitaire, en robotique et vision par ordinateur, en contrôle industriel non destructif, dans les études sur les documents et les œuvres d’art. Hors du domaine du traitement des images, on trouve des applications par exemple en analyse de données, ou encore en théorie des jeux.&lt;/p></description></item><item><title>Evelyn Paiz - Visual exploration of historical image collections: an interactive approach through space and time</title><link>https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/</link><pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/</guid><description>&lt;h3 id="what-is-your-current-research-status">What is your current research status?&lt;/h3>
&lt;p>Last year, I finished my PhD at IGN, and defended it in December 2021. I&amp;rsquo;m currently a research and development engineer at Viceversa, a company that aims at transferring object from the real world to the metaverse. For example, a company could own this object and visualize it online. This can also be used for gaming applications.&lt;/p>
&lt;h3 id="can-you-describe-your-research-work-during-your-phd">Can you describe your research work during your PhD?&lt;/h3>
&lt;p>It was how to visualize digitally historical images. My lab was acquiring a lot of pictures and gather them from other institutions. The objective of the PhD was to present a method for people to visualize these pictures digitally, in 3D, and to explore these pictures in time and space. There were two topics. The first was the rendering of these images: how to render these 2D images in 3D? This includes the issue of the distortion of the pictures during acquisition and how to manage this distortion while projecting the image in a 3D space. We came up with a method to extrapolate the distortion function of these images to be able to correct them during the projection. The second topic was more about how user can interact with the pictures in the 3D space. We presented to the users different methods to be able to interact with the pictures.&lt;/p>
&lt;figure id="figure-3d-city-model-and-various-projected-2d-images">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="3D city model and various projected 2D images. " srcset="
/post/22-10-18-jc-evelynpaiz/image1_hu0a3f105d61626774883345e89c18e174_334289_9ff28b603e9d83b328253b6fd8460143.webp 400w,
/post/22-10-18-jc-evelynpaiz/image1_hu0a3f105d61626774883345e89c18e174_334289_07bde55e15ad20bd96854a1c01c6e0c0.webp 760w,
/post/22-10-18-jc-evelynpaiz/image1_hu0a3f105d61626774883345e89c18e174_334289_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/image1_hu0a3f105d61626774883345e89c18e174_334289_9ff28b603e9d83b328253b6fd8460143.webp"
width="747"
height="587"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
3D city model and various projected 2D images.
&lt;/figcaption>&lt;/figure>
&lt;p>We had different types of data: 2D images but also 3D models, a bit like Google Maps where you can have those two kinds of visualization. IGN has this kind of data for France, and we were using these 3D data and project our &amp;ldquo;old&amp;rdquo; pictures on the model to be able to fill the voids of the images. I was focusing on the distortion part, for the user to have a rectangular image. When you do a projection of a 3D model, you must consider the distortion, otherwise you will have a distortion between the 3D world and the 2D image. If you consider it, your image will be distorted, and you have to correct its shape.&lt;/p>
&lt;p>The second part of the PhD was more tackling how the user can interact with these images when they are in 3D. I was exploring methods like heatmaps, viewpoint markers, adding frames or color values to the images for user to be able to quickly find images among many in 3D.&lt;/p>
&lt;figure id="figure-heatmaps-projected-over-the-3d-scenes-composed-of-point-cloud-geometries">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Heatmaps projected over the 3D scenes composed of point cloud geometries. " srcset="
/post/22-10-18-jc-evelynpaiz/image2_hu6bbd2543e9e115d97f1f9e325937b4e6_192053_26d76d2c3be9b7e954c77fdd9958ff4c.webp 400w,
/post/22-10-18-jc-evelynpaiz/image2_hu6bbd2543e9e115d97f1f9e325937b4e6_192053_269870c228f9c9ecab677a14c76b6b09.webp 760w,
/post/22-10-18-jc-evelynpaiz/image2_hu6bbd2543e9e115d97f1f9e325937b4e6_192053_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/image2_hu6bbd2543e9e115d97f1f9e325937b4e6_192053_26d76d2c3be9b7e954c77fdd9958ff4c.webp"
width="760"
height="433"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Heatmaps projected over the 3D scenes composed of point cloud geometries.
&lt;/figcaption>&lt;/figure>
&lt;p>We presented the images to the user on a screen, to be able to explore the web option. Images came from different institutions, and they all wanted to connect to the same platform. For the interaction we wanted the users to be able to go to the point of view where the image was taken, to be able to see what happen between the contemporary 3D model and the old data that came from the pictures. We also had a timeline where the user was able to filter, for example, just the images of a specific time.&lt;/p>
&lt;figure id="figure-a-timeline-next-to-3d-view-in-histovis-only-five-photos-1946-are-shown-from-the-filtered-selection-credits-to-ignfrejus-collection">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="A timeline next to 3D view in HISTOVIS. Only five photos (1946) are shown from the filtered selection. Credits to IGN/Frejus collection." srcset="
/post/22-10-18-jc-evelynpaiz/image3_hu218bf9f3debedd4e547b8ac03499eacd_571553_ba5ae24f8f0acab802044b992f32db04.webp 400w,
/post/22-10-18-jc-evelynpaiz/image3_hu218bf9f3debedd4e547b8ac03499eacd_571553_33097a98e4848f35a9d9c678d7d4c0a2.webp 760w,
/post/22-10-18-jc-evelynpaiz/image3_hu218bf9f3debedd4e547b8ac03499eacd_571553_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-10-18-jc-evelynpaiz/image3_hu218bf9f3debedd4e547b8ac03499eacd_571553_ba5ae24f8f0acab802044b992f32db04.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
A timeline next to 3D view in HISTOVIS. Only five photos (1946) are shown from the filtered selection. Credits to IGN/Frejus collection.
&lt;/figcaption>&lt;/figure>
&lt;p>The targeted end users were mainly researchers: historian, archivists since we were working with museums. Actually, my PhD was funded by the Alegoria project. The objective was to valorize historical images. This project was conducted by the IGN, the National Archives, and the Nicéphore Niépce Museum.&lt;/p>
&lt;h3 id="what-is-your-proudest-research-result">What is your proudest research result?&lt;/h3>
&lt;p>I wouldn&amp;rsquo;t cite something specific but rather just reaching and showing the results that I was getting to the final users. When we were working in the Alegoria project, we were having meetings every 6 months and I was able to show results, received feedback and was able to improve on this. I liked that part a lot.&lt;/p>
&lt;h3 id="what-are-your-long-term-perspectives-you-are-working-in-the-industry-now-are-you-done-with-academia">What are your long-term perspectives? You are working in the industry now. Are you done with academia?&lt;/h3>
&lt;p>I think academia was not my long-term target. I did a PhD because I wanted to explore a bit more about research, but I knew that I didn&amp;rsquo;t want to become a teacher. I wanted to go back to industry when the PhD was done. Since I am in the research department of my company, I can still do research but it has some benefits, like being able to produce things faster. We can give to the user some products while sometimes, the users will never see what you do in academic research.&lt;/p>
&lt;h3 id="what-do-you-currently-work-on-in-your-company">What do you currently work on in your company?&lt;/h3>
&lt;p>It&amp;rsquo;s a brand-new company, I just started this month. We are created digital models of luxurious brands. The brands come to create digital models from products that they have, and we use photogrammetry to reproduce the objects. We are also trying to improve the methods they are using to add techniques like photometry to be able to reproduce the objects more accurately. In the end, it enables brands to offer both virtual and real products.&lt;/p>
&lt;h3 id="interesting-and-what-would-be-the-final-utility-of-such-virtual-products">Interesting, and what would be the final utility of such virtual products?&lt;/h3>
&lt;p>We will see in the future! But we envision uses where you can combine the physical and the virtual object to be able to control and to use the virtual object thanks to the real one. Though, my job is more on the technical, photogrammetry and computer graphics side. I also have a background on color science, so that is why we will be working in photometry too.&lt;/p>
&lt;h3 id="are-there-some-collaborations-with-the-gdr-that-would-be-interesting-in-your-current-work">Are there some collaborations with the GDR that would be interesting in your current work?&lt;/h3>
&lt;p>We have no ongoing collaborations with GDR members yet. Nevertheless, it could be a possibility. We are currently interested in exploring new topics regarding graphics, vision, and even virtual reality. I think GDR is a good place to search for all of these research subjects.&lt;/p>
&lt;p>&lt;em>Thank you for your presentation and time. I&amp;rsquo;m sure it would be very interesting for future collaboration, and also for PhD students that are wondering what could be done in industry after a PhD!&lt;/em>&lt;/p></description></item><item><title>Zoom sur... Les collaborations du GDR IG-RV avec le GDR MAGIS et MADICS autour des sciences de l’information géographique</title><link>https://gdr-igrv.fr/post/22-08-25-info-geo-gillesg/</link><pubDate>Thu, 25 Aug 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-08-25-info-geo-gillesg/</guid><description>&lt;p>&lt;em>&lt;a href="https://liris.cnrs.fr/page-membre/gilles-gesquiere" target="_blank" rel="noopener">&lt;strong>Gilles Gesquière&lt;/strong>&lt;/a> présente les activités transverses entre les GDR IG-RV et les GDR MAGIS et MADICS autour des sciences de l’information géographique qu&amp;rsquo;il coordonne :&lt;/em>&lt;/p>
&lt;p>Je suis membre du Laboratoire LIRIS, UMR 5205. Je fais partie de la communauté informatique graphique, où j’ai travaillé en modélisation géométrique (surfaces implicites, déformations de maillages, reconstruction par ingénierie inverse, …). Depuis 2008, mes recherches sont plus axées vers les représentations et la dynamique de la ville. On y retrouve un besoin très fort en informatique graphique, en particulier avec une présence toujours plus importante de données 3D (polygones, mais aussi nuages de points) représentant l’intérieur, ou l’extérieur de bâtiments, voire des territoires plus vastes sur des milliers de km2. Nos recherches amènent à aller au-delà de l’informatique graphique. C’est en ce sens que le projet que je dirige depuis 2013 (&lt;a href="https://projet.liris.cnrs.fr/vcity/" target="_blank" rel="noopener">Projet Vcity&lt;/a>) est constitué de spécialistes en informatique graphique, mais aussi en sciences de données, deux expertises fortes au laboratoire LIRIS. Un lien très fort est mis en place avec des entreprises et collectivités.
Cette recherche, au service des territoires, mêle informatique graphique avec les sciences de l’information géographique et peut donc se retrouver à l’interface entre plusieurs GDR. Le GDR IG-RV y apporte ses compétences en modélisation géométrique, mais aussi rendu, visualisation et réalité virtuelle et/ ou augmentée. Le GDR Magis apporte ses compétences en informatique (en particulier sciences des données), mais aussi géographie afin de permettre une meilleure compréhension des données, mais aussi des possibles usages. Il est aussi facile de faire des liens avec les GDR MADICS ou le GDR ISIS sur l’observation de la terre, l’acquisition des données grâce à des capteurs toujours plus performants, et la reconstruction 3D. C’est d’ailleurs en ce sens que nous organisons des évènements conjoints (voir par exemple la &lt;a href="https://github.com/VCityTeam/MAGIS-AP3D/blob/master/Media/JourneeObservation3D.md" target="_blank" rel="noopener">journée d’étude entre GDR MAGIS, MADICS et IG-RV en novembre 2021&lt;/a>. Nous organisons aussi depuis deux ans un webinaire sur la 3D et le géospatial ; il a lieu tous les premiers jeudi de chaque mois de 12h30 à 13h30. Il s’agit de profiter de ces moments pour renforcer encore les liens entre les GDR, en particulier en croisant les expertises (voir &lt;a href="https://github.com/VCityTeam/MAGIS-AP3D/blob/master/Media/README.md" target="_blank" rel="noopener">ici&lt;/a>).&lt;/p>
&lt;p>L’avènement des doubles numériques nous amène aujourd’hui à pouvoir profiter de nombreuses données sur nos territoires ; il y a encore 10 ans, les données 3D étaient assez difficiles à obtenir. Comme le montre &lt;a href="https://github.com/VCityTeam/MAGIS-AP3D/blob/master/data.md" target="_blank" rel="noopener">cette liste en cours de construction&lt;/a>, il existe aujourd’hui de nombreuses sources de données représentant des territoires toujours plus vastes, que ce soit sous la forme de données polygonales (enrichie de données attributaires dans des formats comme CityGML ou IFC par exemple), ou de nuages de points. La livraison en cours par l’IGN du nuage de points Haute Définition permettra d’ailleurs d’avoir un échantillon à l’échelle de la France entière (à voir &lt;a href="https://geoservices.ign.fr/lidarhd" target="_blank" rel="noopener">ici&lt;/a>). Au-delà de cette donnée volumineuse, pouvant souffrir d’erreur d’acquisition, d’erreur dans leur modélisation, il s’agit d’une réelle opportunité d’avoir à disposition des jeux de données qui permettent de mettre en avant les algorithmes que nous développons dans nos laboratoires de recherche. Là encore, le lien avec le GDR Magis, mais aussi avec les entreprises et collectivités permettent de démontrer la forte pertinence de nos algorithmes. Les exemples ne manquent pas et j’en propose ici quelques uns pour illustration.
L’exemple le plus immédiat est la (géo) visualisation de ces données 3D, voire 3D+Temps.&lt;/p>
&lt;figure id="figure-visualisation-3dtemps-de-la-ville-à-gauche-gaillard-et-al-2018-à-droite-jaillot-2020">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Visualisation 3D&amp;#43;temps de la ville (à gauche (Gaillard et al 2018), à droite (Jaillot, 2020))" srcset="
/post/22-08-25-info-geo-gillesg/image1_hu8e05bc591dac43f0cb0f47ae87674aca_1495231_be454da5c57fe7d795dacd5dea0c7974.webp 400w,
/post/22-08-25-info-geo-gillesg/image1_hu8e05bc591dac43f0cb0f47ae87674aca_1495231_cdecb4c1e09df6df823f4dbf43cd63d7.webp 760w,
/post/22-08-25-info-geo-gillesg/image1_hu8e05bc591dac43f0cb0f47ae87674aca_1495231_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-08-25-info-geo-gillesg/image1_hu8e05bc591dac43f0cb0f47ae87674aca_1495231_be454da5c57fe7d795dacd5dea0c7974.webp"
width="760"
height="222"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Visualisation 3D+temps de la ville (à gauche (Gaillard et al 2018), à droite (Jaillot, 2020))
&lt;/figcaption>&lt;/figure>
&lt;p>Prenons un autre exemple avec les problématiques d’intervisibilités et ombres portés. Très vite, les algorithmes de rendus peuvent sur ces grande masse de données apporter des solutions. Comment calculer l’impact de la végétation ou des immeubles de grande hauteur ? Comment calculer, grâce à des informations sémantiques liées aux données 3D, la composition du territoire ou un skyline ?&lt;/p>
&lt;figure id="figure-intervisibilité-et-composition-du-territoire-pédrinis-2017">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Intervisibilité et composition du territoire (Pédrinis, 2017)" srcset="
/post/22-08-25-info-geo-gillesg/image2_hu919a44f9388784fa17122bcbb5413708_285651_30eb5df60cc1bf24c1f323b0aa00989d.webp 400w,
/post/22-08-25-info-geo-gillesg/image2_hu919a44f9388784fa17122bcbb5413708_285651_4e9ec9f1b52befa7d965ab185d5c478c.webp 760w,
/post/22-08-25-info-geo-gillesg/image2_hu919a44f9388784fa17122bcbb5413708_285651_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-08-25-info-geo-gillesg/image2_hu919a44f9388784fa17122bcbb5413708_285651_30eb5df60cc1bf24c1f323b0aa00989d.webp"
width="600"
height="600"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Intervisibilité et composition du territoire (Pédrinis, 2017)
&lt;/figcaption>&lt;/figure>
&lt;p>Ces travaux permettent ensuite d’envisager les possibles évolutions des territoires (ou comment détecter une évolution dans des nuages de points ou des modèles 3D polygonaux ?). Il est nécessaire de mettre en cohérence données 2D et 3D, comportant des erreurs inhérentes à leur création/ acquisition, redécouper une données 3D issue de prises de vues aériennes avec des données cadastrales 2D. Il est aussi nécessaire de comparer les modèles 3D issus de plusieurs millésimes afin de pouvoir mesurer les changements et ainsi apporter des éléments d’évolution de la ville (Pédrinis, 2017), (Jaillot, 2020).
Enfin, il faut pouvoir faire le lien entre données géométriques, mais aussi topologiques et sémantiques, voire aussi avec d’autres médias (photos, images, vidéo). Comment apporter une cohérence entre ces données hétérogènes afin de pouvoir aller plus loin qu’une simple interrogation de la géométrie ? (Jaillot et al, 2021), (Vinasco et al, 2021)&lt;/p>
&lt;p>La constitution du projet Vcity au LIRIS en 2013 permet aujourd’hui de répondre à des besoins à l’interface entre informatique graphique et sciences des données mobilisant les données du territoire. Les expertises nécessaires sont multiples et doivent pouvoir s’orchestrer afin de pouvoir mieux répondre aux challenges auxquels sont confrontés nos territoires. Bien sûr, les compétences nécessaires sont plus nombreuses comme le démontre le recherches menées au sein du &lt;a href="https://imu.universite-lyon.fr/" target="_blank" rel="noopener">LabEx Intelligences des Mondes Urbains&lt;/a> que je dirige depuis 2016 (600 chercheurs, 30 disciplines différentes, et 40 laboratoires réunis).
Au niveau national, les GDR MAGIS et IG-RV apportent de réelles compétence que l’on sait compléter au sein du CNRS par exemple en simulation (INSIS), mais aussi par des compétences plus thématiques (avec l’INEE et l’INSHS (déjà présents en partie au sein du GDR MAgis)). Cette recherche pluridisciplinaire apporte une nouvelle modalité permettant de mettre en avant la qualité des recherches que nous menons en France (voir par exemple la partie territoire du futur du &lt;a href="https://www.cnrs.fr/sites/default/files/download-file/COP_CNRS1_0.pdf" target="_blank" rel="noopener">Contrat d’Objectif et de Performance du CNRS&lt;/a>).&lt;/p>
&lt;h3 id="bibliographie">Bibliographie&lt;/h3>
&lt;ul>
&lt;li>(Gaillard et al, 2018) Jérémy Gaillard, Adrien Peytavie, Gilles Gesquière. Visualisation and personalisation of multi-representations city models. International Journal of Digital Earth, 2018, pp.1-18. ⟨hal-01946770⟩&lt;/li>
&lt;li>(Jaillot, 2020) Vincent Jaillot. 3D, temporal and documented cities : formalization, visualization and navigation. Computer Vision and Pattern Recognition [cs.CV]. Université de Lyon, 2020. English. ⟨NNT : 2020LYSE2026⟩. ⟨tel-03228436⟩&lt;/li>
&lt;li>(Jaillot et al, 2021) Vincent Jaillot, Valentin Rigolle, Sylvie Servigne, John Samuel Samuel, Gilles Gesquière. Integrating multimedia documents and time‐evolving 3D city models for web visualization and navigation. Transactions in GIS, Wiley, 2021, 25 (3), pp.1419-1438. ⟨10.1111/tgis.12734⟩. ⟨hal-03178005⟩&lt;/li>
&lt;li>(Pédrinis, 2017) Frédéric Pedrinis. Représentations et dynamique de la ville virtuelle. Intelligence artificielle [cs.AI]. Université de Lyon, 2017. Français. ⟨NNT : 2017LYSE2092⟩. ⟨tel-01624392v2⟩&lt;/li>
&lt;li>(Vinasco et al, 2021) Diego Vinasco-Alvarez, John Samuel Samuel, Sylvie Servigne, Gilles Gesquière. Towards Limiting Semantic Data Loss In 4D Urban Data Semantic Graph Generation. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2021, VIII-4/W2-2021, pp.37-44. ⟨10.5194/isprs-annals-VIII-4-W2-2021-37-2021⟩. ⟨hal-03375084⟩&lt;/li>
&lt;/ul></description></item><item><title>24èmes journées du Groupe de Travail Animation et Simulation</title><link>https://gdr-igrv.fr/event/journee_gtas2022/</link><pubDate>Tue, 05 Jul 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtas2022/</guid><description>&lt;p>Les prochaines journées du Groupe de Travail Animation et Simulation du GDR IGRV auront lieu du mardi 5 juillet 2022 au mercredi 6 juillet 2022, à Vannes, sur le campus de Tohannic, bâtiment ENSIBS.&lt;/p>
&lt;p>L’objet des Journées du GT AS est triple. Il s’agit :&lt;/p>
&lt;ul>
&lt;li>de partager les avancées de la recherche en animation et simulation,&lt;/li>
&lt;li>de dresser le paysage du domaine en France, et&lt;/li>
&lt;li>d’en préciser les perspectives et les thématiques émergentes.&lt;/li>
&lt;/ul>
&lt;p>Cette année, plusieurs présentations de &lt;strong>travaux et résultats récents&lt;/strong> aborderont des thèmes diversifiés tels que l&amp;rsquo;analyse, la synthèse et l&amp;rsquo;édition de mouvement, la modélisation et la simulation de phénomènes naturels, la capture de mouvements faciaux et du regard, la modélisation et l&amp;rsquo;animation faciale, la synthèse de gestes liés à la prosodie, les aspects multimodaux et multisensoriels dans l&amp;rsquo;animation, l&amp;rsquo;évolution des techniques de motion capture par vidéo, ou encore la synthèse de mouvements de langue des signes.&lt;/p>
&lt;p>Avec un &lt;strong>spectre plus large&lt;/strong>, plusieurs équipes présenteront un panorama pluriannuel de leur thématiques de recherche et de leurs évolutions, ainsi que des avancées de projets collaboratifs auxquelles elles contribuent.&lt;/p>
&lt;p>Les Journées sont également bien sûr l’occasion d’&lt;strong>échanges et de débats scientifiques&lt;/strong>. Deux thèmes focus ont été retenus pour cette année :&lt;/p>
&lt;ul>
&lt;li>les liens de plus en plus importants, en recherche, qui se construisent entre les technologies de l’intelligence artificielle et les problématiques de l’animation et de la simulation,&lt;/li>
&lt;li>les questions relatives à l’enseignement de l’animation et de la simulation et l’usage de l’AS pour la pédagogie d’autres disciplines.&lt;/li>
&lt;/ul>
&lt;p>Par ailleurs, un &lt;strong>atelier pratique&lt;/strong> sur les technologies de capture du mouvement et leurs usages sera proposé par l’équipe organisatrice Expression, et un moment sera dédié au &lt;strong>partage de réalisations et perspectives artistiques&lt;/strong> (œuvres, projets ou travaux en cours), les processus créatifs étant importants pour notre domaine qui adresse la perception visuelle, notamment dans les aspects dynamiques.&lt;/p>
&lt;p>Enfin, l’ensemble des participants s’attacheront à mettre à jour les éléments prospectifs du domaine : nouveaux sujets, thèmes émergents, perspectives, points clés.&lt;/p>
&lt;p>L’inscription aux Journées est gratuite mais obligatoire – merci de prendre contact avec les coordinateurs du GT pour obtenir le lien d&amp;rsquo;inscription.&lt;/p>
&lt;h2 id="programme-prévisionnel">Programme Prévisionnel&lt;/h2>
&lt;h3 id="mardi-5-juillet-2022">Mardi 5 juillet 2022&lt;/h3>
&lt;p>9h : Accueil, hall du batiment ENSIBS&lt;/p>
&lt;p>9h15 - 12h15 : Atelier Mocap, animé par l&amp;rsquo;équipe Expression&lt;/p>
&lt;p>12h30 - 13h45 : Repas offert par l&amp;rsquo;Université Bretagne Sud, batiment DSEG&lt;/p>
&lt;p>14h - 15h30 : Présentations - session 1&lt;/p>
&lt;ul>
&lt;li>&lt;em>CVM-Net: Monocular Video-Based Motion Capture with Deep Learning Techniques&lt;/em>, &lt;strong>Mansour Tchenegnon&lt;/strong>, Thibaut le Naour et Sylvie Gibet, équipe Expression IRISA et Motion Up.&lt;/li>
&lt;li>&lt;em>Présentation de la nouvelle équipe VirtUS&lt;/em>, &lt;strong>Ludovic Hoyet&lt;/strong> et al., équipe Virtus IRISA.&lt;/li>
&lt;li>&lt;em>Detailed Eye Region Capture and Animation&lt;/em>, &lt;strong>Glenn Kerbiriou&lt;/strong>, Maud Marchal et Quentin Avril, équipe Rainbow IRISA et InterDigital.&lt;/li>
&lt;li>&lt;em>Water and Generalized Kelvinlets&lt;/em>, &lt;strong>Mathieu Desbrun&lt;/strong> et al., INRIA.&lt;/li>
&lt;/ul>
&lt;p>15h30 - 15h45 : Pause café hall ENSIBS&lt;/p>
&lt;p>15h45 - 17h : Présentations - session 2&lt;/p>
&lt;ul>
&lt;li>&lt;em>Multiresolution Framework for the Animation and Cutting of Complex or Highly Detailed Objects&lt;/em>, &lt;strong>Quentin Wendling&lt;/strong> et David Cazier, équipe IGG ICUBE.&lt;/li>
&lt;li>&lt;em>A Low-Cost Motion Capture Corpus in French Sign Language for Interpreting Iconicity and Spatial Referencing Mechanisms&lt;/em>, &lt;strong>Clémence Mertz&lt;/strong>, Vincent Barreaud, Damien Lolive et Sylvie Gibet, équipe Expression IRISA.&lt;/li>
&lt;li>&lt;em>Présentation de l’équipe SAARA, avec focus sur les expressions dans les mouvements et gestes, reconnaissance et synthèse&lt;/em>, &lt;strong>Alexandre Meyer&lt;/strong> et al., équipe Saara LIRIS.&lt;/li>
&lt;/ul>
&lt;p>17h : Moment artistique et social event offert par le GDR / CNRS&lt;/p>
&lt;h3 id="mercredi-6-juillet-2022">Mercredi 6 juillet 2022&lt;/h3>
&lt;p>9h : Accueil, hall du batiment ENSIBS&lt;/p>
&lt;p>9h25 - 10h25 : Keynote Christian Theobalt (MaxPlanck Institut)&lt;/p>
&lt;p>&lt;em>Title:&lt;/em> Capturing the Real World in Motion: New ways to unite graphics, vision and machine learning
Abstract: In this presentation, I will talk about some of the recent work we did on new methods for reconstructing computer graphics models of real world scenes from sparse or even monocular video data. These methods are based on bringing together neural network-based and explicit model-based approaches. I will also talk about new neural rendering approaches that combine explicit model-based and neural network based concepts for image formation in new ways. They enable new means to synthesize highly realistic imagery and videos of real work scenes under user control.&lt;/p>
&lt;p>10h30 - 10h45 : Pause café hall ENSIBS&lt;/p>
&lt;p>10h45 - 12h : Présentations - session 3 - focus IA&lt;/p>
&lt;ul>
&lt;li>&lt;em>Interactive loop modeling for nonverbal behavior animation&lt;/em>, &lt;strong>Jieyeon Woo&lt;/strong>, Catherine Pelachaud et Catherine Achard, Sorbonne Université / ISIR.&lt;/li>
&lt;li>&lt;em>UnderPressure: Deep Learning for Foot Contact Detection, Ground Reaction Force Prediction and Footskate Cleanup&lt;/em>, &lt;strong>Lucas Mourot&lt;/strong>, Ludovic Hoyet, François Le Clerc et Pierre Hellier, équipe Virtus IRISA et InterDigital.&lt;/li>
&lt;li>&lt;em>Zero-Shot Multimodal Style Transfer for Text and Speech Driven Gesture Animation&lt;/em>, &lt;strong>Mireille Fares&lt;/strong>, &lt;strong>Michele Grimaldi&lt;/strong>, Catherine Pelachaud et Nicolas Obin, Sorbonne Université / ISIR.&lt;/li>
&lt;/ul>
&lt;p>12h - 12h30 : Discussions &amp;ldquo;IA et Animation&amp;rdquo;&lt;/p>
&lt;p>12h30 - 13h40 : Repas offert par l&amp;rsquo;Université Bretagne Sud, batiment DSEG&lt;/p>
&lt;p>13h40 - 14h : Retour d&amp;rsquo;expérience Projets Européens, &lt;strong>Maud Marchal&lt;/strong>, équipe Rainbow IRISA.&lt;/p>
&lt;p>14h - 15h : Discussions &amp;ldquo;Enseignement de l&amp;rsquo;AS et avec l&amp;rsquo;AS&amp;rdquo;&lt;/p>
&lt;p>15h - 15h15 Pause café hall ENSIBS&lt;/p>
&lt;p>15h15 - 16h : Présentations - session 4&lt;/p>
&lt;ul>
&lt;li>&lt;em>Motion In Style : Analysis of Mocap Data&lt;/em>, &lt;strong>Victor Haguet&lt;/strong>, &lt;strong>Caroline Larboulette&lt;/strong> et Laura Pouppeville, équipe Expression IRISA, Université Bretagne Sud et artiste indépendante.&lt;/li>
&lt;li>&lt;em>3D Human Shape Style Transfer&lt;/em>, &lt;strong>Joao Regateiro&lt;/strong> et al., équipe MiMetic IRISA.&lt;/li>
&lt;li>&lt;em>Vers un outil topo-géométrique modulaire pour la mise en forme visuelle de simulations physiques masses-interactions et l’animation de transformations topologiques&lt;/em>, Jérémy Riffet, Annie Luciani, &lt;strong>Nicolas Castagné&lt;/strong>, Université Grenoble Alpes|Grenoble INP et ACROE.&lt;/li>
&lt;/ul>
&lt;p>16h - 17h : Discussions &amp;ldquo;Prospectives&amp;rdquo;&lt;/p>
&lt;p>17h : Fin des journées&lt;/p></description></item><item><title>Journées optimisation topologique</title><link>https://gdr-igrv.fr/event/journee_jot2022/</link><pubDate>Thu, 30 Jun 2022 10:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_jot2022/</guid><description/></item><item><title>Mobilités inter-laboratoires 2022</title><link>https://gdr-igrv.fr/post/22-06-30-mobilite/</link><pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-06-30-mobilite/</guid><description>&lt;p>Bonjour à tous,&lt;/p>
&lt;p>Pour cette fin d&amp;rsquo;année 2022, le GdR met en place son action de mobilité entre laboratoires français via le financement de court séjour d&amp;rsquo;un doctorant ou d&amp;rsquo;un enseignant-chercheur/chercheur. Le financement sera à hauteur de 1000 euros par mission (mission de 4-5 jours en moyenne). L&amp;rsquo;appel est très large sur ce qui est attendu (échanges scientifiques, montage de projet, expérimentations&amp;hellip;), n&amp;rsquo;hésitez pas à nous solliciter si vous avez des questions.&lt;/p>
&lt;p>La contrainte forte est que cette mission se déroule sur l&amp;rsquo;automne/hiver 2022.&lt;/p>
&lt;p>Le dossier pour postuler doit comprendre :&lt;/p>
&lt;ul>
&lt;li>une lettre de justification de la personne qui part (+ une lettre de son encadrant pour les doctorants)&lt;/li>
&lt;li>une lettre de justification de l&amp;rsquo;&amp;lsquo;équipe / personne qui accueille&lt;/li>
&lt;li>un budget prévisionnel&lt;/li>
&lt;/ul>
&lt;p>La date limite pour l&amp;rsquo;envoi du dossier est le &lt;strong>1er septembre 2022&lt;/strong> (par mail à David et Maud), une décision très rapide devrait arriver dans la foulée pour la mise en place de la mission.&lt;/p>
&lt;p>Merci à tous de relayer l&amp;rsquo;information,
Très cordialement,
David &amp;amp; Maud&lt;/p></description></item><item><title>Journée Visu 2022</title><link>https://gdr-igrv.fr/event/journee_gtvisu2022/</link><pubDate>Tue, 28 Jun 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtvisu2022/</guid><description/></item><item><title>Journée GT Rendu 2022</title><link>https://gdr-igrv.fr/event/journee_gtrendu2022/</link><pubDate>Mon, 23 May 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrendu2022/</guid><description/></item><item><title>Axel Paris : Modélisation et génération de scènes naturelles dans le contexte de l'informatique graphique</title><link>https://gdr-igrv.fr/post/22-05-10-jc-axel-paris/</link><pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-05-10-jc-axel-paris/</guid><description>&lt;h3 id="peux-tu-nous-dire-quelle-est-ta-situation-actuelle-en-matière-de-recherche-">Peux-tu nous dire quelle est ta situation actuelle en matière de recherche ?&lt;/h3>
&lt;p>Je suis en 3ème année de thèse au &lt;a href="https://liris.cnrs.fr" target="_blank" rel="noopener">LIRIS&lt;/a> à Lyon, encadré par Eric Galin et Eric Guérin de l’équipe &lt;a href="https://projet.liris.cnrs.fr/origami/" target="_blank" rel="noopener">Origami&lt;/a>. J’ai réalisé une césure de thèse de 6 mois pour faire un stage de recherche dans une entreprise, chez Adobe Research, et je débute pour cela ma troisième année en décalé en Mars.&lt;/p>
&lt;h3 id="peux-tu-nous-décrire-en-quelques-mots-et-de-manière-accessible-aux-membres-du-gdr-igrv-en-quoi-tes-travaux-de-recherche-consistent-exactement">Peux-tu nous décrire en quelques mots, et de manière accessible aux membres du GDR-IGRV, en quoi tes travaux de recherche consistent exactement?&lt;/h3>
&lt;p>Ma thèse porte sur la modélisation et la généralisation de phénomènes naturels. Concrètement sur les phénomènes naturels, on imagine une scène d’extérieur, naturelle, composée, en général, d&amp;rsquo;un terrain, de la végétation, des fluides (e.g. des rivières, des nuages), et je m’intéresse à la génération de terrains réalistes. Il s’agit donc de reproduire ce qu’on appelle des « modelés », des « formes de terrains » qu’on voit dans la vraie vie, par des algorithmes, par des simulations d’érosion, etc.&lt;/p>
&lt;p>Plus spécifiquement, je m’intéresse aux phénomènes naturels qu’on nomme « tridimensionnels » : les phénomènes volumiques qui ne peuvent pas être représentés uniquement par une surface lisse. Je m’intéresse aux concavités, comme les grottes, les surplombs, les arches, etc. et donc à leur génération.&lt;/p>
&lt;p>Ça a deux applications principalement : une application plutôt dans l’industrie du loisir, notamment le cinéma et le jeu vidéo, où souvent on veut créer des scènes naturelles par ordinateur (e.g. le dernier Avengers). Dans ces scènes naturelles, il y a souvent un terrain et se sont des artistes qui vont le créer et le texturer. C’est un processus de moins en moins manuel : il est semi-manuel, et beaucoup d’algorithmes sont déjà utilisés par des artistes pour commencer à faire le sketching, placer les formes, etc. Dans ce contexte, on va donc chercher à faire des applications qui donnent plutôt du contrôle aux artistes. La deuxième application est à l’interface entre la géologie et l’informatique. Imaginons qu’on regarde une chaîne de montagnes et qu’on veuille savoir comment elle a été formée. On va essayer de rétro-ingéniérer les processus par des algorithmes pour comprendre comment la montagne s’est formée, et ça peut nous aider à prédire l’évolution de la montagne avec des « méthodes inverses ».&lt;/p>
&lt;figure id="figure-simulation-de-terrains-volumiques-par-invasion-percolation">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Simulation de terrains volumiques par invasion-percolation" srcset="
/post/22-05-10-jc-axel-paris/SeaErosion03_hu2d38d96411c8b1476604947d5d3cebdd_246241_57bd1752e2762daa3358325f33c7cdac.webp 400w,
/post/22-05-10-jc-axel-paris/SeaErosion03_hu2d38d96411c8b1476604947d5d3cebdd_246241_619dcaecdf595bf58918ab458155c5d4.webp 760w,
/post/22-05-10-jc-axel-paris/SeaErosion03_hu2d38d96411c8b1476604947d5d3cebdd_246241_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://gdr-igrv.fr/post/22-05-10-jc-axel-paris/SeaErosion03_hu2d38d96411c8b1476604947d5d3cebdd_246241_57bd1752e2762daa3358325f33c7cdac.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Simulation de terrains volumiques par invasion-percolation
&lt;/figcaption>&lt;/figure>
&lt;h4 id="est-ce-que-côté-technologie-tu-arriverais-à-décrire-un-peu-les-outils-que-tu-utilises-">Est-ce que côté technologie tu arriverais à décrire un peu les outils que tu utilises ?&lt;/h4>
&lt;p>Dans ma thèse, je me suis focalisé principalement sur les modèles à base de surfaces implicites. Très succinctement, c’est une représentation très compacte de formes géométriques. On ne les représente non pas comme des maillages, mais comme des équations (des équations de distance à la forme), et ça prend très peu de place en mémoire. On peut représenter de très grandes scènes avec ça! Ca a aussi d’autres avantages au niveau contrôle : il y a des opérateurs de mélange, on peut mélanger des formes (très utile pour les artistes). C’est un modèle très expressif. Dans le cadre de ma thèse, il s’agit de regarder tout ce qu’il est possible de faire avec les surfaces implicites pour les phénomènes naturels. J’ai aussi travaillé sur les modèles 2D de cartes de hauteur.&lt;/p>
&lt;h3 id="quel-est-ton-résultat-de-recherche-dont-tu-es-le-plus-fier">Quel est ton résultat de recherche dont tu es le plus fier?&lt;/h3>
&lt;p>J’ai eu l’occasion de travailler dans ma thèse sur des sujets assez différents qui m’ont tous beaucoup plu. Si je devais revenir sur juste un, je dirais le dernier qui concernait la génération de réseaux de grottes. Je l’ai trouvé particulièrement intéressant car on a pu collaborer avec quelqu’un de l’extérieur, une géologue, qui avait des connaissances que nous n’avions pas du tout (Pauline Colon, de l’université de Lorraine). Elle nous a apporté beaucoup de connaissances en géologie et en géomorphologie. On a rédigé un article ensemble où le côté pluridisciplinaire ressort beaucoup, et chacun a apporté des connaissances à l’autre. La collaboration continue d’ailleurs avec des stages en suite de ce papier.&lt;/p>
&lt;figure id="figure-simulation-de-paysages-désertiques-dunes-nabkha">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Simulation de paysages désertiques: Dunes Nabkha" srcset="
/post/22-05-10-jc-axel-paris/nabkha_1_huee0d455830741d157102e10d7a7baf97_1491283_42dacb72a6404de2a89ec26e5e23cbf1.webp 400w,
/post/22-05-10-jc-axel-paris/nabkha_1_huee0d455830741d157102e10d7a7baf97_1491283_e8ce5921d5872b62e904aa06db6c30c4.webp 760w,
/post/22-05-10-jc-axel-paris/nabkha_1_huee0d455830741d157102e10d7a7baf97_1491283_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-05-10-jc-axel-paris/nabkha_1_huee0d455830741d157102e10d7a7baf97_1491283_42dacb72a6404de2a89ec26e5e23cbf1.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Simulation de paysages désertiques: Dunes Nabkha
&lt;/figcaption>&lt;/figure>
&lt;h3 id="quelles-sont-tes-perspectives-à-long-terme--après-la-thèse-ou-le-post-doc-ec-cr">Quelles sont tes perspectives à long terme ? (Après la thèse ou le post-doc, EC, CR..)&lt;/h3>
&lt;p>Ça n&amp;rsquo;est pas simple… j’ai pleins d’idées ! Disons que rien ne me semble “pas attractif”, même si j’ai quelques préférences. Si je devais choisir maintenant, je m’orienterais dans la recherche d’un post-doc à l’étranger dans une équipe qui fait des choses en lien avec ce que je fais .. ou pas .. j’aime aussi l’idée de changer un peu. Mes projets à plus long terme demandent encore à se préciser. Ma césure en entreprise m’a permis de tester à la fois le privé et le public, et je vois que les deux ont des avantages et des inconvénients, je me laisse donc encore du temps pour réfléchir.&lt;/p>
&lt;h3 id="quelles-sont-les-recherchesexpériencesthématiques-que-tu-rêverais-daborder-dans-ton-laboratoire-idéal-">Quelles sont les recherches/expériences/thématiques que tu rêverais d&amp;rsquo;aborder dans ton laboratoire idéal ?&lt;/h3>
&lt;p>Bonne question… ! Suite à mes derniers travaux en collaboration avec une géologue, j’ai compris l’enjeu et bénéfice de la dimension pluridisciplinaire que peut prendre la recherche, et j’aimerais beaucoup pouvoir retrouver cela dans un futur laboratoire.&lt;/p>
&lt;p>&lt;em>Toutes les illustrations de cet article ont été fournies par Axel et le détail de ses travaux est disponible sur &lt;a href="https://aparis69.github.io/" target="_blank" rel="noopener">son site web&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Zoom sur... Aldo Napoli du Centre de recherche sur les Risques et les Crises (CRC) (Mines Paris | PSL)</title><link>https://gdr-igrv.fr/post/22-05-05-zoom-aldo-napoli/</link><pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-05-05-zoom-aldo-napoli/</guid><description>&lt;p>&lt;a href="https://www.minesparis.psl.eu/Services/Annuaire/aldo-napoli" target="_blank" rel="noopener">&lt;strong>Aldo Napoli&lt;/strong>&lt;/a>, membre du &lt;a href="https://www.crc.mines-paristech.fr/fr/" target="_blank" rel="noopener">&lt;strong>Centre de recherche sur les Risques et les Crises&lt;/strong>&lt;/a> (CRC), s&amp;rsquo;intéresse à la gestion des risques maritimes dus à la navigation de navires. Les trajectoires des navires sont enregistrées en permanence et sont analysées par des opérateurs responsables de réagir face à des situations de risque. Aldo Napoli travaille sur des méthodes d&amp;rsquo;analyses des trajectoires de navires pour l&amp;rsquo;aide à la décision, mais aussi sur leur visualisation. En lien avec le GdR, c&amp;rsquo;est plutôt de ses travaux autour de la visualisation qu&amp;rsquo;il a souhaité nous parler.&lt;/p>
&lt;h4 id="est-ce-que-vous-pourriez-nous-décrire-votre-projet-de-recherche-et-comment-il-sinscrit-dans-le-gdr-igrv">Est-ce que vous pourriez nous décrire votre projet de recherche et comment il s’inscrit dans le GdR IGRV?&lt;/h4>
&lt;p>Dans le cadre d’une thèse de doctorat menée de 2012 à 2014, nous avons conçu et développé un environnement d’aide à l’analyse géovisuelle, qui permet de guider l’utilisateur dans la visualisation et l’analyse d’informations pour l’étude des risques maritimes. Les outils de visualisation des trajectoires maritimes sont aujourd&amp;rsquo;hui nombreux, mais requiert un certain apprentissage de la part des opérateurs ainsi que d&amp;rsquo;analyser une très large quantité de données sur plusieurs moniteurs. Le but de cette thèse était de concevoir un système à base de connaissances, afin de proposer des méthodes adéquates pour la visualisation et l’analyse des trajectoires de navires.&lt;/p>
&lt;h4 id="quels-sont-les-principaux-verrous-techniques-ou-méthodologiques-en-lien-avec-le-gdr-que-vous-essayez-de-résoudre">Quels sont les principaux verrous techniques ou méthodologiques (en lien avec le GdR) que vous essayez de résoudre?&lt;/h4>
&lt;p>Cette dernière décennie, les laboratoires de R&amp;amp;D ainsi que les grands groupes liés aux sciences de l’information géographique (GIScience) proposent et développent de nouvelles manières de cartographier l’espace et visualiser l’information spatio-temporelle. Cependant, devant une trop grande panoplie d’outils disponibles, il est aujourd’hui compliqué de savoir quelle méthode, quel algorithme, quel logiciel utiliser pour mener un processus d’analyse d’information à composantes spatiales.&lt;/p>
&lt;p>L’un des grands défis posés par la communauté GIScience ces dernières années n’est donc plus de proposer de nouvelles méthodes de visualisation de l’information, mais de consolider l’utilisation de la visualisation, en étudiant le réel apport de ces nombreuses méthodes par rapport aux questions de l’utilisateur. Le point fondamental n’est donc pas de développer une nouvelle méthode pour l’analyse géovisuelle des trajectoires, mais de rechercher comment guider l’utilisateur dans le processus d’analyse géovisuelle.&lt;/p>
&lt;p>Nous avons défini un environnement d’aide à l’analyse géovisuelle qui permet de soutenir l’analyse d’informations par l’utilisation de méthodes visuelles adaptées au cas d’utilisation. Nous avons identifié plusieurs profils d’utilisateurs qui auraient besoin de ce type d’environnement, à savoir les personnes liés à la prise de décision à partir de l’analyse de données de mouvement (les contrôleurs, les analystes, etc.), mais aussi les scientifiques amenés à analyser l’information géographique afin de modéliser les risques maritimes. Ces nombreux utilisateurs, par leur profil, leur formation et leurs habitudes, sont amenés à utiliser des visualisations variées, dans des contextes différents. Notre environnement les guide dans le choix de la visualisation adéquate.&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-05-05-zoom-aldo-napoli/image-choix_huaa019a8b8e18f6bab88f09c91da10c72_309098_b9dbec8fac67c60fa248071f52f7d0be.webp 400w,
/post/22-05-05-zoom-aldo-napoli/image-choix_huaa019a8b8e18f6bab88f09c91da10c72_309098_db2d000dde6d1cd7bb028b40e0f38a3a.webp 760w,
/post/22-05-05-zoom-aldo-napoli/image-choix_huaa019a8b8e18f6bab88f09c91da10c72_309098_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-05-05-zoom-aldo-napoli/image-choix_huaa019a8b8e18f6bab88f09c91da10c72_309098_b9dbec8fac67c60fa248071f52f7d0be.webp"
width="760"
height="542"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h4 id="est-ce-quil-y-a-dautres-verrous-que-vous-aimeriez-voir-résolus-mais-sur-lesquels-vous-ne-travaillez-pas-vous-même-">Est-ce qu’il y a d’autres verrous que vous aimeriez voir résolus, mais sur lesquels vous ne travaillez pas vous-même ?&lt;/h4>
&lt;p>Depuis l’interface que nous avons proposée, il est encore compliqué pour un utilisateur quelconque de pouvoir évaluer son profil selon les trois niveaux de compétence et d’expérience identifiés. Une perspective importante pour ce travail de recherche serait d’approfondir la modélisation de l’utilisateur et de son environnement, afin de rendre le profil plus intuitif, et moins empirique. Plusieurs travaux de modélisation de l’utilisateur et de son environnement ont pu être proposés, cette question étant un point de recherche à part entière ; tandis que nous avons préféré exploiter la modélisation de la visualisation elle-même.&lt;/p>
&lt;p>La modélisation des méthodes de visualisation d’information que nous avons proposée ne prend pas en compte la dynamique du processus d’analyse et de décision. Pourtant, comme le montre les différents processus de gestion des risques, l’analyse et la définition des comportements à risque doit être un processus itératif. Une amélioration d’intérêt serait de prendre en compte l’ordre et la récurrence de ces tâches d’analyse géovisuelle dans la modélisation des stratégies de visualisation, et d’avoir un impact sur les résultats proposés : ordre des propositions, méthode la plus importante car plus demandée, etc.&lt;/p>
&lt;p>&lt;em>Travaux menés dans le cadre de la thèse de Gabriel Vatin (dirigée par Aldo Napoli) de 2012 à 2014&lt;/em>&lt;/p></description></item><item><title>Yann Glemarec : Une approche narrative interactive pour les audiences virtuelles</title><link>https://gdr-igrv.fr/post/22-03-21-jc-yann-glemarec/</link><pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-03-21-jc-yann-glemarec/</guid><description>&lt;h3 id="peux-tu-nous-dire-quelle-est-ta-situation-actuelle-en-matière-de-recherche-">Peux-tu nous dire quelle est ta situation actuelle en matière de recherche ?&lt;/h3>
&lt;p>Je suis actuellement en thèse, en 3ème année. La particularité c’est que je suis en cotutelle entre le &lt;a href="https://labsticc.fr/fr" target="_blank" rel="noopener">Lab-STICC&lt;/a> (&lt;a href="https://www.enib.fr/fr/" target="_blank" rel="noopener">ENIB&lt;/a>, Brest) et le &lt;a href="http://hci.uni-wuerzburg.de/" target="_blank" rel="noopener">laboratoire HCI de l’université de Würzburg&lt;/a>. J’ai donc moitié du temps en France et moitié du temps en Allemagne, où je suis actuellement. La fin de thèse est prévue pour la fin de l’été 2022.&lt;/p>
&lt;h3 id="peux-tu-nous-décrire-en-quelques-mots-et-de-manière-accessible-aux-membres-du-gdr-igrv-en-quoi-tes-travaux-de-recherche-consistent-exactement">Peux-tu nous décrire en quelques mots, et de manière accessible aux membres du GDR-IGRV, en quoi tes travaux de recherche consistent exactement?&lt;/h3>
&lt;p>On utilise le potentiel des agents virtuels (différents des avatars car ils ne sont pas contrôlés par un humain) afin de fournir les meilleurs systèmes d’entraînement ou de thérapie en réalité virtuelle. Un exemple de système d’entraînement est l’entraînement à la prise de parole en public, je travaille souvent là-dessus. Cela marche aussi pour les thérapies, pour les personnes atteintes d’angoisses à la prise de parole en public, du point de vue de psychologie clinique. Si je rentre dans le détail, on utilise le comportement non verbal des agents pour créer des comportements et donc générer des réactions chez l’utilisateur. Ça nous permet de créer des environnements crédibles, plausibles pour les utilisateurs, mais aussi pour les instructeurs et thérapeutes qui eux peuvent mettre en place des scénarios de formations, de thérapies, en utilisant ces « audiences virtuelles », pour entraîner les gens à parler en public, faire des présentations.&lt;/p>
&lt;video autoplay loop >
&lt;source src="https://gdr-igrv.fr/post/22-03-21-jc-yann-glemarec/NextStep.mp4" type="video/mp4">
&lt;/video>
&lt;h4 id="donc-du-coup-la-spécificité-de-tes-travaux-cest-vraiment-détudier-comment-générer-cette-audience-et-comment-la-contrôler">Donc du coup la spécificité de tes travaux c’est vraiment d’étudier comment générer cette audience et comment la contrôler?&lt;/h4>
&lt;p>Oui en fait nous on crée des audiences on fait des études perceptives pour savoir comment les gens perçoivent ces audiences, en terme d’émotions par exemple. « Quelle est l’attitude perçue ? » « Est-ce qu’ils sont intéressés par ce que je dis ? ». Derrière, ce qui nous intéresse c’est de permettre aux instructeurs de contrôler cette perception qu’auront les utilisateurs de l’audience virtuelles pour faire ressentir une émotion particulière.&lt;/p>
&lt;h4 id="il-y-a-donc-une-dimension-assez-technique-pour-développer-la-plateforme-mais-il-y-a-aussi-toute-la-facette-perception-parce-que-vous-apportez-aussi-avec-un-bagage-de-connaissance-sur-comment-les-audiences-de-la-plateforme-sont-perçues">Il y a donc une dimension assez technique pour développer la plateforme, mais il y a aussi toute la facette perception parce que vous apportez aussi avec un bagage de connaissance sur comment les audiences de la plateforme sont perçues.&lt;/h4>
&lt;p>Exactement. Nous ne sommes pas une équipe de psychologues, mais nous nous basons sur des modèles de psychologie cognitive de perception des émotions par exemple, comme l’échelle connue de la « valence-arousal ». Ce sont deux axes qui permettent d’un côté d’évaluer, dans ce contexte lié à l’audience (si elle est positive ou négative) et l’arousal correspondrait à son engagement (attentive ou non).&lt;/p>
&lt;h4 id="sur-quels-types-de-dispositifs-travailles-tu-">Sur quels types de dispositifs travailles-tu ?&lt;/h4>
&lt;p>En terme de matériel, on s’est concentrés au début sur les casques de réalité virtuelle. On se sert aussi des CAVEs. On a fait face à des gens ayant des réticences à utiliser les casques de réalité virtuelle et qui préféraient par conséquent ce type de systèmes immersifs, mais le tracking du participant est plus complexe dans ce type de configuration.&lt;/p>
&lt;h3 id="quel-est-ton-résultat-de-recherche-dont-tu-es-le-plus-fier">Quel est ton résultat de recherche dont tu es le plus fier?&lt;/h3>
&lt;p>On a réussi à intégrer notre système d’audience virtuelle dans un système qu’on utilise ici pour des étudiants lors d’un cours où ils apprennent à faire des présentations scientifiques, donc typiquement des présentations d’articles. On leur permet de faire un entraînement en réalité virtuelle, comme une conférence virtuelle, et nous ça nous permet de tester nos audiences, pendant deux semestres.&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/22-03-21-jc-yann-glemarec/TherapistGUI_hu35804965efff09982f91d5d80062d3b5_11137492_f3ca61e96b85b69e07e6fcfe6a34639f.webp 400w,
/post/22-03-21-jc-yann-glemarec/TherapistGUI_hu35804965efff09982f91d5d80062d3b5_11137492_9754dc2b37189b194c168c17eacf07bf.webp 760w,
/post/22-03-21-jc-yann-glemarec/TherapistGUI_hu35804965efff09982f91d5d80062d3b5_11137492_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/post/22-03-21-jc-yann-glemarec/TherapistGUI_hu35804965efff09982f91d5d80062d3b5_11137492_f3ca61e96b85b69e07e6fcfe6a34639f.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;h3 id="quelles-sont-tes-perspectives-à-long-terme--après-la-thèse-ou-le-post-doc-ec-cr">Quelles sont tes perspectives à long terme ? (Après la thèse ou le post-doc, EC, CR..)&lt;/h3>
&lt;p>&lt;em>(rigole)&lt;/em> C’est une question qui est au cœur des échanges avec mes encadrants en ce moment. Pour le moment je me dirige vers la recherche académique. Le plan serait de peut-être me diriger vers un poste d’ATER pour donner un peu plus de cours et pour pouvoir aussi finaliser et poursuivre un peu mes travaux de thèse. J’envisage aussi la possibilité d’un post-doc, sans avoir encore de préférence entre un poste de maître de conférences ou chargé de recherche.&lt;/p>
&lt;h3 id="quelles-sont-les-recherchesexpériencesthématiques-que-tu-rêverais-daborder-dans-ton-laboratoire-idéal-">Quelles sont les recherches/expériences/thématiques que tu rêverais d&amp;rsquo;aborder dans ton laboratoire idéal ?&lt;/h3>
&lt;p>Si je devais réfléchir à un laboratoire idéal, ce serait surtout un laboratoire cross-disciplinaire. Par exemple j’ai beaucoup aimé pendant ma thèse pouvoir travailler avec des psychologues, c’est super intéressant. J’aimerais continuer dans mon domaine, la réalité virtuelle, mais si possible avec des personnes d’autres domaines comme la psychologie par exemple. J’aime le côté applicable des travaux de recherches, où il y a un potentiel de valorisation assez élevé, comme ici avec un système qui pourra être utilisé dans l’éducation.&lt;/p>
&lt;p>&lt;em>Toutes les illustrations de cet article ont été fournies par Yann et le détail de ses travaux est disponible sur &lt;a href="https://www.enib.fr/~glemarec/" target="_blank" rel="noopener">son site web&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Journées du GTMG</title><link>https://gdr-igrv.fr/event/journee_gtmg2022/</link><pubDate>Wed, 16 Mar 2022 11:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtmg2022/</guid><description/></item><item><title>Journées Informatique et Géométrie 2022</title><link>https://gdr-igrv.fr/event/jig2022/</link><pubDate>Tue, 15 Mar 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/jig2022/</guid><description/></item><item><title>Journée « Environnements virtuels : adaptation du système à l'humain ou de l'humain au système ? »</title><link>https://gdr-igrv.fr/event/journee_gtrv2022/</link><pubDate>Wed, 09 Mar 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrv2022/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://journee-rvia.hds.utc.fr/_detail/pma_equipe_copyright.jpg?id=fr%3Astart" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h1 id="responsables">Responsables&lt;/h1>
&lt;ul>
&lt;li>Domitile Lourdeaux (Heudiasyc – Université de technologie de Compiègne)&lt;/li>
&lt;li>Indira Thouvenin-Moutapa (Heudiasyc – Université de technologie de Compiègne)&lt;/li>
&lt;/ul>
&lt;h1 id="programme">Programme&lt;/h1>
&lt;p>&lt;strong>9 mars 2022&lt;/strong>&lt;/p>
&lt;p>Le programme prévisionnel de la journée est le suivant :&lt;/p>
&lt;p>Train de Paris : départ 8.34 - arrivée 9.26 Comptez 10 min pour rejoindre le centre d’innovation en taxi. Les bus sont gratuits mais lents (prévoir 30 min). Voir plan d&amp;rsquo;accès Centre d&amp;rsquo;Innovation à côté du Génie Informatique.&lt;/p>
&lt;p>Le programme sera détaillé ultérieurement, voici les grands temps forts :&lt;/p>
&lt;ul>
&lt;li>9.30-10.00 Accueil, café&lt;/li>
&lt;li>10.10-10.15 Ouverture (Mot de l’AFIA, du GdR IG-RV et de Philippe Bonnifait, directeur de l&amp;rsquo;UMR 7253 Heudiasyc)&lt;/li>
&lt;li>10.15-10.35 « Pourquoi cette journée ? Environnements virtuels : adaptation du système à l&amp;rsquo;humain ou de l&amp;rsquo;humain au système ? » Domitile Lourdeaux et Indira Thouvenin&lt;/li>
&lt;li>10.35-11.05 Présentation invitée « Environnements virtuels et modèles de décision pour l’interaction » IRISA, Rennes&lt;/li>
&lt;li>11.05-11.15 Pause café&lt;/li>
&lt;li>11.15-11.45 Présentation invitée « La réalité virtuelle en tant qu&amp;rsquo;outil de formation adapté aux pratiques de l&amp;rsquo;enseignant: scénarisation des travaux pratiques, enseignement du geste et adaptation au comportement » Ludovic Hamon, LIUM, Laval&lt;/li>
&lt;li>11.45-12.10 « Facteurs humains et réalité virtuelle : détecter les effets secondaires avec capteurs physiologiques et machine learning » Alexis Souchet, Heudiasyc Compiègne&lt;/li>
&lt;li>12.10-12.30 « Génération d’un profil dynamique du stress pour l’entraînement à la gestion de situations de crise » Luca Pelissero-Witoslawski, Heudiasyc Compiègne&lt;/li>
&lt;li>12.30-14.00 Buffet et session Posters&lt;/li>
&lt;li>14.00-15.00 Visite du CAVE et des démonstrations&lt;/li>
&lt;li>15.00-15.30 Présentation invitée « Les agents virtuels dans les environnements immersifs d&amp;rsquo;apprentissage » David Panzoli, IRIT Toulouse&lt;/li>
&lt;li>15.30-15.55 « Toucher social pour l’interaction humain-agent incarné en environnement virtuel » Fabien Boucaud, ISIR, Paris&lt;/li>
&lt;li>15.55-16.15 « Retours adaptatif en réalité augmentée basés sur l’état du conducteur de véhicule hautement automatisé lors de la reprise de contrôle » Baptiste Wojtkowski, Heudiasyc, Compiègne&lt;/li>
&lt;li>16.15-17.00 Table Ronde « Environnements virtuels : adaptation du système à l&amp;rsquo;humain ou de l&amp;rsquo;humain au système ? »&lt;/li>
&lt;/ul>
&lt;p>Un mode hybride est en cours d&amp;rsquo;études mais on privilégie le présentiel pour permettre de participer aux démonstrations.&lt;/p>
&lt;p>Train retour départ 17.35 – arrivée 18.26&lt;/p>
&lt;h1 id="inscriptions">Inscriptions&lt;/h1>
&lt;p>Pour des raisons pratiques, les inscriptions devront se faire avant le 28 février 2022&lt;/p>
&lt;p>&lt;a href="https://journee-rvia.hds.utc.fr/fr/inscriptions" target="_blank" rel="noopener">https://journee-rvia.hds.utc.fr/fr/inscriptions&lt;/a>&lt;/p>
&lt;p>Retrouvez toutes les informations&lt;/p>
&lt;p>&lt;a href="https://journee-rvia.hds.utc.fr/fr/presentation" target="_blank" rel="noopener">https://journee-rvia.hds.utc.fr/fr/presentation&lt;/a>&lt;/p></description></item><item><title>Journée du GT-RV</title><link>https://gdr-igrv.fr/event/journee_gtrv2022-8-03/</link><pubDate>Tue, 08 Mar 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrv2022-8-03/</guid><description>&lt;p>Comme vous le savez déjà, la journée du GT-RV se tiendra le 8 mars dans les locaux parisiens de l&amp;rsquo;UTC au 62 Boulevard de Sébastopol, 75003 Paris&lt;/p>
&lt;p>Nous vous proposons de vous inscrire à l&amp;rsquo;adresse suivante en indiquant si vous souhaitez être en présentiel ou éventuellement distanciel.
&lt;a href="https://framaforms.org/inscription-journees-du-gt-rv-1644410184" target="_blank" rel="noopener">https://framaforms.org/inscription-journees-du-gt-rv-1644410184&lt;/a>&lt;/p>
&lt;p>L&amp;rsquo;entrée est gratuite, mais le présentiel est limité à 40 personnes.&lt;/p>
&lt;p>Attention, pour des raisons sanitaires, nous ne pouvons pas vous proposer de repas de déjeuner sur place, mais nous avons le plaisir d&amp;rsquo;être accueillis dans un des quartiers parisiens les plus fournis en petits restaurants très sympathiques.&lt;/p>
&lt;p>Le distanciel se fera à cette adresse :
&lt;a href="https://catalogue-ent2.univ-paris8.fr/BigBlueButtonReunion/client.php?meetingID=4882&amp;amp;fullName=Anonyme&amp;amp;password=4bsexESkl7D092oXV_v5jRQKHh6imPyZMpwa&amp;amp;checksum=b1e8eb8c7ad246eb8689dc2f89ed2fb0ecb063bc" target="_blank" rel="noopener">https://catalogue-ent2.univ-paris8.fr/BigBlueButtonReunion/client.php?meetingID=4882&amp;fullName=Anonyme&amp;password=4bsexESkl7D092oXV_v5jRQKHh6imPyZMpwa&amp;checksum=b1e8eb8c7ad246eb8689dc2f89ed2fb0ecb063bc&lt;/a>&lt;/p>
&lt;h1 id="programme">Programme&lt;/h1>
&lt;p>Nous sommes heureux de vous proposer le programme de la journée, que vous pourrez retrouver, pour plus de facilité en pdf attaché en pièce jointe :
9h30-11h00 : Présentations, Chairman : Pr Daniel Mestre&lt;/p>
&lt;ul>
&lt;li>9h 30: &lt;strong>RAMOUSSE Florian&lt;/strong>
Laboratoire / Institution : LIRIS / École Centrale de Lyon&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Immersive environnements for Assessing and Treating Binge Eating Disorders : How the Visual Quality of 3D Food Stimuli can Influence the Desire to Eat&lt;/p>
&lt;ul>
&lt;li>9h50 : &lt;strong>VILLENAVE Sophie&lt;/strong>
Laboratoire / Institution : LIRIS / École Centrale de Lyon-ENISE&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : XREcho : Un outil d’enregistrement et de visualisation des expériences XR
Résumé : XREcho, c&amp;rsquo;est un plugin pour le logiciel Unity qui permet d&amp;rsquo;enregistrer et de rejouer en temps réel des sessions d&amp;rsquo;XR (VR et AR), développées avec Unity.
Le développement du plugin est en cours, mais nous sommes en train de rédiger un papier destiné à MMSys pour la section demo/soft/dataset afin d&amp;rsquo;avoir accès à une plateforme de diffusion large.
Ce plugin devrait permettre à la communauté scientifique étudiant le comportement et les interactions des utilisateurs avec l&amp;rsquo;AR et la VR d&amp;rsquo;obtenir des données objectives afin d&amp;rsquo;établir des modèles plus justes et plus proche de la réalité.&lt;/p>
&lt;ul>
&lt;li>10h10 : &lt;strong>Elodie Bayle&lt;/strong>
Laboratoire : Institut de recherche biomédicale des armées&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Entre fusion et rivalité binoculaires : Impact des caractéristiques des stimuli visuels lors de l’utilisation d’un système de réalité augmentée semi-transparent monoculaire.
Résumé : Les visuels de casque monoculaires utilisés dans l’aéronautique augmentent la vision des pilotes et facilitent l’accès aux informations essentielles telles que la symbologie de vol. Du fait de la projection d’une image virtuelle devant un seul œil alors que l’environnement est binoculaire, cela génère une perception visuelle particulière. Le travail de cette thèse consistait à évaluer l’impact des caractéristiques des stimuli sur les performances à travers deux études psychophysiques et une étude écologique en simulateur de vol.&lt;/p>
&lt;ul>
&lt;li>10h30 : &lt;strong>Olivier ROUPIN&lt;/strong>
Laboratoire : Lab-STICC / InterDigital &amp;amp; IMT Atlantique Brest&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Détection d’objets supprimés dans des scènes 3D à l&amp;rsquo;aide d&amp;rsquo;images dans les applications de Réalité Mixte
Résumé : Une connaissance précise de l&amp;rsquo;environnement est requise pour l&amp;rsquo;interaction entre contenu virtuel et réel en réalité mixte. Cependant, une mise à jour en temps réel du modèle de la réalité est coûteuse en temps et matériel; diverses approches hybrides ont donc été développées : un modèle à jour du monde peut être déduit d&amp;rsquo;une capture hors-ligne de l&amp;rsquo;environnement 3D, corrigé en ligne en utilisant une séquence d&amp;rsquo;images courantes, à condition qu&amp;rsquo;un algorithme de détection de changement rapide et robuste soit développé. Les algorithmes existant présente un biais vers la détection d&amp;rsquo;apparition d&amp;rsquo;objets au mépris de la suppression d&amp;rsquo;objets; dans un environnement où l&amp;rsquo;arrière plan est photométriquement uniforme, la disparition d&amp;rsquo;objets au premier plan, entre un scan 3D d&amp;rsquo;une scène et la prise de nouvelles photos de cette même scène, est difficile à détecter par re-projection. Notre approche contourne ce problème en se concentrant sur les régions occultées par le premier plan où aucun changement ne se produit après re-projection. On montre par l&amp;rsquo;expérience sur des dataset réalistes, que cette approche est meilleure à la tâche de détection et localisation 3D d&amp;rsquo;objets supprimés. Cette approche peut être combinée avec un algorithme de détection d&amp;rsquo;apparitions d&amp;rsquo;objets pour produire un système de détection de changement complet.&lt;/p>
&lt;ul>
&lt;li>10h50 : &lt;strong>Charlotte DUBOSC&lt;/strong>
Laboratoire : Présence &amp;amp; Innovation, LAMPA / ENSAM Laval&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Étude de l’interdépendance du réalisme visuel et comportemental pour l’acceptation des personnages virtuels en environnement immersif collaboratif
Résumé : Présentation du protocole et des développements d’une expérimentation de thèse portant sur l’interdépendance du réalisme visuel et comportemental de personnages virtuels. Cette étude ambitionne d’évaluer la tolérance des utilisateurs confrontés à des personnages dont l’apparence présente des inadéquations potentielles avec leur expressivité faciale. Les évaluations porteront sur le réalisme perçu, la familiarité, l’étrangeté et l’attractivité des agents virtuels.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>11h10-11h30 pause&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11h30-12h30 : &lt;strong>Présentations&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11h30 : &lt;strong>Rebecca Fribourg&lt;/strong> (École Centrale de Nantes) — Prix de thèse IG-RV 2021&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : &amp;ldquo;Contribution to the study of factors influencing the sense of embodiment towards avatars in virtual reality&amp;rdquo;&lt;/p>
&lt;p>Résumé : Le terme “avatar” fait référence à la représentation des utilisateurs dans un monde virtuel, dans le cas où ils portent un casque de réalité virtuelle et ne peuvent donc pas voir leur propre corps. Les avatars sont désormais devenus une exigence majeure dans les applications de réalité virtuelle immersive, ce qui accroît la nécessité de mieux comprendre et identifier les facteurs qui influencent le sentiment d’incarnation d’un utilisateur envers son avatar. Dans cette thèse, nous avons défini trois axes de recherche pour explorer l’influence de plusieurs facteurs sur le sentiment d’incarnation, en nous basant sur une catégorisation qui ne prend pas seulement en compte les facteurs liés à l’avatar, mais aussi les facteurs liés à l’environnement virtuel et à l’utilisateur. En premier lieu, nous avons étudié l’influence des environnements virtuels partagés sur le sentiment d’incarnation, dans une étude où les utilisateurs accomplissaient une tâche ensemble dans le même environnement virtuel, et dans une autre étude où les utilisateurs partageaient le contrôle du même avatar. Dans une deuxième partie, nous avons exploré les interrelations entre les facteurs liés aux avatars qui influencent le sentiment d’incarnation. Enfin, dans une troisième partie, nous avons étudié l’influence des différences individuelles des utilisateurs sur le sentiment d’incarnation.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>12h00 : &lt;strong>Maud Marchal et Domitile Lourdeaux&lt;/strong>
Titre de la présentation : projets européens, recensement des projets européens dans le GT et retour d&amp;rsquo;expérience&lt;/p>
&lt;/li>
&lt;li>
&lt;p>12h30-14h : pause midi&lt;/p>
&lt;/li>
&lt;li>
&lt;p>14h-16h : &lt;strong>atelier ANSES&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Atelier sur le rapport d’expertise collective relatifs aux effets sanitaires potentiels liés à l&amp;rsquo;exposition aux technologies utilisant la réalité augmentée et la réalité virtuelle réalisé dans le cadre de l&amp;rsquo;ANSES (téléchargeable à &lt;a href="https://www.anses.fr/fr/system/files/AP2017SA0076Ra.pdf" target="_blank" rel="noopener">https://www.anses.fr/fr/system/files/AP2017SA0076Ra.pdf&lt;/a> ). Cet atelier est co-organisé avec la Commission « Réalité Virtuelle, Augmentée et Mixte » de l’Association de la Recherche en Psychologie Ergonomique et Ergonomie (ARPEGE).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>14h : &lt;strong>Présentation du rapport de l&amp;rsquo;ANSES par Jean-Marie Burkhardt&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>14h30-15h30 : &lt;strong>atelier discussion&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>15h30-16h : pause café&lt;/p>
&lt;/li>
&lt;li>
&lt;p>16h-17h : &lt;strong>Atelier prospective&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Résultats du prix 2022</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2022/</link><pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2022/</guid><description>&lt;h2 id="lauréate">Lauréate&lt;/h2>
&lt;p>&lt;strong>Marie-Julie Rakotosaona&lt;/strong> pour sa thèse intitulée &amp;ldquo;&lt;em>Learning-based representations and methods for 3D shape analysis, manipulation and reconstruction&lt;/em>&amp;rdquo; effectuée sous la direction de Maks Ovsjanikov (Ecole Polytechnique).&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2022/video_these_rakotosaona_marie-julie.avi" type="video/avi">
&lt;/video>
&lt;p>&lt;a href="https://archivesic.ccsd.cnrs.fr/LIX/tel-03541331v1" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;h2 id="accessit">Accessit&lt;/h2>
&lt;p>&lt;strong>Mickael Ly&lt;/strong> pour sa thèse intitulée &amp;ldquo;&lt;em>Static inverse modelling of cloth&lt;/em>&amp;rdquo; effectuée sous la direction de Florence Bertails-Descoubes et Mélina Skouras (Université Grenoble Alpes).&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2022/afig_ly.mp4" type="video/mp4">
&lt;/video>
&lt;p>&lt;a href="https://hal.inria.fr/tel-03499280" target="_blank" rel="noopener">Thèse&lt;/a>&lt;/p>
&lt;p>&lt;em>Le jury 2022 a été animé par Loïc Barthe et Guillaume Cordonnier. Il était composé de Florence Bertails-Descoubes, Georges-Pierre Bonneau, Tamy Boubekeur, Samuel Hornus, Yvonne Jansen, Daniel Mestre.&lt;/em>&lt;/p></description></item><item><title>Zoom sur... L'équipe PIROS du laboratoire ISIR, avec Catherine Pelachaud</title><link>https://gdr-igrv.fr/post/22-02-11-zoom-catherine-pelachaud/</link><pubDate>Fri, 11 Feb 2022 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/22-02-11-zoom-catherine-pelachaud/</guid><description>&lt;p>&lt;a href="http://pages.isir.upmc.fr/~pelachaud/" target="_blank" rel="noopener">&lt;strong>Catherine Pelachaud&lt;/strong>&lt;/a> nous explique les travaux menés dans l&amp;rsquo;équipe &lt;strong>&lt;a href="https://www.isir.upmc.fr/equipes/piros/" target="_blank" rel="noopener">PIROS&lt;/a>&lt;/strong> (laboratoire ISIR), où la réalité virtuelle et la simulation sont utilisés pour modéliser des agents conversationnels animés (ACAs) expressifs capables d’interagir émotionnellement et socialement avec des interlocuteurs humains:&lt;/p>
&lt;p>&amp;ldquo;Nous avons développé des modèles computationnels du comportement communicatif non-verbal et socio-émotionnel de l’agent. Avec des collègues de l’UTC, en particulier Indira Thouvenin, nous nous intéressons au toucher social et souhaitons comprendre comment modéliser la prise en compte du toucher tant du point de vue de l’humain que de l’agent dans un environnement de réalité virtuelle, menant ainsi au développement d’un agent touchant et touché. Nous nous focalisons aussi sur les modèles d’interaction entre un humain et un agent, donnant à l’agent la capacité d’adapter son comportement à plusieurs niveaux (conversationnel, comportemental, signal) pour contrôler l’impression qu’il donne à son interlocuteur humain et/ou pour qu’il maintienne l’engagement de celui-ci dans leur interaction.&lt;/p>
&lt;p>Ainsi nos thématiques de recherche s’intègrent dans l’axe GT animation et simulation et dernièrement dans celui sur la réalité virtuelle.
Nous faisons face à de nombreux verrous techniques tels que la création d’animation expressive. Nous utilisons des modèles procéduraux qui nous permet un grand contrôle mais offre une qualité insuffisante. Un autre verrou est de modéliser des agents crédibles, pas nécessairement réalistes. Cela demande de comprendre quand et quel comportement l’agent doit montrer, quel en sera l’impact sur la perception de son interlocuteur humain.
Modéliser une interaction humain-agent requière de nombreux composants comme la reconnaissance et la compréhension du langage, des expressions du locuteur, mais aussi un modèle de dialogue, d’émotion, de représentation des connaissances, pour en nommer quelques-uns. Pour y palier nous utilisons des modules développés par d’autres chercheurs et mis à disposition à la communauté de recherche.&amp;rdquo;&lt;/p></description></item><item><title>Journées Françaises de l'Informatique Graphique</title><link>https://gdr-igrv.fr/event/jfig2021/</link><pubDate>Wed, 24 Nov 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/jfig2021/</guid><description/></item><item><title>Journées inter-GdR CNRS MAGIS-MADICS-IGRV</title><link>https://gdr-igrv.fr/event/intergdr-magis-madics-igrv/</link><pubDate>Wed, 24 Nov 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/intergdr-magis-madics-igrv/</guid><description>&lt;hr>
&lt;pre>&lt;code> Journées inter-GdR CNRS MAGIS-MADICS-IGRV
Observation 3D : outils et verrous
Paris, 24 et 25 novembre 2021
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h1 id="programme-des-journées-">Programme des journées :&lt;/h1>
&lt;p>Mercredi 24 Novembre : de l’acquisition à la représentation de données 3D&lt;/p>
&lt;p>Matin :&lt;/p>
&lt;ul>
&lt;li>9h45-10h : Accueil des participants&lt;/li>
&lt;li>10h-10h15 : Introduction de la journée&lt;/li>
&lt;li>10h15-11h15 : exposé “La 3D au CNES : le système CO3D et quelques applications spatiales avec Pléiades”, Laurent Lebegue et Jean-Marc Delvit, CNES) - 45’ + 15’ questions&lt;/li>
&lt;li>11h15-12h15 : exposé “Deep learning pour les données 3D en télédétection”, Loïc Landrieu, LASTIG - 45’ + 15’ questions&lt;/li>
&lt;li>12h15-12h30 : discussions&lt;/li>
&lt;/ul>
&lt;p>Après midi :&lt;/p>
&lt;ul>
&lt;li>14h : session interactive d’échanges entre participants : chaque participant devra fournir un transparent de présentation de sa thématique / problématique selon une trame qui sera précisée par les organisateurs.&lt;/li>
&lt;li>15h30-16h : pause café&lt;/li>
&lt;li>16h-18h : TP “Deep Learning for 3D Data: Semantic Segmentation of Aerial LiDAR with PointNet”, par Loïc Landrieu, LASTIG.
Note: afin de préparer ce TP, il vous sera demandé de compléter un auto-test&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>Jeudi 25 Novembre : traiter, annoter et visualiser des données 3D&lt;/p>
&lt;p>Matin :&lt;/p>
&lt;ul>
&lt;li>9h-9h15 : Accueil des participants&lt;/li>
&lt;li>9h15-9h30 : Introduction de la journée&lt;/li>
&lt;li>9h30-10h30 : Mathieu Brédif - LASTIG, Université Gustave Eiffel, IGN-ENSG - “Navigation immersive dans des images historiques (ANR ALEGORIA)” - 45’ + 15’ questions -&lt;/li>
&lt;li>10h30-10h45 : pause café&lt;/li>
&lt;li>10h45-11h45 : Livio de Luca - UMR MAP, CNRS (en Visio) - “Enrichissement sémantique de ressources documentaires spatialisées pour l’étude pluridisciplinaire de Notre-Dame de Paris” - 45’ + 15’ questions.&lt;/li>
&lt;li>11h45-12h15: discussions sur les défis et besoins&lt;/li>
&lt;/ul>
&lt;p>Après midi :&lt;/p>
&lt;ul>
&lt;li>14h-16h : TP iTowns&lt;/li>
&lt;li>16h-16h30 : Conclusion des deux journées (organisateurs)&lt;/li>
&lt;/ul>
&lt;h1 id="date-et-lieu-">Date et lieu :&lt;/h1>
&lt;ul>
&lt;li>Géoroom IGN, 8 Avenue Pasteur, 94160 Saint-Mandé: Métro Saint-Mandé (Ligne 1) ou RER Vincennes (RER A).&lt;/li>
&lt;li>Mercredi 24 et Jeudi 25 novembre 2021 (de 10h le mercredi à 16h30 le jeudi)&lt;/li>
&lt;/ul>
&lt;h1 id="participation-">Participation :&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>Inscription gratuite mais obligatoire avant le 01/11/2021 (nombre de places limité) : envoyer un email à &lt;a href="mailto:gdr.madics-magis-igrv.observation3d@inria.fr">gdr.madics-magis-igrv.observation3d@inria.fr&lt;/a> en précisant votre nom, prénom, laboratoire, jours de présence, thématique de recherche, thématique(s) d&amp;rsquo;intérêt(s) spécifiques sur ces journées&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Attention, en fonction des règles sanitaires et du nombre d’invités, un pass sanitaire pourra être demandé à votre arrivée.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si le temps le permet, une présentation de 5 minutes de vos travaux pourra être envisagée (session interactive du 24/11 après-midi). Dans ce cas, merci de préciser votre souhait de présenter lors de votre inscription, avec un titre.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="organisation-">Organisation :&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>Ces journées sont co-organisées par les actions “Analyse d’images pour le suivi des milieux” (P. Dusseux, P.-A. Herrault, A. Puissant, D. Sheeren) et “Données 3D géospatiales” (M. Servières, S. Christophe) du GdR CNRS MAGIS, et par l’action MACLEAN du GdR CNRS MADICS. (T. Corpetti, D. Ienco, R. Interdonato, S. Lefèvre, M.-T. Pham) en partenariat avec le GdR CNRS IG-RV (G. Gesquière).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Contact : &lt;a href="mailto:gdr.madics-magis-igrv.observation3d@inria.fr">gdr.madics-magis-igrv.observation3d@inria.fr&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Les repas de midi des mercredi 24/11 et jeudi 25/11 seront pris en charge par les GdR impliqués&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Journées du GT GDMM</title><link>https://gdr-igrv.fr/event/gdmm2021/</link><pubDate>Mon, 15 Nov 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/gdmm2021/</guid><description/></item><item><title>Journée « Avatars » 2021</title><link>https://gdr-igrv.fr/event/avatars-2021/</link><pubDate>Wed, 13 Oct 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/avatars-2021/</guid><description/></item><item><title>Explication des modèles des réseaux profonds en problèmes de classification, d'amélioration et d’interprétation des images et des signaux/données (GdR ISIS, GdR IG-RV)</title><link>https://gdr-igrv.fr/event/explicationia/</link><pubDate>Mon, 11 Oct 2021 10:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/explicationia/</guid><description>&lt;p>L&amp;rsquo;apprentissage profond, un des outils-phares de l&amp;rsquo;Intelligence Artificielle, a remporté un grand succès dans de nombreux domaines en traitement et analyse des images, des vidéos, de l&amp;rsquo;information multimodale. Cependant, l&amp;rsquo;aspect boîte noire des réseaux de neurones profonds est devenu l&amp;rsquo;un des principaux obstacles à leur large acceptation dans des applications critiques telles que le diagnostic médical et la thérapie, voire la conduite autonome. Au lieu de développer et d&amp;rsquo;utiliser les réseaux de neurones profonds comme des boîtes noires et d&amp;rsquo;adapter des architectures connues à une variété de problèmes, le but de l&amp;rsquo;apprentissage profond explicable est de proposer des méthodes pour &amp;ldquo;comprendre&amp;rdquo; et &amp;ldquo;expliquer&amp;rdquo; comment ces systèmes produisent leurs décisions. L’explication des décisions des réseaux profonds comporte deux aspects: l’analyse des décisions et la présentation des explications à l’utilisateur. Elle fait donc intervenir deux communautés scientifiques Intelligence artificielle/Image et Visualisation de l’information. L&amp;rsquo;objectif de cette deuxième journée du GDR-ISIS est de rassembler la communauté des chercheurs qui travaillent sur la question de l&amp;rsquo;amélioration de l&amp;rsquo;explicabilité des algorithmes et systèmes d&amp;rsquo;IA dans le domaine image-signal et de visualisation de l’information.&lt;/p>
&lt;p>Les principaux sujets que nous proposons de traiter sont les suivants mais peuvent être étendus :&lt;/p>
&lt;ul>
&lt;li>explication des caractéristiques générées par des couches de convolution des réseaux profonds convolutionnels,&lt;/li>
&lt;li>les mécanismes d&amp;rsquo;attention dans les réseaux neuronaux profonds et leur explication ;&lt;/li>
&lt;li>pour les données temporelles, l&amp;rsquo;explication des caractéristiques et des moments les plus importants pour la prédiction et des intervalles de temps où la contribution de chaque donnée est importante ;&lt;/li>
&lt;li>comment l&amp;rsquo;explication peut aider à rendre les architectures d&amp;rsquo;apprentissage profond plus parcimonieuses et plus légères ;&lt;/li>
&lt;li>lors de l&amp;rsquo;utilisation de données multimodales, comment les prédictions dans les flux de données sont corrélées et s&amp;rsquo;expliquent entre elles ;&lt;/li>
&lt;li>la génération automatique d&amp;rsquo;explications / justifications des décisions des algorithmes et des systèmes ;&lt;/li>
&lt;li>visualisation des explications de manière interprétable pour les utilisateurs;&lt;/li>
&lt;li>évaluation des explications générées par l&amp;rsquo;apprentissage profond et d&amp;rsquo;autres systèmes d&amp;rsquo;IA:&lt;/li>
&lt;/ul>
&lt;p>Cette journée est organisée conjointement par le thème B Image et vision et le thème T conjointement avec GDR IGRV . Le programme comporte 2 conférences invitées :&lt;/p>
&lt;p>“Une analyse théorique de la méthode LIME”, Damien Garreau, Laboratoire J.A. Dieudonné UMR CNRS 7351 Université de Nice Côte d’Azur
&amp;ldquo;Reasoning vs. bias exploitation: X-raying high-capacity deep networks&amp;rdquo; Chrisian Wolf, LIRIS UMR 5205, INSA Lyon&lt;/p>
&lt;p>Organisateurs :&lt;/p>
&lt;p>GDR-ISIS&lt;/p>
&lt;p>Nicolas Thome : &lt;a href="mailto:nicolas.thome@cnam.fr">nicolas.thome@cnam.fr&lt;/a>
Jenny Benois-Pineau : &lt;a href="mailto:jenny.benois-pineau@u-bordeaux.fr">jenny.benois-pineau@u-bordeaux.fr&lt;/a>
Alexandre Benoit : &lt;a href="mailto:alexandre.benoit@univ-smb.fr">alexandre.benoit@univ-smb.fr&lt;/a>&lt;/p>
&lt;p>GDR-IGRV&lt;/p>
&lt;p>Romain Vuillemot : &lt;a href="mailto:romain.vuillemot@ec-lyon.fr">romain.vuillemot@ec-lyon.fr&lt;/a>
Romain Bourqui : &lt;a href="mailto:romain.bourqui@u-bordeaux.fr">romain.bourqui@u-bordeaux.fr&lt;/a>&lt;/p>
&lt;p>Propositions des exposés sont à envoyer aux organisateurs de la journée.&lt;/p></description></item><item><title>Prix de thèse du GDR IG-RV 2021</title><link>https://gdr-igrv.fr/post/21-10-06-prix-these-2021/</link><pubDate>Wed, 06 Oct 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/21-10-06-prix-these-2021/</guid><description>&lt;p>&lt;strong>Résultats du prix de thèse du GDR IG-RV 2021 en collaboration avec l’Association Française d’Informatique Graphique, l’Association Française de la XR et le Chapitre Français d’Eurographics.&lt;/strong>&lt;/p>
&lt;p>Pour cette cinquième édition, la participation au concours était ouverte aux docteurs ayant soutenu leur thèse entre le 01/01/2020 et le 31/12/2020. Il y a eu 11 soumissions, toutes d’un excellent niveau scientifique et couvrant largement les thématiques du GDR IG-RV.&lt;/p>
&lt;p>Cette année, le jury de sélection a été animé par David Coeurjolly et Loïc Barthe et il était composé de Florence Bertails-Descoubes, Georges-Pierre Bonneau, George Drettakis, Samuel Hornus, Daniel Mestre, Alexis Paljic et Julien Tierny.&lt;/p>
&lt;p>Le prix de thèse du GDR IG-RV 2021 est décerné à :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Rebecca Fribourg&lt;/strong> pour sa thèse intitulée &lt;em>« Contribution to the study of factors influencing the sense of embodiment towards avatars in virtual reality »&lt;/em>, effectuée sous la direction d’Anatole Lécuyer, Ferran Argelaguet et Ludovic Hoyet à l’Université de Rennes 1.&lt;/li>
&lt;/ul>
&lt;p>Un accessit a aussi été décerné à :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Pierre Ecormier-Nocca&lt;/strong> pour sa thèse intitulée &lt;em>« Authoring consistent, animated ecosystems: Efficient learning from partial data »&lt;/em>, effectuée sous la direction de Marie-Paule Cani et Pooran Memari à l’Ecole Polytechnique.&lt;/li>
&lt;/ul>
&lt;p>Nous tenons à remercier l’ensemble des candidats pour leur participation,&lt;/p>
&lt;p>Les animateurs du prix de thèse 2021,
David Coeurjolly et Loïc Barthe&lt;/p></description></item><item><title>De nouveaux rédacteurs scientifiques rejoignent l'équipe de rédaction du site</title><link>https://gdr-igrv.fr/post/21-09-30-new-redactors/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/21-09-30-new-redactors/</guid><description>&lt;p>&lt;a href="https://gdr-igrv.fr/author/johanna-delanoy/">Johanna&lt;/a>, &lt;a href="https://gdr-igrv.fr/author/rebecca-fribourg/">Rebecca&lt;/a> et &lt;a href="https://gdr-igrv.fr/author/etienne-corman/">Étienne&lt;/a> rejoignent l&amp;rsquo;équipe de rédaction du site web du GdR. Ils participeront à la rédaction des articles et brèves du site et à la communication du GdR. Merci à eux !&lt;/p></description></item><item><title>Journées du GTAS</title><link>https://gdr-igrv.fr/event/gtas-2021/</link><pubDate>Mon, 05 Jul 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/gtas-2021/</guid><description/></item><item><title>Groupe de travail "Géométrie discrète &amp; morphologie mathématique" (GT-GDMM)</title><link>https://gdr-igrv.fr/gts/gt-gdmm/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/gts/gt-gdmm/</guid><description>&lt;img src="segmentation_regularisation.png" height="300">
&lt;ul>
&lt;li>&lt;strong>Site&lt;/strong> : &lt;a href="http://gt-gdmm.u-bordeaux.fr" target="_blank" rel="noopener">http://gt-gdmm.u-bordeaux.fr&lt;/a>&lt;/li>
&lt;li>&lt;strong>Responsables&lt;/strong> : Phuc Ngo (Université de Lorraine, LORIA) et Jean Cousty (LIGM, Marne-la-Vallée)&lt;/li>
&lt;li>&lt;strong>Mots-clés&lt;/strong> : Géométrie discrète, morphologie mathématique, topologies discrète et digitale, imagerie discrète, graphes.&lt;/li>
&lt;/ul>
&lt;br>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Description&lt;/strong> : Par définition, le barycentre du GT GDMM est
constitué par la Morphologie mathématique et de la Géométrie
discrète, deux domaines dans lesquels la recherche française tient
historiquement une place prépondérante. Néanmoins, les champs
d’investigation du GT GDMM se sont largement ouverts au cours des
dernières années, et la géométrie discrète comme la morphologie
mathématique se développent désormais fortement à leurs interfaces,
et notamment en lien avec les domaines suivants :&lt;/p>
&lt;ul>
&lt;li>Traitement de la géométrie ou Geometry processing, géométrie algorithmique, analyse numérique pour la géométrie digitale ;&lt;/li>
&lt;li>Optimisation discrète, théorie des graphes, traitement du signal, machine learning pour la morphologie mathématique.&lt;/li>
&lt;/ul>
&lt;p>Ainsi, en sus des travaux intrinsèquement liés au GT GDMM, ces
développements permettent d’établir des ponts avec plusieurs autres
grands domaines relevant du GdR IGRV. On peut souligner par exemple des
liens avec des problématiques de rendu (e.g. le développement
d’opérateurs différentiels robustes pour l’application de textures sur
des données discrètes) ; de la modélisation géométrique (e.g. modéli-
sation par croquis via une forme digitale, modélisation de formes
digitales par union de convexes) ; ou encore de la visualisation
(e.g. visualisation de données de grandes dimensions par l’utilisation
de modèles hiérarchiques de structures combinatoires).&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Groupe de travail "modélisation géométrique" (GT-MG)</title><link>https://gdr-igrv.fr/gts/gt-mg/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/gts/gt-mg/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/gts/gt-mg/logo-gt-mg_hu139f885b965f96c31b2cc6f06b8fdd6d_117244_18a4737f75546f570aab50faed897156.webp 400w,
/gts/gt-mg/logo-gt-mg_hu139f885b965f96c31b2cc6f06b8fdd6d_117244_b73d33b021d9b9bf679ab01a4ed7a585.webp 760w,
/gts/gt-mg/logo-gt-mg_hu139f885b965f96c31b2cc6f06b8fdd6d_117244_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://gdr-igrv.fr/gts/gt-mg/logo-gt-mg_hu139f885b965f96c31b2cc6f06b8fdd6d_117244_18a4737f75546f570aab50faed897156.webp"
width="641"
height="259"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Site&lt;/strong> : &lt;a href="http://gtmg.u-bourgogne.fr/" target="_blank" rel="noopener">http://gtmg.u-bourgogne.fr/&lt;/a>&lt;/li>
&lt;li>&lt;strong>Responsables&lt;/strong> : Julie Digne (CNRS, LIRIS, Lyon) et Romain Raffin (LIB, Dijon)&lt;/li>
&lt;li>&lt;strong>Mots-clés&lt;/strong> : Courbes, surfaces, maillages, modèles 3D, nuages de points, reconstruction, contraintes, déformation, multirésolution, paramétrisation, apprentissage, géométrie différentielle, algorithmes de subdivision, topologie, axe médian, squelette.&lt;/li>
&lt;/ul>
&lt;p>La modélisation géométrique est un domaine de recherche commun à l&amp;rsquo;informatique et aux mathématiques appliquées qui s&amp;rsquo;intéresse à des méthodes numériques et algorithmiques de création, représentation, modélisation, analyse et acquisition de formes géométriques 3D (courbes et surfaces, maillages, nuages de points et volumes, domaines discret, continu et semi-continu, analyse de formes, descripteurs).&lt;/p>
&lt;p>Ce domaine de recherche combine théorie et applications de plusieurs disciplines :&lt;/p>
&lt;ul>
&lt;li>Informatique (algorithmes, structures de données, calcul numérique et symbolique, informatique graphique, géométrie algorithmique, traitement de données géométriques),&lt;/li>
&lt;li>Mathématiques (géométrie différentielle, géométrie algébrique, approximation, optimisation, topologie calculatoire),&lt;/li>
&lt;li>Ingénierie (génération de maillages, éléments finis, conception, prototypage virtuel).&lt;/li>
&lt;/ul>
&lt;p>Une des spécificités de la modélisation géométrique est de considérer de façon transverse ces 3 domaines. La modélisation sous contraintes utilise un ensemble de règles (géométrique, physique) et une résolution formelle ; des critères sémantiques ou esthétiques sont parfois considérés. La génération des maillages pour les méthodes à éléments finis en 2D ou 3D proposent des modèles hybrides (hexaédriques, tétraédriques ou plus généraux) ; les modèles volumiques gagnent en importance dans le contexte de la fabrication additive. Le &lt;em>geometry processing&lt;/em>, qui extrait des modèles géométriques à partir de données 3D larges et non-structurées, se base sur des théories mathématiques reconnues (optimisation robuste, transport optimal, méthodes &lt;em>a contrario&lt;/em>).&lt;/p>
&lt;p>Traditionnellement les domaines applicatifs sont ceux de la CAO, la mécanique, le &lt;em>design&lt;/em> ou le jeu vidéo. De plus en plus, grâce à la démocratisation des moyens de numérisation, les contenus 3D sont largement présents dans tous les domaines industriels et à l&amp;rsquo;interface de nombreuses disciplines (multimedia, médecine, patrimoine&amp;hellip;). La demande de manipulation, de compréhension et d&amp;rsquo;analyse de modèles géométriques est donc plus pregnante, allant de la numérisation à l&amp;rsquo;impression de prototypes (grâce à la fabrication additive) en passant par les méthodes d&amp;rsquo;apprentissage (en particulier apprentissage profond).&lt;/p>
&lt;p>Le GT MG fait également partie des GT du GDR Informatique Mathématique &lt;a href="https://www.gdr-im.fr/" target="_blank" rel="noopener">GDR IM&lt;/a>.&lt;/p></description></item><item><title>Groupe de travail "Réalités virtuelles" (GT-RV)</title><link>https://gdr-igrv.fr/gts/gt-rv/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/gts/gt-rv/</guid><description>&lt;img src="photo gtrv.png" height="300">
&lt;ul>
&lt;li>&lt;strong>Responsables&lt;/strong> : Cédric Fleury (IMT Atlantique; INUIT), Jean-Marie Normand (AAU/Hybrid, École Centrale de Nantes).&lt;/li>
&lt;li>&lt;strong>Mots-clés&lt;/strong> : réalité virtuelle, réalité augmentée, interaction 3D, métaphores, interfaces, multi-modalité,
perception, cognition, motricité, comportement, immersion, présence, usages, acceptabilité.&lt;/li>
&lt;/ul>
&lt;p>Le thème générique des modèles et techniques d’interaction en environnement virtuel, que ce soit
dans un contexte de réalité virtuelle ou dans un contexte de réalité augmentée est central pour ce
groupe de travail. La problématique de l’immersion et de l’interaction est abordée à la fois sous un
angle technologique, essentiellement informatique, et d’un point de vue humano-centré. Malgré les
très nombreux travaux scientifiques et les améliorations constantes des dispositifs techniques,
l’interaction en environnement 3D reste un sujet d’actualité qui est très loin d’être clos, car il reste
encore aujourd’hui difficile pour un sujet humain d’interagir avec un tel environnement. Le cœur
scientifique de ce groupe de travail est la prise en compte les situations d&amp;rsquo;interaction d&amp;rsquo;un sujet humain
avec un environnement de synthèse dans lequel il se trouve immergé, que ce soit dans un contexte de
réalité virtuelle ou dans un contexte de réalité augmentée. L&amp;rsquo;objet d&amp;rsquo;étude est le couplage perceptivo-
moteur et cognitif entre l&amp;rsquo;utilisateur et l&amp;rsquo;environnement. La question est donc abordée selon le
triptyque : (1) tâche (action à réaliser dans l’environnement), (2) dispositif, à la fois logiciel (mise en
évidence d’une métaphore d’interaction) et matériel (dispositif d’interaction) et (3) expérience vécue
par le sujet humain.&lt;/p>
&lt;p>Les nouvelles générations de dispositifs immersifs, visiocasques, lunettes de réalité augmentée, ou
l’extension de leurs usages, soulèvent des questions sur leur acceptabilité, la nécessité d’une
conception spécifique des environnements virtuels et des interfaces 3D, ou les limites des capacités
d’adaptation des sujets humains à leur utilisation. Ces questions sont d’autant plus pertinentes que la
réalité virtuelle ou augmentée est peut-être en passe de sortir d’un usage limité dans le temps, la
nature des tâches et le profil des utilisateurs, pour investir des usages destinés à un public plus vaste
(enfants, adultes, personnes âgées), pour des usages variés (ludiques, éducatifs, médicaux, etc.). Ce
nouveau contexte motive que la communauté scientifique dresse un état des connaissances sur le
36domaine et s’interroge sur les nouvelles études à mener. Par exemple, on peut s’interroger sur l’impact
du type de dispositif sur la perception des distances, du mouvement, la précision des gestes, la
locomotion, la perception de soi… Est-ce que les avancées technologiques font que les dispositifs ont
des caractéristiques techniques garantissant une immersion de qualité (selon quels critères) ? Est-ce
que les valeurs critiques des différents critères d’acceptabilité sont les mêmes ? Que sait-on de
l’impact de leurs caractéristiques sur les processus physiologiques et cognitifs ? Existe-t-il des risques
connus, potentiels, en matière de santé publique ? Est-il envisageable de définir des guides de
conception des environnements virtuels adaptés à ces nouveaux contextes ?&lt;/p></description></item><item><title>Groupe de travail "Rendu" (GT-rendu)</title><link>https://gdr-igrv.fr/gts/gt-rendu/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/gts/gt-rendu/</guid><description>&lt;img src="rep-img-gt-rendu.jpg" height="300" >
&lt;ul>
&lt;li>&lt;strong>Site&lt;/strong> : &lt;a href="http://gtrendu.blogspot.fr/" target="_blank" rel="noopener">http://gtrendu.blogspot.fr/&lt;/a>&lt;/li>
&lt;li>&lt;strong>Responsable&lt;/strong> : Romain Vergne (LJK, Grenoble), George Drettakis (INRIA, Sophia-Antipolis), Romain Pacanowski (INRIA, Bordeaux)&lt;/li>
&lt;li>&lt;strong>Mots-clés&lt;/strong> : rendu photo réaliste, simulation de l&amp;rsquo;éclairage et d&amp;rsquo;effets lumineux, rendu inverse, rendu expressif, rendu artistique, réalité augmentée, rendu temps réel, rendu basé image.&lt;/li>
&lt;/ul>
&lt;br>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Description&lt;/strong> : Les objectifs du GT Rendu peuvent se résumer comme suit :&lt;/p>
&lt;ul>
&lt;li>Comprendre et prendre en compte la plupart des phénomènes lumineux pour créer des images réalistes, en maîtrisant les erreurs engendrées entre les modèles utilisés et la réalité.&lt;/li>
&lt;li>Comprendre, modéliser et mettre en évidence les informations pertinentes pour obtenir des images adaptées à la communication et à l&amp;rsquo;expression visuelle.&lt;/li>
&lt;/ul>
&lt;p>Les modèles de rendu, réaliste ou non, deviennent de plus en plus complexes et conduisent donc à des temps de calcul de plus en plus grands. L&amp;rsquo;un des enjeux de la synthèse d&amp;rsquo;images reste le développement d&amp;rsquo;algorithmes plus performants en terme de vitesse de calcul. Un problème scientifique fondamental concerne la manipulation temps réel de grands volumes de données. Des problèmes algorithmiques difficiles restent à explorer et rejoignent les problèmes algorithmiques précédemment cités si l&amp;rsquo;on veut bénéficier de techniques de visualisation temps réel et dynamique des données.
Les travaux récents des équipes françaises d&amp;rsquo;informatique graphique ont permis des avancées significatives dans la plupart des thématiques liées au rendu :&lt;/p>
&lt;ul>
&lt;li>L&amp;rsquo;acquisition et la représentation de matériaux qui constituent des problèmes complexes pour obtenir des images réalistes de manière efficace.&lt;/li>
&lt;li>L&amp;rsquo;intelligence artificielle, et notamment sur l&amp;rsquo;apprentissage profond, qui nécessite un grand nombre d&amp;rsquo;images et de données en entrée qui sont souvent impossible à obtenir. La synthèse est une des clés permettant de générer ces données.&lt;/li>
&lt;li>L&amp;rsquo;échantillonnage des données sur chaque pixel qui constitue un aspect primordial pour générer des images de qualité rapidement lors de la résolution de l&amp;rsquo;équation du rendu. Même si le problème n&amp;rsquo;est pas récent, il est toujours traité activement par la communauté.&lt;/li>
&lt;li>Le rendu expressif, dont l&amp;rsquo;objectif est de produire des images stylisées ou plausibles en s&amp;rsquo;appuyant sur des schémas d&amp;rsquo;approximation du transport de la lumière ainsi que sur des analyses et expériences perceptuelles.&lt;/li>
&lt;li>La génération de textures (par l&amp;rsquo;exemple ou procéduralement) qui constitue également un domaine de recherche actif pour obtenir des solutions en temps réel en contrôlant précisément les aspects de l&amp;rsquo;apparence finale des surfaces.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Groupe de travail "Visualisation" (GT-Visu)</title><link>https://gdr-igrv.fr/gts/gt-visu/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/gts/gt-visu/</guid><description>&lt;ul>
&lt;li>&lt;strong>Responsables&lt;/strong> : Jonathan Sarton (ICube, Université de Strasbourg), Romain Vuillemot (LIRIS, Lyon) et Florent Cabric (LISN, Paris Saclay)&lt;/li>
&lt;li>&lt;strong>Mots-clés&lt;/strong> : Visualisation scientifique, visualisation d’informations, Visual Analytics, Visual Data Mining, visualisation in-situ, High Performance Visualization, interactions visuelles, visualisation d&amp;rsquo;informations incertaines.&lt;/li>
&lt;/ul></description></item><item><title>Résultats du prix 2021</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2021/</link><pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2021/</guid><description>&lt;h1 id="lauréate">Lauréate&lt;/h1>
&lt;p>&lt;strong>Rebecca Fribourg&lt;/strong> pour sa thèse intitulée « &lt;em>Contribution to the study of factors influencing the sense of embodiment towards avatars in virtual reality&lt;/em> », effectuée sous la direction d’Anatole Lécuyer, Ferran Argelaguet et Ludovic Hoyet à l’Université de Rennes 1.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2021/prixdeth%c3%a8se_rebecca_fribourg.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://tel.archives-ouvertes.fr/tel-03191307" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="accessit">Accessit&lt;/h1>
&lt;p>&lt;strong>Pierre Ecormier-Nocca&lt;/strong> pour sa thèse intitulée « &lt;em>Authoring consistent, animated ecosystems: Efficient learning from partial data&lt;/em> », effectuée sous la direction de Marie-Paule Cani et Pooran Memari à l’Ecole Polytechnique.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2021/Video-Pierre.mkv" type="video/mkv">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://tel.archives-ouvertes.fr/tel-03086483" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;p>&lt;em>Le jury 2021 a été animé par Loïc Barthe et David Coeurjolly. Il était composé de Florence Bertails-Descoubes, Georges-Pierre Bonneau, George Drettakis, Samuel Hornus, Daniel Mestre, Alexis Paljic et Julien Tierny.&lt;/em>&lt;/p></description></item><item><title>La gazette du GT « Modélisation géométrique », n°0</title><link>https://gdr-igrv.fr/post/20-12-02-gtmg-gazette/</link><pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/post/20-12-02-gtmg-gazette/</guid><description>&lt;p>Le &lt;a href="https://gdr-igrv.fr/gts/gt-mg/">GT MG&lt;/a> a lancé le &lt;a href="https://gtmg.u-bourgogne.fr/wp-content/uploads/2021/07/gazette-GTMG_n0_16juillet2021.pdf" target="_blank" rel="noopener">premier numéro&lt;/a> de sa gazette.&lt;/p></description></item><item><title>Résultats du prix 2020</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2020/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2020/</guid><description>&lt;h1 id="lauréat">Lauréat&lt;/h1>
&lt;p>&lt;strong>Valentin Deschaintre&lt;/strong> (Inria Sophia) pour sa thèse intitulée « &lt;em>Acquisition légère de matériaux par apprentissage profond&lt;/em> », effectuée sous la co-direction d&amp;rsquo;Adrien Bousseau et George Drettakis.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2020/prix2020_Valentin-Deschaintre.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://hal.archives-ouvertes.fr/tel-02418445v1" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;p>&lt;em>Le jury 2020 a été animé par Loïc Barthe et David Coeurjolly. Il était composé de Georges-Pierre Bonneau, George Drettakis, Samuel Hornus, Maud Marchal, Alexis Paljic, Julien Tierny.&lt;/em>&lt;/p></description></item><item><title>An example preprint / working paper</title><link>https://gdr-igrv.fr/publication/preprint/</link><pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/publication/preprint/</guid><description>&lt;p>Supplementary notes can be added here, including &lt;a href="https://sourcethemes.com/academic/docs/writing-markdown-latex/" target="_blank" rel="noopener">code and math&lt;/a>.&lt;/p></description></item><item><title>Résultats du prix 2019</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2019/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2019/</guid><description>&lt;h1 id="lauréat">Lauréat&lt;/h1>
&lt;p>&lt;strong>Guillaume Cordonnier&lt;/strong> (Université Grenoble Alpes) pour sa thèse intitulée « &lt;em>Modèles à couches pour simuler l&amp;rsquo;évolution de paysages à grande échelle&lt;/em> », effectuée sous la co-direction de Marie-Paule Cani et Eric Galin.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2019/Prix-These-IGRV-2019_Cordonnier.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="http://www.theses.fr/2018GREAM072" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="accessit">Accessit&lt;/h1>
&lt;p>&lt;strong>Jean-Dominique Favreau&lt;/strong> (Inria Sophia) pour sa thèse intitulée « &lt;em>Vectorisation compacte d’images par approches stochastiques&lt;/em> », effectuée sous la co-direction de Adrien Bousseau et Florent Lafarge.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2019/Prix-These-IGRV-2019_Accessit_Favreau.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="http://www.theses.fr/2018AZUR4004" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;p>&lt;em>Le jury 2019 a été animé par Loïc Barthe et David Coeurjolly. Il était composé de Raphaëlle Chaine, George Drettakis, Jacques-Olivier Lachaud, Maud Marchal, Alexis Paljic, Julien Tierny.&lt;/em>&lt;/p></description></item><item><title>Résultats du prix 2018</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2018/</link><pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2018/</guid><description>&lt;h1 id="lauréat">Lauréat&lt;/h1>
&lt;p>&lt;strong>Jérémie Dumas&lt;/strong> (Université de Lorraine) pour sa thèse intitulée « &lt;em>Synthèse de formes contrôlable pour la fabrication digitale&lt;/em> », effectuée sous la direction de Sylvain Lefebvre.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2018/Prix-These-IGRV-2018_Dumas.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://www.jdumas.org/phd/" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="accessits">Accessits&lt;/h1>
&lt;p>&lt;strong>Lonni Besançon&lt;/strong> (Université Paris-Saclay) pour sa thèse intitulée « &lt;em>An interaction Continuum for 3D Data Visualization&lt;/em> », effectuée sous la co-direction de Tobias Isenberg et Mehdi Ammi.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2018/Prix-These-IGRV-2018_Accessit-1_Besancon.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://tel.archives-ouvertes.fr/tel-01684210/" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Tibor Stanko&lt;/strong> (Université Grenoble Alpes) pour sa thèse intitulée « &lt;em>Shape reconstruction of meshed smooth surfaces equipped with inertial sensors&lt;/em> », effectuée sous la co-direction de Stefanie Hahmann, Georges-Pierre Bonneau et Nathalie Saguin-Sprynski.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2018/Prix-These-IGRV-2018_Accessit-2_Stanko.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://hal.inria.fr/tel-01673779" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;p>&lt;em>Le jury 2018 a été animé par Loïc Barthe et David Coeurjolly. Il était composé de Raphaëlle Chaine, Pierre De Loor, Julien Tierny, Jacques-Olivier Lachaud, Maud Marchal et Mathias Paulin.&lt;/em>&lt;/p></description></item><item><title>Résultats du prix 2017</title><link>https://gdr-igrv.fr/resultats-prix-de-these/2017/</link><pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/resultats-prix-de-these/2017/</guid><description>&lt;h1 id="lauréat">Lauréat&lt;/h1>
&lt;p>&lt;strong>Gilles Daviet&lt;/strong> (Université de Grenoble, Inria) pour sa thèse intitulée « &lt;em>Modèles et algorithmes pour la simulation du contact frottant dans les matériaux complexes - Application aux milieux fibreux et granulaires&lt;/em> ».&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2017/Prix-These-IGRV-2017_Daviet.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://tel.archives-ouvertes.fr/tel-01519203" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="accessits">Accessits&lt;/h1>
&lt;p>&lt;strong>Merwan Achibet&lt;/strong> (Insa Rennes) pour sa thèse intitulée &amp;ldquo;&lt;em>Contributions to the Design of Novel Hand-based Interaction Techniques for Virtual Environments&lt;/em>&amp;rdquo;.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2017/Prix-These-IGRV-2017_Accessit-1_Gonzalez-Lorenzo.ogv" type="video/ogv">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="http://merwanachibet.net/thesis/thesis.pdf" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Aldo Gonzalez Lorenzo&lt;/strong> (Aix-Marseille Université, Universidad de Sevilla) pour sa thèse intitulée &amp;ldquo;&lt;em>Computational Homology Applied to Discrete Objects&lt;/em>&amp;rdquo;.&lt;/p>
&lt;video controls >
&lt;source src="https://projet.liris.cnrs.fr/gdr-igrv-data/Videos-PrixThese/2017/Prix-These-IGRV-2017_Accessit-2_Achibet.mp4" type="video/mp4">
&lt;/video>
&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://hal.archives-ouvertes.fr/tel-01477399v1" target="_blank" rel="noopener" class="btn btn-primary px-3 py-3">📄 Thèse&lt;/a>
&lt;/li>
&lt;/ul>
&lt;p>&lt;em>Le jury 2018 a été animé par Loïc Barthe et David Coeurjolly.&lt;/em>&lt;/p></description></item><item><title>An example journal article</title><link>https://gdr-igrv.fr/publication/journal-article/</link><pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/publication/journal-article/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;p>Supplementary notes can be added here, including &lt;a href="https://sourcethemes.com/academic/docs/writing-markdown-latex/" target="_blank" rel="noopener">code and math&lt;/a>.&lt;/p></description></item><item><title>An example conference paper</title><link>https://gdr-igrv.fr/publication/conference-paper/</link><pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/publication/conference-paper/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;p>Supplementary notes can be added here, including &lt;a href="https://sourcethemes.com/academic/docs/writing-markdown-latex/" target="_blank" rel="noopener">code and math&lt;/a>.&lt;/p></description></item><item><title/><link>https://gdr-igrv.fr/actions/prix-these/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/actions/prix-these/</guid><description/></item><item><title/><link>https://gdr-igrv.fr/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/admin/config.yml</guid><description/></item><item><title/><link>https://gdr-igrv.fr/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/contact/</guid><description/></item><item><title/><link>https://gdr-igrv.fr/gts/gt-as/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/gts/gt-as/</guid><description/></item><item><title/><link>https://gdr-igrv.fr/people/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/people/</guid><description/></item></channel></rss>